<Type Name="SpeechRecognitionEngine" FullName="System.Speech.Recognition.SpeechRecognitionEngine">
  <Metadata><Meta Name="ms.openlocfilehash" Value="ef8a305c992c9553d22e0a44d7bd0091f7f4577f" /><Meta Name="ms.sourcegitcommit" Value="0084afad1b3b1cb2c8ad2c142ae3597d08bad4a7" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="ja-JP" /><Meta Name="ms.lasthandoff" Value="10/31/2019" /><Meta Name="ms.locfileid" Value="73395714" /></Metadata><TypeSignature Language="C#" Value="public class SpeechRecognitionEngine : IDisposable" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit SpeechRecognitionEngine extends System.Object implements class System.IDisposable" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.SpeechRecognitionEngine" />
  <TypeSignature Language="VB.NET" Value="Public Class SpeechRecognitionEngine&#xA;Implements IDisposable" />
  <TypeSignature Language="C++ CLI" Value="public ref class SpeechRecognitionEngine : IDisposable" />
  <TypeSignature Language="F#" Value="type SpeechRecognitionEngine = class&#xA;    interface IDisposable" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces>
    <Interface>
      <InterfaceName>System.IDisposable</InterfaceName>
    </Interface>
  </Interfaces>
  <Docs>
    <summary><span data-ttu-id="b4702-101">インプロセス音声認識エンジンにアクセスしてエンジンを管理するための手段を提供します。</span><span class="sxs-lookup"><span data-stu-id="b4702-101">Provides the means to access and manage an in-process speech recognition engine.</span></span></summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-102">インストールされている音声認識機能のいずれかに対して、このクラスのインスタンスを作成できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-102">You can create an instance of this class for any of the installed speech recognizers.</span></span> <span data-ttu-id="b4702-103">インストールされているレコグナイザーに関する情報を取得するには、静的な <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A> 方法を使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-103">To get information about which recognizers are installed, use the static <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A> method.</span></span>  
  
 <span data-ttu-id="b4702-104">このクラスは、音声認識エンジンをインプロセスで実行するためのもので、次のように音声認識のさまざまな側面を制御します。</span><span class="sxs-lookup"><span data-stu-id="b4702-104">This class is for running speech recognition engines in-process, and provides control over various aspects of speech recognition, as follows:</span></span>  
  
-   <span data-ttu-id="b4702-105">インプロセス音声認識エンジンを作成するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A> コンストラクターのいずれかを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-105">To create an in-process speech recognizer, use one of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A> constructors.</span></span>  
  
-   <span data-ttu-id="b4702-106">音声認識文法を管理するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A> の各メソッドと、<xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A> プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-106">To manage speech recognition grammars, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A> methods, and the <xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A> property.</span></span>  
  
-   <span data-ttu-id="b4702-107">認識エンジンへの入力を構成するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>、または <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-107">To configure the input to the recognizer, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>, or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> method.</span></span>  
  
-   <span data-ttu-id="b4702-108">音声認識を実行するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> 方法を使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-108">To perform speech recognition, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> method.</span></span>  
  
-   <span data-ttu-id="b4702-109">認識が無音または予期しない入力を処理する方法を変更するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> の各プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-109">To modify how recognition handles silence or unexpected input, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> properties.</span></span>  
  
-   <span data-ttu-id="b4702-110">レコグナイザーが返す代替の数を変更するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A> プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-110">To change the number of alternates the recognizer returns, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A> property.</span></span> <span data-ttu-id="b4702-111">認識エンジンは <xref:System.Speech.Recognition.RecognitionResult> オブジェクトで認識結果を返します。</span><span class="sxs-lookup"><span data-stu-id="b4702-111">The recognizer returns recognition results in a <xref:System.Speech.Recognition.RecognitionResult> object.</span></span>  
  
-   <span data-ttu-id="b4702-112">認識エンジンに対する変更を同期するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-112">To synchronize changes to the recognizer, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> method.</span></span> <span data-ttu-id="b4702-113">認識エンジンは、複数のスレッドを使用してタスクを実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-113">The recognizer uses more than one thread to perform tasks.</span></span>  
  
-   <span data-ttu-id="b4702-114">認識エンジンへの入力をエミュレートするには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> メソッドと <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-114">To emulate input to the recognizer, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> methods.</span></span>  
  
 <span data-ttu-id="b4702-115"><xref:System.Speech.Recognition.SpeechRecognitionEngine> オブジェクトは、オブジェクトをインスタンス化したプロセスを単に使用するためのものです。</span><span class="sxs-lookup"><span data-stu-id="b4702-115">The <xref:System.Speech.Recognition.SpeechRecognitionEngine> object is for the sole use of the process that instantiated the object.</span></span> <span data-ttu-id="b4702-116">これに対し、<xref:System.Speech.Recognition.SpeechRecognizer> は、1つのレコグナイザーを使用したいアプリケーションと共有します。</span><span class="sxs-lookup"><span data-stu-id="b4702-116">By contrast, the <xref:System.Speech.Recognition.SpeechRecognizer> shares a single recognizer with any application that wants to use it.</span></span>  
  
> [!NOTE]
>  <span data-ttu-id="b4702-117">音声認識エンジンへの最後の参照を解放する前に、常に <xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A> を呼び出してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-117">Always call <xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A> before you release your last reference to the speech recognizer.</span></span> <span data-ttu-id="b4702-118">それ以外の場合、使用しているリソースは、ガベージコレクターがレコグナイザーオブジェクトの `Finalize` メソッドを呼び出すまで解放されません。</span><span class="sxs-lookup"><span data-stu-id="b4702-118">Otherwise, the resources it is using will not be freed until the garbage collector calls the recognizer object's `Finalize` method.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-119">次の例は、基本的な音声認識を示すコンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-119">The following example shows part of a console application that demonstrates basic speech recognition.</span></span> <span data-ttu-id="b4702-120">この例では、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> メソッドの `Multiple` モードを使用するため、コンソールウィンドウを閉じるか、デバッグを停止するまで認識を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-120">Because this example uses the `Multiple` mode of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> method, it performs recognition until you close the console window or stop debugging.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SpeechRecognitionApp  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Create an in-process speech recognizer for the en-US locale.  
      using (  
      SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(  
          new System.Globalization.CultureInfo("en-US")))  
      {  
  
        // Create and load a dictation grammar.  
        recognizer.LoadGrammar(new DictationGrammar());  
  
        // Add a handler for the speech recognized event.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Configure input to the speech recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Start asynchronous, continuous speech recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
  
        // Keep the console window open.  
        while (true)  
        {  
          Console.ReadLine();  
        }  
      }  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Recognized text: " + e.Result.Text);  
    }  
  }  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.Grammar" />
    <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
  </Docs>
  <Members>
    <MemberGroup MemberName=".ctor">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary><span data-ttu-id="b4702-121"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> クラスの新しいインスタンスを初期化します。</span><span class="sxs-lookup"><span data-stu-id="b4702-121">Initializes a new instance of the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> class.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-122"><xref:System.Speech.Recognition.SpeechRecognitionEngine> インスタンスは、次のいずれかから構築できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-122">You can construct a <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance from any of the following:</span></span>  
  
-   <span data-ttu-id="b4702-123">システムの既定の音声認識エンジン</span><span class="sxs-lookup"><span data-stu-id="b4702-123">The default speech recognition engine for the system</span></span>  
  
-   <span data-ttu-id="b4702-124">名前で指定した特定の音声認識エンジン</span><span class="sxs-lookup"><span data-stu-id="b4702-124">A specific speech recognition engine that you specify by name</span></span>  
  
-   <span data-ttu-id="b4702-125">指定したロケールの既定の音声認識エンジン</span><span class="sxs-lookup"><span data-stu-id="b4702-125">The default speech recognition engine for a locale that you specify</span></span>  
  
-   <span data-ttu-id="b4702-126"><xref:System.Speech.Recognition.RecognizerInfo> オブジェクトで指定した条件を満たす特定の認識エンジン。</span><span class="sxs-lookup"><span data-stu-id="b4702-126">A specific recognition engine that meets the criteria that you specify in a <xref:System.Speech.Recognition.RecognizerInfo> object.</span></span>  
  
 <span data-ttu-id="b4702-127">音声認識エンジンが認識を開始するには、少なくとも1つの音声認識文法を読み込み、認識エンジンの入力を構成する必要があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-127">Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</span></span>  
  
 <span data-ttu-id="b4702-128">文法を読み込むには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> メソッドを呼び出します。</span><span class="sxs-lookup"><span data-stu-id="b4702-128">To load a grammar, call the <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> method.</span></span>  
  
 <span data-ttu-id="b4702-129">オーディオ入力を構成するには、次のいずれかの方法を使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-129">To configure the audio input, use one of the following methods:</span></span>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A>  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognitionEngine ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; SpeechRecognitionEngine();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary><span data-ttu-id="b4702-130">システムの既定の音声認識エンジンを使用して、<see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> クラスの新しいインスタンスを初期化します。</span><span class="sxs-lookup"><span data-stu-id="b4702-130">Initializes a new instance of the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> class using the default speech recognizer for the system.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-131">音声認識エンジンが音声認識を開始するには、少なくとも1つの認識文法を読み込み、認識エンジンの入力を構成する必要があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-131">Before the speech recognizer can begin speech recognition, you must load at least one recognition grammar and configure the input for the recognizer.</span></span>  
  
 <span data-ttu-id="b4702-132">文法を読み込むには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> メソッドを呼び出します。</span><span class="sxs-lookup"><span data-stu-id="b4702-132">To load a grammar, call the <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> method.</span></span>  
  
 <span data-ttu-id="b4702-133">オーディオ入力を構成するには、次のいずれかの方法を使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-133">To configure the audio input, use one of the following methods:</span></span>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A>  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognitionEngine (System.Globalization.CultureInfo culture);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class System.Globalization.CultureInfo culture) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (culture As CultureInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; SpeechRecognitionEngine(System::Globalization::CultureInfo ^ culture);" />
      <MemberSignature Language="F#" Value="new System.Speech.Recognition.SpeechRecognitionEngine : System.Globalization.CultureInfo -&gt; System.Speech.Recognition.SpeechRecognitionEngine" Usage="new System.Speech.Recognition.SpeechRecognitionEngine culture" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="culture" Type="System.Globalization.CultureInfo" />
      </Parameters>
      <Docs>
        <param name="culture"><span data-ttu-id="b4702-134">音声認識エンジンがサポートする必要があるロケール。</span><span class="sxs-lookup"><span data-stu-id="b4702-134">The locale that the speech recognizer must support.</span></span></param>
        <summary><span data-ttu-id="b4702-135">指定したロケールの既定の音声認識エンジンを使用して、<see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> クラスの新しいインスタンスを初期化します。</span><span class="sxs-lookup"><span data-stu-id="b4702-135">Initializes a new instance of the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> class using the default speech recognizer for a specified locale.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-136">Microsoft Windows とシステム。 Speech API 有効な国コードをすべて受け入れます。</span><span class="sxs-lookup"><span data-stu-id="b4702-136">Microsoft Windows and the System.Speech API accept all valid language-country codes.</span></span> <span data-ttu-id="b4702-137">`CultureInfo` 引数で指定された言語を使用して音声認識を実行するには、その言語の国コードをサポートする音声認識エンジンがインストールされている必要があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-137">To perform speech recognition using the language specified in the `CultureInfo` argument, a speech recognition engine that supports that language-country code must be installed.</span></span> <span data-ttu-id="b4702-138">Microsoft Windows 7 に付属している音声認識エンジンは、次の言語の国コードを使用して動作します。</span><span class="sxs-lookup"><span data-stu-id="b4702-138">The speech recognition engines that shipped with Microsoft Windows 7 work with the following language-country codes.</span></span>  
  
-   <span data-ttu-id="b4702-139">en-GB.</span><span class="sxs-lookup"><span data-stu-id="b4702-139">en-GB.</span></span> <span data-ttu-id="b4702-140">英語 (英国)</span><span class="sxs-lookup"><span data-stu-id="b4702-140">English (United Kingdom)</span></span>  
  
-   <span data-ttu-id="b4702-141">en-US.</span><span class="sxs-lookup"><span data-stu-id="b4702-141">en-US.</span></span> <span data-ttu-id="b4702-142">英語 (米国)</span><span class="sxs-lookup"><span data-stu-id="b4702-142">English (United States)</span></span>  
  
-   <span data-ttu-id="b4702-143">de-de.</span><span class="sxs-lookup"><span data-stu-id="b4702-143">de-DE.</span></span> <span data-ttu-id="b4702-144">ドイツ語 (ドイツ)</span><span class="sxs-lookup"><span data-stu-id="b4702-144">German (Germany)</span></span>  
  
-   <span data-ttu-id="b4702-145">es-ES.</span><span class="sxs-lookup"><span data-stu-id="b4702-145">es-ES.</span></span> <span data-ttu-id="b4702-146">スペイン語 (スペイン)</span><span class="sxs-lookup"><span data-stu-id="b4702-146">Spanish (Spain)</span></span>  
  
-   <span data-ttu-id="b4702-147">fr-FR.</span><span class="sxs-lookup"><span data-stu-id="b4702-147">fr-FR.</span></span> <span data-ttu-id="b4702-148">フランス語 (フランス)</span><span class="sxs-lookup"><span data-stu-id="b4702-148">French (France)</span></span>  
  
-   <span data-ttu-id="b4702-149">ja-JP.</span><span class="sxs-lookup"><span data-stu-id="b4702-149">ja-JP.</span></span> <span data-ttu-id="b4702-150">日本語 (日本)</span><span class="sxs-lookup"><span data-stu-id="b4702-150">Japanese (Japan)</span></span>  
  
-   <span data-ttu-id="b4702-151">zh-CN.</span><span class="sxs-lookup"><span data-stu-id="b4702-151">zh-CN.</span></span> <span data-ttu-id="b4702-152">中国語 (中国)</span><span class="sxs-lookup"><span data-stu-id="b4702-152">Chinese (China)</span></span>  
  
-   <span data-ttu-id="b4702-153">zh-TW.</span><span class="sxs-lookup"><span data-stu-id="b4702-153">zh-TW.</span></span> <span data-ttu-id="b4702-154">中国語 (台湾)</span><span class="sxs-lookup"><span data-stu-id="b4702-154">Chinese (Taiwan)</span></span>  
  
 <span data-ttu-id="b4702-155">"en"、"fr"などの 2 文字の言語コードまたは"es"も使用できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-155">Two-letter language codes such as "en", "fr", or "es" are also permitted.</span></span>  
  
 <span data-ttu-id="b4702-156">音声認識エンジンが認識を開始するには、少なくとも1つの音声認識文法を読み込み、認識エンジンの入力を構成する必要があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-156">Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</span></span>  
  
 <span data-ttu-id="b4702-157">文法を読み込むには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> メソッドを呼び出します。</span><span class="sxs-lookup"><span data-stu-id="b4702-157">To load a grammar, call the <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> method.</span></span>  
  
 <span data-ttu-id="b4702-158">オーディオ入力を構成するには、次のいずれかの方法を使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-158">To configure the audio input, use one of the following methods:</span></span>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-159">次の例は、基本的な音声認識を示し、en-us ロケールの音声認識エンジンを初期化するコンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-159">The following example shows part of a console application that demonstrates basic speech recognition, and initializes a speech recognizer for the en-US locale.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SpeechRecognitionApp  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Create an in-process speech recognizer for the en-US locale.  
      using (  
      SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(  
          new System.Globalization.CultureInfo("en-US")))  
      {  
  
        // Create and load a dictation grammar.  
        recognizer.LoadGrammar(new DictationGrammar());  
  
        // Add a handler for the speech recognized event.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Configure input to the speech recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Start asynchronous, continuous speech recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
  
        // Keep the console window open.  
        while (true)  
        {  
          Console.ReadLine();  
        }  
      }  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Recognized text: " + e.Result.Text);  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.ArgumentException"><span data-ttu-id="b4702-160">インストールされた音節認識機能はいずれもこのロケールをサポートしないか、または <paramref name="culture" /> が不変のカルチャです。</span><span class="sxs-lookup"><span data-stu-id="b4702-160">None of the installed speech recognizers support the specified locale, or <paramref name="culture" /> is the invariant culture.</span></span></exception>
        <exception cref="T:System.ArgumentNullException"><span data-ttu-id="b4702-161"><paramref name="Culture" /> は <see langword="null" />です。</span><span class="sxs-lookup"><span data-stu-id="b4702-161"><paramref name="Culture" /> is <see langword="null" />.</span></span></exception>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognitionEngine (System.Speech.Recognition.RecognizerInfo recognizerInfo);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class System.Speech.Recognition.RecognizerInfo recognizerInfo) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; SpeechRecognitionEngine(System::Speech::Recognition::RecognizerInfo ^ recognizerInfo);" />
      <MemberSignature Language="F#" Value="new System.Speech.Recognition.SpeechRecognitionEngine : System.Speech.Recognition.RecognizerInfo -&gt; System.Speech.Recognition.SpeechRecognitionEngine" Usage="new System.Speech.Recognition.SpeechRecognitionEngine recognizerInfo" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="recognizerInfo" Type="System.Speech.Recognition.RecognizerInfo" />
      </Parameters>
      <Docs>
        <param name="recognizerInfo"><span data-ttu-id="b4702-162">特定の音声認識エンジンの情報。</span><span class="sxs-lookup"><span data-stu-id="b4702-162">The information for the specific speech recognizer.</span></span></param>
        <summary><span data-ttu-id="b4702-163">使用する認識エンジンを指定する <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> オブジェクトの情報を使用して、<see cref="T:System.Speech.Recognition.RecognizerInfo" /> クラスの新しいインスタンスを初期化します。</span><span class="sxs-lookup"><span data-stu-id="b4702-163">Initializes a new instance of the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> using the information in a <see cref="T:System.Speech.Recognition.RecognizerInfo" /> object to specify the recognizer to use.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-164">インストールされている音声認識機能のいずれかに対して、このクラスのインスタンスを作成できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-164">You can create an instance of this class for any of the installed speech recognizers.</span></span> <span data-ttu-id="b4702-165">インストールされているレコグナイザーに関する情報を取得するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-165">To get information about which recognizers are installed, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A> method.</span></span>  
  
 <span data-ttu-id="b4702-166">音声認識エンジンが認識を開始するには、少なくとも1つの音声認識文法を読み込み、認識エンジンの入力を構成する必要があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-166">Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</span></span>  
  
 <span data-ttu-id="b4702-167">文法を読み込むには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> メソッドを呼び出します。</span><span class="sxs-lookup"><span data-stu-id="b4702-167">To load a grammar, call the <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> method.</span></span>  
  
 <span data-ttu-id="b4702-168">オーディオ入力を構成するには、次のいずれかの方法を使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-168">To configure the audio input, use one of the following methods:</span></span>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-169">次の例は、基本的な音声認識を示し、英語をサポートする音声認識エンジンを初期化するコンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-169">The following example shows part of a console application that demonstrates basic speech recognition, and initializes a speech recognizer that supports the English language.</span></span>  
  
```csharp  
 using System;  
using System.Speech.Recognition;  
  
namespace SpeechRecognitionApp  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Select a speech recognizer that supports English.  
      RecognizerInfo info = null;  
      foreach (RecognizerInfo ri in SpeechRecognitionEngine.InstalledRecognizers())  
      {  
        if (ri.Culture.TwoLetterISOLanguageName.Equals("en"))  
        {  
          info = ri;  
          break;  
        }  
      }  
      if (info == null) return;  
  
      // Create the selected recognizer.  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(info))  
      {  
  
        // Create and load a dictation grammar.  
        recognizer.LoadGrammar(new DictationGrammar());  
  
        // Add a handler for the speech recognized event.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Configure input to the speech recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Start asynchronous, continuous speech recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
  
        // Keep the console window open.  
        while (true)  
        {  
          Console.ReadLine();  
        }  
      }  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Recognized text: " + e.Result.Text);  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognitionEngine (string recognizerId);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string recognizerId) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (recognizerId As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; SpeechRecognitionEngine(System::String ^ recognizerId);" />
      <MemberSignature Language="F#" Value="new System.Speech.Recognition.SpeechRecognitionEngine : string -&gt; System.Speech.Recognition.SpeechRecognitionEngine" Usage="new System.Speech.Recognition.SpeechRecognitionEngine recognizerId" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="recognizerId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="recognizerId"><span data-ttu-id="b4702-170">使用する音声レコグナイザーのトークン名。</span><span class="sxs-lookup"><span data-stu-id="b4702-170">The token name of the speech recognizer to use.</span></span></param>
        <summary><span data-ttu-id="b4702-171">使用する認識エンジンの名前を指定する文字列パラメーターを使用して、<see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> クラスの新しいインスタンスを初期化します。</span><span class="sxs-lookup"><span data-stu-id="b4702-171">Initializes a new instance of the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> class with a string parameter that specifies the name of the recognizer to use.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-172">レコグナイザーのトークン名は、レコグナイザーの <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A> プロパティによって返される <xref:System.Speech.Recognition.RecognizerInfo> オブジェクトの <xref:System.Speech.Recognition.RecognizerInfo.Id%2A> プロパティの値です。</span><span class="sxs-lookup"><span data-stu-id="b4702-172">The token name of the recognizer is the value of the <xref:System.Speech.Recognition.RecognizerInfo.Id%2A> property of the <xref:System.Speech.Recognition.RecognizerInfo> object returned by the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A> property of the recognizer.</span></span> <span data-ttu-id="b4702-173">インストールされているすべてのレコグナイザーのコレクションを取得するには、静的な <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-173">To get a collection of all the installed recognizers, use the static <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A> method.</span></span>  
  
 <span data-ttu-id="b4702-174">音声認識エンジンが認識を開始するには、少なくとも1つの音声認識文法を読み込み、認識エンジンの入力を構成する必要があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-174">Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</span></span>  
  
 <span data-ttu-id="b4702-175">文法を読み込むには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> メソッドを呼び出します。</span><span class="sxs-lookup"><span data-stu-id="b4702-175">To load a grammar, call the <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> method.</span></span>  
  
 <span data-ttu-id="b4702-176">オーディオ入力を構成するには、次のいずれかの方法を使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-176">To configure the audio input, use one of the following methods:</span></span>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-177">次の例では、基本的な音声認識を示し、Windows 用の音声認識エンジン 8.0 (英語) のインスタンスを作成するコンソールアプリケーションの一部を示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-177">The following example shows part of a console application that demonstrates basic speech recognition, and creates an instance of the Speech Recognizer 8.0 for Windows (English - US).</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SpeechRecognitionApp  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Create an instance of the Microsoft Speech Recognizer 8.0 for  
      // Windows (English - US).  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine("MS-1033-80-DESK"))  
      {  
  
        // Create and load a dictation grammar.  
        recognizer.LoadGrammar(new DictationGrammar());  
  
        // Add a handler for the speech recognized event.  
        recognizer.SpeechRecognized += new EventHandler(recognizer_SpeechRecognized);  
  
        // Configure input to the speech recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Start asynchronous, continuous speech recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
  
        // Keep the console window open.  
        while (true)  
        {  
          Console.ReadLine();  
        }  
      }  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Recognized text: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.ArgumentException"><span data-ttu-id="b4702-178">そのトークン名の音声認識機能はインストールされていないか、または <paramref name="recognizerId" /> が空の文字列 ("") です。</span><span class="sxs-lookup"><span data-stu-id="b4702-178">No speech recognizer with that token name is installed, or <paramref name="recognizerId" /> is the empty string ("").</span></span></exception>
        <exception cref="T:System.ArgumentNullException"><span data-ttu-id="b4702-179"><paramref name="recognizerId" /> が <see langword="null" /> です。</span><span class="sxs-lookup"><span data-stu-id="b4702-179"><paramref name="recognizerId" /> is <see langword="null" />.</span></span></exception>
      </Docs>
    </Member>
    <Member MemberName="AudioFormat">
      <MemberSignature Language="C#" Value="public System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioFormat As SpeechAudioFormatInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::AudioFormat::SpeechAudioFormatInfo ^ AudioFormat { System::Speech::AudioFormat::SpeechAudioFormatInfo ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioFormat : System.Speech.AudioFormat.SpeechAudioFormatInfo" Usage="System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.AudioFormat.SpeechAudioFormatInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-180"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> によって受け取られるオーディオの形式を取得します。</span><span class="sxs-lookup"><span data-stu-id="b4702-180">Gets the format of the audio being received by the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />.</span></span></summary>
        <value><span data-ttu-id="b4702-181"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> インスタンスへの入力時のオーディオの形式、または入力が構成されていないか null 入力に設定されている場合は <see langword="null" />。</span><span class="sxs-lookup"><span data-stu-id="b4702-181">The format of audio at the input to the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> instance, or <see langword="null" /> if the input is not configured or set to the null input.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-182">オーディオ入力を構成するには、次のいずれかの方法を使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-182">To configure the audio input, use one of the following methods:</span></span>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>  
  
-   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-183">次の例では、<xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat%2A> を使用して、オーディオ形式のデータを取得して表示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-183">The example below uses <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat%2A> to obtain and display audio format data.</span></span>  
  
```  
static void DisplayAudioDeviceFormat(Label label, SpeechRecognitionEngine recognitionEngine)   
{  
  
  if (recognitionEngine != null && label != null)   
  {  
    label.Text = String.Format("Encoding Format:         {0}\n" +  
          "AverageBytesPerSecond    {1}\n" +  
          "BitsPerSample            {2}\n" +  
          "BlockAlign               {3}\n" +  
          "ChannelCount             {4}\n" +  
          "SamplesPerSecond         {5}",  
          recognitionEngine.AudioFormat.EncodingFormat.ToString(),  
          recognitionEngine.AudioFormat.AverageBytesPerSecond,  
          recognitionEngine.AudioFormat.BitsPerSample,  
          recognitionEngine.AudioFormat.BlockAlign,  
          recognitionEngine.AudioFormat.ChannelCount,  
          recognitionEngine.AudioFormat.SamplesPerSecond);  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.AudioFormat.SpeechAudioFormatInfo" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat" />
      </Docs>
    </Member>
    <Member MemberName="AudioLevel">
      <MemberSignature Language="C#" Value="public int AudioLevel { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 AudioLevel" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioLevel As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int AudioLevel { int get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioLevel : int" Usage="System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-184"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> によって受け取られるオーディオのレベルを取得します。</span><span class="sxs-lookup"><span data-stu-id="b4702-184">Gets the level of the audio being received by the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />.</span></span></summary>
        <value><span data-ttu-id="b4702-185">音声認識エンジンへの入力のオーディオ レベル (0 ～ 100)。</span><span class="sxs-lookup"><span data-stu-id="b4702-185">The audio level of the input to the speech recognizer, from 0 through 100.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-186">値0は無音を表し、100は最大入力ボリュームを表します。</span><span class="sxs-lookup"><span data-stu-id="b4702-186">The value 0 represents silence, and 100 represents the maximum input volume.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      </Docs>
    </Member>
    <Member MemberName="AudioLevelUpdated">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; AudioLevelUpdated;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; AudioLevelUpdated" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioLevelUpdated As EventHandler(Of AudioLevelUpdatedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioLevelUpdatedEventArgs ^&gt; ^ AudioLevelUpdated;" />
      <MemberSignature Language="F#" Value="member this.AudioLevelUpdated : EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; " Usage="member this.AudioLevelUpdated : System.EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-187"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> がオーディオ入力のレベルを報告すると発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-187">Raised when the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> reports the level of its audio input.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-188"><xref:System.Speech.Recognition.SpeechRecognitionEngine> は、1秒間にこのイベントを複数回発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-188">The <xref:System.Speech.Recognition.SpeechRecognitionEngine> raises this event multiple times per second.</span></span> <span data-ttu-id="b4702-189">イベントが発生する頻度は、アプリケーションが実行されているコンピューターによって異なります。</span><span class="sxs-lookup"><span data-stu-id="b4702-189">The frequency with which the event is raised depends on the computer on which the application is running.</span></span>  
  
 <span data-ttu-id="b4702-190">イベント時にオーディオレベルを取得するには、関連付けられた <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>の <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A> プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-190">To get the audio level at the time of the event, use the <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A> property of the associated <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>.</span></span> <span data-ttu-id="b4702-191">認識エンジンへの入力の現在のオーディオレベルを取得するには、レコグナイザーの <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A> プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-191">To get the current audio level of the input to the recognizer, use the recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A> property.</span></span>  
  
 <span data-ttu-id="b4702-192"><xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated> デリゲートを作成する場合は、イベントを処理するメソッドを指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-192">When you create an <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated> delegate, you identify the method that will handle the event.</span></span> <span data-ttu-id="b4702-193">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="b4702-193">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="b4702-194">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-194">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="b4702-195">イベントハンドラーデリゲートの詳細については、「[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-195">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-196">次の例では、<xref:System.Speech.Recognition.SpeechRecognitionEngine> オブジェクトに <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated> イベントのハンドラーを追加します。</span><span class="sxs-lookup"><span data-stu-id="b4702-196">The following example adds a handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated> event to a <xref:System.Speech.Recognition.SpeechRecognitionEngine> object.</span></span> <span data-ttu-id="b4702-197">ハンドラーは、新しいオーディオレベルをコンソールに出力します。</span><span class="sxs-lookup"><span data-stu-id="b4702-197">The handler outputs the new audio level to the console.</span></span>  
  
```  
private SpeechRecognitionEngine recognizer;  
  
// Initialize the SpeechRecognitionEngine object.   
private void Initialize()  
{  
  recognizer = new SpeechRecognitionEngine();  
  
  // Add an event handler for the AudioLevelUpdated event.  
  recognizer.AudioLevelUpdated +=   
   new EventHandler<AudioLevelUpdatedEventArgs>(recognizer_AudioLevelUpdated);  
  
  // Add other initialization code here.  
  
}  
  
// Write the audio level to the console when the AudioLevelUpdated event is raised.  
void recognizer_AudioLevelUpdated(object sender, AudioLevelUpdatedEventArgs e)  
{  
  Console.WriteLine("The audio level is now: {0}.", e.AudioLevel);  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioLevelUpdatedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel" />
      </Docs>
    </Member>
    <Member MemberName="AudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan AudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan AudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan AudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioPosition : TimeSpan" Usage="System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-198"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> に入力を提供しているデバイスによって生成されているオーディオ ストリーム内の現在の位置を取得します。</span><span class="sxs-lookup"><span data-stu-id="b4702-198">Gets the current location in the audio stream being generated by the device that is providing input to the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />.</span></span></summary>
        <value><span data-ttu-id="b4702-199">入力デバイスによって生成されているオーディオ ストリームの現在の位置。</span><span class="sxs-lookup"><span data-stu-id="b4702-199">The current location in the audio stream being generated by the input device.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-200"><xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> プロパティは、生成されたオーディオストリーム内の入力デバイスの位置を参照します。</span><span class="sxs-lookup"><span data-stu-id="b4702-200">The <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> property references the input device's position in its generated audio stream.</span></span> <span data-ttu-id="b4702-201">これに対し、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> プロパティは、オーディオ入力内のレコグナイザーの位置を参照します。</span><span class="sxs-lookup"><span data-stu-id="b4702-201">By contrast, the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> property references the recognizer's position within its audio input.</span></span> <span data-ttu-id="b4702-202">これらの位置は異なる場合があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-202">These positions can be different.</span></span> <span data-ttu-id="b4702-203">たとえば、認識結果がまだ生成されていない認識エンジンが入力を受け取った場合、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> プロパティの値は <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> プロパティの値よりも小さくなります。</span><span class="sxs-lookup"><span data-stu-id="b4702-203">For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> property is less than the value of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> property.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-204">次の例では、プロセス内音声認識エンジンがディクテーションの文法を使用して音声入力を照合します。</span><span class="sxs-lookup"><span data-stu-id="b4702-204">In the following example, the in-process speech recognizer uses a dictation grammar to match speech input.</span></span> <span data-ttu-id="b4702-205"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> イベントのハンドラーは、音声認識エンジンが入力時に音声を検出したときに、<xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A> をコンソールに書き込みます。</span><span class="sxs-lookup"><span data-stu-id="b4702-205">A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> event writes to the console the <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>, and  <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A> when the speech recognizer detects speech at its input.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognition engine for US English.  
      using (recognizer = new SpeechRecognitionEngine(  
        new System.Globalization.CultureInfo("en-US")))  
      {  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Create a grammar for finding services in different cities.  
        Choices services = new Choices(new string[] { "restaurants", "hotels", "gas stations" });  
        Choices cities = new Choices(new string[] { "Seattle", "Boston", "Dallas" });  
  
        GrammarBuilder findServices = new GrammarBuilder("Find");  
        findServices.Append(services);  
        findServices.Append("near");  
        findServices.Append(cities);  
  
        // Create a Grammar object from the GrammarBuilder and load it to the recognizer.  
        Grammar servicesGrammar = new Grammar(findServices);  
        recognizer.LoadGrammarAsync(servicesGrammar);  
  
        // Add handlers for events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.SpeechDetected +=  
          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  
  
        // Start asynchronous recognition.  
        recognizer.RecognizeAsync();  
        Console.WriteLine("Starting asynchronous recognition...");  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Gather information about detected speech and write it to the console.  
    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Speech detected:");  
      Console.WriteLine("  Audio level: " + recognizer.AudioLevel);  
      Console.WriteLine("  Audio position at the event: " + e.AudioPosition);  
      Console.WriteLine("  Current audio position: " + recognizer.AudioPosition);  
      Console.WriteLine("  Current recognizer audio position: " +   
        recognizer.RecognizerAudioPosition);  
    }  
  
    // Write the text of the recognition result to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("\nSpeech recognized: " + e.Result.Text);  
  
      // Add event handler code here.  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="AudioSignalProblemOccurred">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; AudioSignalProblemOccurred;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; AudioSignalProblemOccurred" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioSignalProblemOccurred As EventHandler(Of AudioSignalProblemOccurredEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioSignalProblemOccurredEventArgs ^&gt; ^ AudioSignalProblemOccurred;" />
      <MemberSignature Language="F#" Value="member this.AudioSignalProblemOccurred : EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; " Usage="member this.AudioSignalProblemOccurred : System.EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-206"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> がオーディオ信号の問題を検出したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-206">Raised when the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> detects a problem in the audio signal.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-207">発生した問題を取得するには、関連付けられている <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>の <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A> プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-207">To get which problem occurred, use the <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A> property of the associated <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>.</span></span>  
  
 <span data-ttu-id="b4702-208"><xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred> デリゲートを作成する場合は、イベントを処理するメソッドを指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-208">When you create an <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred> delegate, you identify the method that will handle the event.</span></span> <span data-ttu-id="b4702-209">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="b4702-209">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="b4702-210">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-210">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="b4702-211">イベントハンドラーデリゲートの詳細については、「[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-211">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-212">次の例では、<xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred> イベントに関する情報を収集するイベントハンドラーを定義します。</span><span class="sxs-lookup"><span data-stu-id="b4702-212">The following example defines an event handler that gathers information about an <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred> event.</span></span>  
  
```  
private SpeechRecognitionEngine recognizer;  
  
// Initialize the speech recognition engine.  
private void Initialize()  
{  
  recognizer = new SpeechRecognitionEngine();  
  
  // Add a handler for the AudioSignalProblemOccurred event.  
  recognizer.AudioSignalProblemOccurred +=   
    new EventHandler<AudioSignalProblemOccurredEventArgs>(  
      recognizer_AudioSignalProblemOccurred);  
}  
  
// Gather information when the AudioSignalProblemOccurred event is raised.  
void recognizer_AudioSignalProblemOccurred(object sender, AudioSignalProblemOccurredEventArgs e)  
{  
  StringBuilder details = new StringBuilder();  
  
  details.AppendLine("Audio signal problem information:");  
  details.AppendFormat(  
    " Audio level:               {0}" + Environment.NewLine +  
    " Audio position:            {1}" + Environment.NewLine +  
    " Audio signal problem:      {2}" + Environment.NewLine +  
    " Recognition engine audio position: {3}" + Environment.NewLine,  
    e.AudioLevel, e.AudioPosition,  e.AudioSignalProblem,  
    e.recoEngineAudioPosition);  
  
  // Insert additional event handler code here.  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioSignalProblem" />
        <altmember cref="T:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs" />
      </Docs>
    </Member>
    <Member MemberName="AudioState">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.AudioState AudioState { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.AudioState AudioState" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioState" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioState As AudioState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::AudioState AudioState { System::Speech::Recognition::AudioState get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioState : System.Speech.Recognition.AudioState" Usage="System.Speech.Recognition.SpeechRecognitionEngine.AudioState" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.AudioState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-213"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> によって受け取られるオーディオの状態を取得します。</span><span class="sxs-lookup"><span data-stu-id="b4702-213">Gets the state of the audio being received by the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />.</span></span></summary>
        <value><span data-ttu-id="b4702-214">音声レコグナイザーへのオーディオ入力の状態。</span><span class="sxs-lookup"><span data-stu-id="b4702-214">The state of the audio input to the speech recognizer.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-215"><xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A> プロパティは、<xref:System.Speech.Recognition.AudioState> 列挙体のメンバーを持つオーディオ状態を表します。</span><span class="sxs-lookup"><span data-stu-id="b4702-215">The <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A> property represents the audio state with a member of the <xref:System.Speech.Recognition.AudioState> enumeration.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioState" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioState" />
      </Docs>
    </Member>
    <Member MemberName="AudioStateChanged">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; AudioStateChanged;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioStateChangedEventArgs&gt; AudioStateChanged" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioStateChanged As EventHandler(Of AudioStateChangedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioStateChangedEventArgs ^&gt; ^ AudioStateChanged;" />
      <MemberSignature Language="F#" Value="member this.AudioStateChanged : EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; " Usage="member this.AudioStateChanged : System.EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-216">オーディオの状態変化が <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> によって受け取られるときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-216">Raised when the state changes in the audio being received by the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-217">イベント時にオーディオの状態を取得するには、関連付けられた <xref:System.Speech.Recognition.AudioStateChangedEventArgs>の <xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-217">To get the audio state at the time of the event, use the <xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> property of the associated <xref:System.Speech.Recognition.AudioStateChangedEventArgs>.</span></span> <span data-ttu-id="b4702-218">認識エンジンへの入力の現在のオーディオの状態を取得するには、レコグナイザーの <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A> プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-218">To get the current audio state of the input to the recognizer, use the recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A> property.</span></span> <span data-ttu-id="b4702-219">オーディオ状態の詳細については、「<xref:System.Speech.Recognition.AudioState> 列挙型」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-219">For more information about audio state, see the <xref:System.Speech.Recognition.AudioState> enumeration.</span></span>  
  
 <span data-ttu-id="b4702-220"><xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged> デリゲートを作成する場合は、イベントを処理するメソッドを指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-220">When you create an <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged> delegate, you identify the method that will handle the event.</span></span> <span data-ttu-id="b4702-221">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="b4702-221">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="b4702-222">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-222">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="b4702-223">イベントハンドラーデリゲートの詳細については、「[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-223">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-224">次の例では、<xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged> イベントのハンドラーを使用して、<xref:System.Speech.Recognition.AudioState> 列挙体のメンバーを使用して、変更するたびに、レコグナイザーの新しい <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A> をコンソールに書き込みます。</span><span class="sxs-lookup"><span data-stu-id="b4702-224">The following example uses a handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged> event to write the recognizer's new <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A> to the console each time it changes, using a member of the <xref:System.Speech.Recognition.AudioState> enumeration.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize an in-process speech recognition engine.  
    {  
      using (SpeechRecognitionEngine recognizer =  
         new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US")))  
      {  
  
        // Create and load a grammar.  
        Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
        GrammarBuilder farm = new GrammarBuilder("On this farm he had a");  
        farm.Append(animals);  
        Grammar farmAnimals = new Grammar(farm);  
        farmAnimals.Name = "Farm";  
        recognizer.LoadGrammar(farmAnimals);  
  
        // Attach event handlers.  
        recognizer.AudioStateChanged +=  
          new EventHandler<AudioStateChangedEventArgs>(recognizer_AudioStateChanged);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Set the input to the recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Start recognition.  
        recognizer.RecognizeAsync();  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null && e.Result.Text != null)  
      {  
        Console.WriteLine();  
        Console.WriteLine("  Recognized text =  {0}", e.Result.Text);  
        Console.WriteLine();  
      }  
      else  
      {  
        Console.WriteLine("  Recognized text not available.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Done.");  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the AudioStateChanged event.  
    static void recognizer_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  
    {  
      Console.WriteLine("The new audio state is: " + e.AudioState);  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioState" />
        <altmember cref="T:System.Speech.Recognition.AudioStateChangedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioState" />
      </Docs>
    </Member>
    <Member MemberName="BabbleTimeout">
      <MemberSignature Language="C#" Value="public TimeSpan BabbleTimeout { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan BabbleTimeout" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout" />
      <MemberSignature Language="VB.NET" Value="Public Property BabbleTimeout As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan BabbleTimeout { TimeSpan get(); void set(TimeSpan value); };" />
      <MemberSignature Language="F#" Value="member this.BabbleTimeout : TimeSpan with get, set" Usage="System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>System.ComponentModel.EditorBrowsable(System.ComponentModel.EditorBrowsableState.Advanced)</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-225"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> が認識を終了する前にバックグラウンド ノイズのみを含む入力を受け入れる時間間隔を取得または設定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-225">Gets or sets the time interval during which a <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> accepts input containing only background noise, before finalizing recognition.</span></span></summary>
        <value><span data-ttu-id="b4702-226">時間の間隔。</span><span class="sxs-lookup"><span data-stu-id="b4702-226">The duration of the time interval.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-227">各音声認識エンジンには、無音と音声を区別するためのアルゴリズムが用意されています。</span><span class="sxs-lookup"><span data-stu-id="b4702-227">Each speech recognizer has an algorithm to distinguish between silence and speech.</span></span> <span data-ttu-id="b4702-228">認識エンジンは、どのレコグナイザーが読み込まれ、有効になっている音声認識文法の初期ルールとも一致しない、無音でない入力をバックグラウンドノイズとして分類します。</span><span class="sxs-lookup"><span data-stu-id="b4702-228">The recognizer classifies as background noise any non-silence input that does not match the initial rule of any of the recognizer's loaded and enabled speech recognition grammars.</span></span> <span data-ttu-id="b4702-229">バブルのタイムアウト間隔内で、レコグナイザーがバックグラウンドノイズと無音のみを受信した場合、認識エンジンはその認識操作を終了します。</span><span class="sxs-lookup"><span data-stu-id="b4702-229">If the recognizer receives only background noise and silence within the babble timeout interval, then the recognizer finalizes that recognition operation.</span></span>  
  
-   <span data-ttu-id="b4702-230">非同期認識操作の場合、レコグナイザーは <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> イベントを発生させ、<xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=nameWithType> プロパティは `true`、<xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=nameWithType> プロパティは `null`ます。</span><span class="sxs-lookup"><span data-stu-id="b4702-230">For asynchronous recognition operations, the recognizer raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> event, where the <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=nameWithType> property is `true`, and the <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=nameWithType> property is `null`.</span></span>  
  
-   <span data-ttu-id="b4702-231">同期認識操作とエミュレーションでは、認識エンジンは有効な <xref:System.Speech.Recognition.RecognitionResult>ではなく `null`を返します。</span><span class="sxs-lookup"><span data-stu-id="b4702-231">For synchronous recognition operations and emulation, the recognizer returns `null`, instead of a valid <xref:System.Speech.Recognition.RecognitionResult>.</span></span>  
  
 <span data-ttu-id="b4702-232">バブル timeout 期間が0に設定されている場合、レコグナイザーはバブル timeout チェックを実行しません。</span><span class="sxs-lookup"><span data-stu-id="b4702-232">If the babble timeout period is set to 0, the recognizer does not perform a babble timeout check.</span></span> <span data-ttu-id="b4702-233">タイムアウト間隔には、負でない値を指定できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-233">The timeout interval can be any non-negative value.</span></span> <span data-ttu-id="b4702-234">既定値は0秒です。</span><span class="sxs-lookup"><span data-stu-id="b4702-234">The default is 0 seconds.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-235">次の例は、音声認識を開始する前に <xref:System.Speech.Recognition.SpeechRecognitionEngine> の <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> と <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> のプロパティを設定する基本的な音声認識を示す、コンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-235">The following example shows part of a console application that demonstrates basic speech recognition that sets the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> before initiating speech recognition.</span></span> <span data-ttu-id="b4702-236">音声認識エンジンの <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged> イベントと <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> イベントのハンドラーは、イベント情報をコンソールに出力して、<xref:System.Speech.Recognition.SpeechRecognitionEngine> の <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> プロパティが認識操作にどのように影響するかを示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-236">Handlers for the speech recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> events output event information to the console to demonstrate how the <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> affect recognition operations.</span></span>  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
  
namespace SpeechRecognitionApp  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognizer.  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(  
          new System.Globalization.CultureInfo("en-US")))  
      {  
        // Load a Grammar object.  
        recognizer.LoadGrammar(CreateServicesGrammar("FindServices"));  
  
        // Add event handlers.  
        recognizer.AudioStateChanged +=  
          new EventHandler<AudioStateChangedEventArgs>(  
            AudioStateChangedHandler);  
        recognizer.RecognizeCompleted +=  
          new EventHandler<RecognizeCompletedEventArgs>(  
            RecognizeCompletedHandler);  
  
        // Configure input to the speech recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(3);  
        recognizer.BabbleTimeout = TimeSpan.FromSeconds(2);  
        recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1);  
        recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.5);  
  
        Console.WriteLine("BabbleTimeout: {0}", recognizer.BabbleTimeout);  
        Console.WriteLine("InitialSilenceTimeout: {0}", recognizer.InitialSilenceTimeout);  
        Console.WriteLine("EndSilenceTimeout: {0}", recognizer.EndSilenceTimeout);  
        Console.WriteLine("EndSilenceTimeoutAmbiguous: {0}", recognizer.EndSilenceTimeoutAmbiguous);  
        Console.WriteLine();  
  
        // Start asynchronous speech recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Single);  
  
        // Keep the console window open.  
        while (true)  
        {  
          Console.ReadLine();  
        }  
      }  
    }  
  
    // Create a grammar and build it into a Grammar object.   
    static Grammar CreateServicesGrammar(string grammarName)  
    {  
  
      // Create a grammar for finding services in different cities.  
      Choices services = new Choices(new string[] { "restaurants", "hotels", "gas stations" });  
      Choices cities = new Choices(new string[] { "Seattle", "Boston", "Dallas" });  
  
      GrammarBuilder findServices = new GrammarBuilder("Find");  
      findServices.Append(services);  
      findServices.Append("near");  
      findServices.Append(cities);  
  
      // Create a Grammar object from the GrammarBuilder. 
      Grammar servicesGrammar = new Grammar(findServices);  
      servicesGrammar.Name = ("FindServices");  
      return servicesGrammar;  
    }  
  
    // Handle the AudioStateChanged event.  
    static void AudioStateChangedHandler(  
      object sender, AudioStateChangedEventArgs e)  
    {  
      Console.WriteLine("AudioStateChanged ({0}): {1}",  
        DateTime.Now.ToString("mm:ss.f"), e.AudioState);  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void RecognizeCompletedHandler(  
      object sender, RecognizeCompletedEventArgs e)  
    {  
      Console.WriteLine("RecognizeCompleted ({0}):",  
        DateTime.Now.ToString("mm:ss.f"));  
  
      string resultText;  
      if (e.Result != null) { resultText = e.Result.Text; }  
      else { resultText = "<null>"; }  
  
      Console.WriteLine(  
        " BabbleTimeout: {0}; InitialSilenceTimeout: {1}; Result text: {2}",  
        e.BabbleTimeout, e.InitialSilenceTimeout, resultText);  
      if (e.Error != null)  
      {  
        Console.WriteLine(" Exception message: ", e.Error.Message);  
      }  
  
      // Start the next asynchronous recognition operation.  
      ((SpeechRecognitionEngine)sender).RecognizeAsync(RecognizeMode.Single);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.ArgumentOutOfRangeException"><span data-ttu-id="b4702-237">このプロパティが 0 秒未満の値に設定されています。</span><span class="sxs-lookup"><span data-stu-id="b4702-237">This property is set to less than 0 seconds.</span></span></exception>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      </Docs>
    </Member>
    <MemberGroup MemberName="Dispose">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary><span data-ttu-id="b4702-238"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> オブジェクトを破棄します。</span><span class="sxs-lookup"><span data-stu-id="b4702-238">Disposes the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> object.</span></span></summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="public void Dispose ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance void Dispose() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.Dispose" />
      <MemberSignature Language="VB.NET" Value="Public Sub Dispose ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; virtual void Dispose();" />
      <MemberSignature Language="F#" Value="abstract member Dispose : unit -&gt; unit&#xA;override this.Dispose : unit -&gt; unit" Usage="speechRecognitionEngine.Dispose " />
      <MemberType>Method</MemberType>
      <Implements>
        <InterfaceMember>M:System.IDisposable.Dispose</InterfaceMember>
      </Implements>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary><span data-ttu-id="b4702-239"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> オブジェクトを破棄します。</span><span class="sxs-lookup"><span data-stu-id="b4702-239">Disposes the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> object.</span></span></summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="protected virtual void Dispose (bool disposing);" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig newslot virtual instance void Dispose(bool disposing) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)" />
      <MemberSignature Language="VB.NET" Value="Protected Overridable Sub Dispose (disposing As Boolean)" />
      <MemberSignature Language="C++ CLI" Value="protected:&#xA; virtual void Dispose(bool disposing);" />
      <MemberSignature Language="F#" Value="abstract member Dispose : bool -&gt; unit&#xA;override this.Dispose : bool -&gt; unit" Usage="speechRecognitionEngine.Dispose disposing" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="disposing" Type="System.Boolean" />
      </Parameters>
      <Docs>
        <param name="disposing"><span data-ttu-id="b4702-240">マネージド リソースとアンマネージド リソースの両方を解放する場合は <see langword="true" />。アンマネージド リソースだけを解放する場合は <see langword="false" />。</span><span class="sxs-lookup"><span data-stu-id="b4702-240"><see langword="true" /> to release both managed and unmanaged resources; <see langword="false" /> to release only unmanaged resources.</span></span></param>
        <summary><span data-ttu-id="b4702-241"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> オブジェクトを破棄し、セッション中に使用するリソースを解放します。</span><span class="sxs-lookup"><span data-stu-id="b4702-241">Disposes the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> object and releases resources used during the session.</span></span></summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="EmulateRecognize">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary><span data-ttu-id="b4702-242">同期音声認識に音声ではなくテキストを使用して、音声認識エンジンに対する入力をエミュレートします。</span><span class="sxs-lookup"><span data-stu-id="b4702-242">Emulates input to the speech recognizer, using text in place of audio for synchronous speech recognition.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-243">これらのメソッドは、システムオーディオ入力をバイパスし、<xref:System.String> オブジェクトまたは <xref:System.Speech.Recognition.RecognizedWordUnit> オブジェクトの配列として認識エンジンにテキストを提供します。</span><span class="sxs-lookup"><span data-stu-id="b4702-243">These methods bypass the system audio input and provide text to the recognizer as <xref:System.String> objects or as an array of <xref:System.Speech.Recognition.RecognizedWordUnit> objects.</span></span> <span data-ttu-id="b4702-244">これは、アプリケーションまたは文法をテストまたはデバッグするときに役立ちます。</span><span class="sxs-lookup"><span data-stu-id="b4702-244">This can be helpful when you are testing or debugging an application or grammar.</span></span> <span data-ttu-id="b4702-245">たとえば、エミュレーションを使用して、単語が文法に含まれるかどうか、および単語が認識されたときにどのようなセマンティクスが返されるかを判断できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-245">For example, you can use emulation to determine whether a word is in a grammar and what semantics are returned when the word is recognized.</span></span> <span data-ttu-id="b4702-246"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> メソッドを使用して、エミュレーション操作中に音声認識エンジンへのオーディオ入力を無効にします。</span><span class="sxs-lookup"><span data-stu-id="b4702-246">Use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> method to disable audio input to the speech recognition engine during emulation operations.</span></span>  
  
 <span data-ttu-id="b4702-247">音声認識エンジンは、認識操作がエミュレートされていないかのように、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> のイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-247">The speech recognizer raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> events as if the recognition operation is not emulated.</span></span> <span data-ttu-id="b4702-248">レコグナイザーは、新しい行と余分な空白文字を無視し、句読点をリテラル入力として扱います。</span><span class="sxs-lookup"><span data-stu-id="b4702-248">The recognizer ignores new lines and extra white space and treats punctuation as literal input.</span></span>  
  
> [!NOTE]
>  <span data-ttu-id="b4702-249">エミュレートされた入力への応答として音声認識エンジンによって生成される <xref:System.Speech.Recognition.RecognitionResult> オブジェクトは、その <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> プロパティに `null` の値を持ちます。</span><span class="sxs-lookup"><span data-stu-id="b4702-249">The <xref:System.Speech.Recognition.RecognitionResult> object generated by the speech recognizer in response to emulated input has a value of `null` for its <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> property.</span></span>  
  
 <span data-ttu-id="b4702-250">非同期認識をエミュレートするには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-250">To emulate asynchronous recognition, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(string inputText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Function EmulateRecognize (inputText As String) As RecognitionResult" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(System::String ^ inputText);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : string -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognitionEngine.EmulateRecognize inputText" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="inputText"><span data-ttu-id="b4702-251">認識操作の入力。</span><span class="sxs-lookup"><span data-stu-id="b4702-251">The input for the recognition operation.</span></span></param>
        <summary><span data-ttu-id="b4702-252">同期音声認識に音声ではなくテキストを使用して、音声認識エンジンに対する語句の入力をエミュレートします。</span><span class="sxs-lookup"><span data-stu-id="b4702-252">Emulates input of a phrase to the speech recognizer, using text in place of audio for synchronous speech recognition.</span></span></summary>
        <returns><span data-ttu-id="b4702-253">認識操作の結果。操作が不適切だったり、認識エンジンが有効でない場合は <see langword="null" />。</span><span class="sxs-lookup"><span data-stu-id="b4702-253">The result for the recognition operation, or <see langword="null" /> if the operation is not successful or the recognizer is not enabled.</span></span></returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-254">音声認識エンジンは、認識操作がエミュレートされていないかのように、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> のイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-254">The speech recognizer raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> events as if the recognition operation is not emulated.</span></span>  
  
 <span data-ttu-id="b4702-255">Vista および Windows 7 に付属しているレコグナイザーは、文法規則を入力語句に適用するときに大文字と小文字の区別を無視します。</span><span class="sxs-lookup"><span data-stu-id="b4702-255">The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</span></span> <span data-ttu-id="b4702-256">この種類の比較の詳細については、<xref:System.Globalization.CompareOptions> 列挙値 <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> と <xref:System.Globalization.CompareOptions.IgnoreWidth>を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-256">For more information about this type of comparison, see the <xref:System.Globalization.CompareOptions> enumeration values <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> and <xref:System.Globalization.CompareOptions.IgnoreWidth>.</span></span> <span data-ttu-id="b4702-257">また、このレコグナイザーは新しい行と余分な空白を無視し、句読点をリテラル入力として扱います。</span><span class="sxs-lookup"><span data-stu-id="b4702-257">The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-258">次のコード例は、エミュレートされた入力、関連する認識結果、音声認識エンジンによって発生した関連イベントを示すコンソールアプリケーションの一部です。</span><span class="sxs-lookup"><span data-stu-id="b4702-258">The code example below is part of a console application that demonstrates emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</span></span> <span data-ttu-id="b4702-259">この例では、次の出力が生成されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-259">The example generates the following output.</span></span>  
  
```  
TestRecognize("Smith")...  
 SpeechDetected event raised.  
 SpeechRecognized event raised.  
  Grammar = Smith; Text = Smith  
...Recognition result text = Smith  
  
TestRecognize("Jones")...  
 SpeechDetected event raised.  
 SpeechRecognized event raised.  
  Grammar = Jones; Text = Jones  
...Recognition result text = Jones  
  
TestRecognize("Mister")...  
 SpeechDetected event raised.  
 SpeechHypothesized event raised.  
  Grammar = Smith; Text = mister  
 SpeechRecognitionRejected event raised.  
  Grammar = <not available>; Text =  
...No recognition result.  
  
TestRecognize("Mister Smith")...  
 SpeechDetected event raised.  
 SpeechRecognized event raised.  
  Grammar = Smith; Text = mister Smith  
...Recognition result text = mister Smith  
  
press any key to exit...  
```  
  
```csharp  
  
using System;  
using System.Globalization;  
using System.Speech.Recognition;  
  
namespace Sre_EmulateRecognize  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Create an in-process speech recognizer for the en-US locale.  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(new CultureInfo("en-US")))  
      {  
  
        // Load grammars.  
        recognizer.LoadGrammar(CreateNameGrammar("Smith"));  
        recognizer.LoadGrammar(CreateNameGrammar("Jones"));  
  
        // Disable audio input to the recognizer.  
        recognizer.SetInputToNull();  
  
        // Add handlers for events raised by the EmulateRecognize method.  
        recognizer.SpeechDetected +=  
          new EventHandler<SpeechDetectedEventArgs>(  
            SpeechDetectedHandler);  
        recognizer.SpeechHypothesized +=  
          new EventHandler<SpeechHypothesizedEventArgs>(  
            SpeechHypothesizedHandler);  
        recognizer.SpeechRecognitionRejected +=  
          new EventHandler<SpeechRecognitionRejectedEventArgs>(  
            SpeechRecognitionRejectedHandler);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
  
        // Start four synchronous emulated recognition operations.  
        TestRecognize(recognizer, "Smith");  
        TestRecognize(recognizer, "Jones");  
        TestRecognize(recognizer, "Mister");  
        TestRecognize(recognizer, "Mister Smith");  
      }  
  
      Console.WriteLine("press any key to exit...");  
      Console.ReadKey(true);  
    }  
  
    // Create a simple name grammar.  
    // Set the grammar name to the surname.  
    private static Grammar CreateNameGrammar(string surname)  
    {  
      GrammarBuilder builder = new GrammarBuilder("mister", 0, 1);  
      builder.Append(surname);  
  
      Grammar nameGrammar = new Grammar(builder);  
      nameGrammar.Name = surname;  
  
      return nameGrammar;  
    }  
  
    // Send emulated input to the recognizer for synchronous recognition.  
    private static void TestRecognize(  
      SpeechRecognitionEngine recognizer, string input)  
    {  
      Console.WriteLine("TestRecognize(\"{0}\")...", input);  
      RecognitionResult result =  
        recognizer.EmulateRecognize(input,CompareOptions.IgnoreCase);  
      if (result != null)  
      {  
        Console.WriteLine("...Recognition result text = {0}",  
          result.Text ?? "<null>");  
      }  
      else  
      {  
        Console.WriteLine("...No recognition result.");  
      }  
      Console.WriteLine();  
    }  
  
    static void SpeechDetectedHandler(  
      object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine(" SpeechDetected event raised.");  
    }  
  
    // Handle events.  
    static void SpeechHypothesizedHandler(  
      object sender, SpeechHypothesizedEventArgs e)  
    {  
      Console.WriteLine(" SpeechHypothesized event raised.");  
      if (e.Result != null)  
      {  
        Console.WriteLine("  Grammar = {0}; Text = {1}",  
          e.Result.Grammar.Name ?? "<none>", e.Result.Text);  
      }  
      else  
      {  
        Console.WriteLine("  No recognition result available.");  
      }  
    }  
  
    static void SpeechRecognitionRejectedHandler(  
      object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine(" SpeechRecognitionRejected event raised.");  
      if (e.Result != null)  
      {  
        string grammarName;  
        if (e.Result.Grammar != null)  
        {  
          grammarName = e.Result.Grammar.Name ?? "<none>";  
        }  
        else  
        {  
          grammarName = "<not available>";  
        }  
        Console.WriteLine("  Grammar = {0}; Text = {1}",  
          grammarName, e.Result.Text);  
      }  
      else  
      {  
        Console.WriteLine("  No recognition result available.");  
      }  
    }  
  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine(" SpeechRecognized event raised.");  
      if (e.Result != null)  
      {  
        Console.WriteLine("  Grammar = {0}; Text = {1}",  
          e.Result.Grammar.Name ?? "<none>", e.Result.Text);  
      }  
      else  
      {  
        Console.WriteLine("  No recognition result available.");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.InvalidOperationException"><span data-ttu-id="b4702-260">認識エンジンに読み込まれている音声認識文法がありません。</span><span class="sxs-lookup"><span data-stu-id="b4702-260">The recognizer has no speech recognition grammars loaded.</span></span></exception>
        <exception cref="T:System.ArgumentNullException"><span data-ttu-id="b4702-261"><paramref name="inputText" /> が <see langword="null" /> です。</span><span class="sxs-lookup"><span data-stu-id="b4702-261"><paramref name="inputText" /> is <see langword="null" />.</span></span></exception>
        <exception cref="T:System.ArgumentException"><span data-ttu-id="b4702-262"><paramref name="inputText" /> が空の文字列 ("") です。</span><span class="sxs-lookup"><span data-stu-id="b4702-262"><paramref name="inputText" /> is the empty string ("").</span></span></exception>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(class System.Speech.Recognition.RecognizedWordUnit[] wordUnits, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(cli::array &lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ wordUnits, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : System.Speech.Recognition.RecognizedWordUnit[] * System.Globalization.CompareOptions -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognitionEngine.EmulateRecognize (wordUnits, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="wordUnits" Type="System.Speech.Recognition.RecognizedWordUnit[]" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="wordUnits"><span data-ttu-id="b4702-263">認識操作のための必要を格納する単語単位の配列。</span><span class="sxs-lookup"><span data-stu-id="b4702-263">An array of word units that contains the input for the recognition operation.</span></span></param>
        <param name="compareOptions"><span data-ttu-id="b4702-264">エミュレートされた認識操作に使用する比較の種類を示す列挙値のビットごとの組み合わせ。</span><span class="sxs-lookup"><span data-stu-id="b4702-264">A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</span></span></param>
        <summary><span data-ttu-id="b4702-265">同期音声認識にオーディオではなくテキストを使用して、音声認識エンジンに対する特定の語の入力をエミュレートし、語と読み込まれている音声認識文法との間で認識エンジンが Unicode 比較をどのように行うかを指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-265">Emulates input of specific words to the speech recognizer, using text in place of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</span></span></summary>
        <returns><span data-ttu-id="b4702-266">認識操作の結果。操作が不適切だったり、認識エンジンが有効でない場合は <see langword="null" />。</span><span class="sxs-lookup"><span data-stu-id="b4702-266">The result for the recognition operation, or <see langword="null" /> if the operation is not successful or the recognizer is not enabled.</span></span></returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-267">音声認識エンジンは、認識操作がエミュレートされていないかのように、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> のイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-267">The speech recognizer raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> events as if the recognition operation is not emulated.</span></span>  
  
 <span data-ttu-id="b4702-268">認識エンジンは、文法規則を入力語句に適用するときに `compareOptions` を使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-268">The recognizer uses `compareOptions` when it applies grammar rules to the input phrase.</span></span> <span data-ttu-id="b4702-269"><xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> または <xref:System.Globalization.CompareOptions.IgnoreCase> の値が存在する場合、Vista および Windows 7 に付属しているレコグナイザーは、大文字小文字を区別しません。</span><span class="sxs-lookup"><span data-stu-id="b4702-269">The recognizers that ship with Vista and Windows 7 ignore case if the <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> or <xref:System.Globalization.CompareOptions.IgnoreCase> value is present.</span></span> <span data-ttu-id="b4702-270">認識エンジンは、文字幅を常に無視し、かなの種類を無視しません。</span><span class="sxs-lookup"><span data-stu-id="b4702-270">The recognizer always ignores the character width and never ignores the Kana type.</span></span> <span data-ttu-id="b4702-271">また、このレコグナイザーは、新しい行と余分な空白を無視し、句読点をリテラル入力として扱います。</span><span class="sxs-lookup"><span data-stu-id="b4702-271">The recognizer also ignores new lines and extra white space and treats punctuation as literal input.</span></span> <span data-ttu-id="b4702-272">文字幅とかなの種類の詳細については、<xref:System.Globalization.CompareOptions> 列挙体を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-272">For more information about character width and Kana type, see the <xref:System.Globalization.CompareOptions> enumeration.</span></span>  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.InvalidOperationException"><span data-ttu-id="b4702-273">認識エンジンに読み込まれている音声認識文法がありません。</span><span class="sxs-lookup"><span data-stu-id="b4702-273">The recognizer has no speech recognition grammars loaded.</span></span></exception>
        <exception cref="T:System.ArgumentNullException"><span data-ttu-id="b4702-274"><paramref name="wordUnits" /> が <see langword="null" /> です。</span><span class="sxs-lookup"><span data-stu-id="b4702-274"><paramref name="wordUnits" /> is <see langword="null" />.</span></span></exception>
        <exception cref="T:System.ArgumentException"><span data-ttu-id="b4702-275"><paramref name="wordUnits" /> は 1 つ以上の <see langword="null" /> 要素を含みます。</span><span class="sxs-lookup"><span data-stu-id="b4702-275"><paramref name="wordUnits" /> contains one or more <see langword="null" /> elements.</span></span></exception>
        <exception cref="T:System.NotSupportedException"><span data-ttu-id="b4702-276"><paramref name="compareOptions" /> は <see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" />、<see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" />、または <see cref="F:System.Globalization.CompareOptions.StringSort" /> フラグを含みます。</span><span class="sxs-lookup"><span data-stu-id="b4702-276"><paramref name="compareOptions" /> contains the <see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" />, <see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" />, or <see cref="F:System.Globalization.CompareOptions.StringSort" /> flag.</span></span></exception>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(string inputText, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(System::String ^ inputText, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : string * System.Globalization.CompareOptions -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognitionEngine.EmulateRecognize (inputText, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="inputText"><span data-ttu-id="b4702-277">認識操作の入力語句。</span><span class="sxs-lookup"><span data-stu-id="b4702-277">The input phrase for the recognition operation.</span></span></param>
        <param name="compareOptions"><span data-ttu-id="b4702-278">エミュレートされた認識操作に使用する比較の種類を示す列挙値のビットごとの組み合わせ。</span><span class="sxs-lookup"><span data-stu-id="b4702-278">A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</span></span></param>
        <summary><span data-ttu-id="b4702-279">同期音声認識にオーディオではなくテキストを使用して、音声認識エンジンに対するフレーズの入力をエミュレートし、フレーズと読み込まれている音声認識文法との間で認識エンジンが Unicode 比較をどのように行うかを指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-279">Emulates input of a phrase to the speech recognizer, using text in place of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</span></span></summary>
        <returns><span data-ttu-id="b4702-280">認識操作の結果。操作が不適切だったり、認識エンジンが有効でない場合は <see langword="null" />。</span><span class="sxs-lookup"><span data-stu-id="b4702-280">The result for the recognition operation, or <see langword="null" /> if the operation is not successful or the recognizer is not enabled.</span></span></returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-281">音声認識エンジンは、認識操作がエミュレートされていないかのように、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> のイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-281">The speech recognizer raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> events as if the recognition operation is not emulated.</span></span>  
  
 <span data-ttu-id="b4702-282">認識エンジンは、文法規則を入力語句に適用するときに `compareOptions` を使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-282">The recognizer uses `compareOptions` when it applies grammar rules to the input phrase.</span></span> <span data-ttu-id="b4702-283"><xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> または <xref:System.Globalization.CompareOptions.IgnoreCase> の値が存在する場合、Vista および Windows 7 に付属しているレコグナイザーは、大文字小文字を区別しません。</span><span class="sxs-lookup"><span data-stu-id="b4702-283">The recognizers that ship with Vista and Windows 7 ignore case if the <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> or <xref:System.Globalization.CompareOptions.IgnoreCase> value is present.</span></span> <span data-ttu-id="b4702-284">認識エンジンは、文字幅を常に無視し、かなの種類を無視しません。</span><span class="sxs-lookup"><span data-stu-id="b4702-284">The recognizer always ignores the character width and never ignores the Kana type.</span></span> <span data-ttu-id="b4702-285">また、このレコグナイザーは、新しい行と余分な空白を無視し、句読点をリテラル入力として扱います。</span><span class="sxs-lookup"><span data-stu-id="b4702-285">The recognizer also ignores new lines and extra white space and treats punctuation as literal input.</span></span> <span data-ttu-id="b4702-286">文字幅とかなの種類の詳細については、<xref:System.Globalization.CompareOptions> 列挙体を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-286">For more information about character width and Kana type, see the <xref:System.Globalization.CompareOptions> enumeration.</span></span>  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.InvalidOperationException"><span data-ttu-id="b4702-287">認識エンジンに読み込まれている音声認識文法がありません。</span><span class="sxs-lookup"><span data-stu-id="b4702-287">The recognizer has no speech recognition grammars loaded.</span></span></exception>
        <exception cref="T:System.ArgumentNullException"><span data-ttu-id="b4702-288"><paramref name="inputText" /> が <see langword="null" /> です。</span><span class="sxs-lookup"><span data-stu-id="b4702-288"><paramref name="inputText" /> is <see langword="null" />.</span></span></exception>
        <exception cref="T:System.ArgumentException"><span data-ttu-id="b4702-289"><paramref name="inputText" /> が空の文字列 ("") です。</span><span class="sxs-lookup"><span data-stu-id="b4702-289"><paramref name="inputText" /> is the empty string ("").</span></span></exception>
        <exception cref="T:System.NotSupportedException"><span data-ttu-id="b4702-290"><paramref name="compareOptions" /> は <see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" />、<see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" />、または <see cref="F:System.Globalization.CompareOptions.StringSort" /> フラグを含みます。</span><span class="sxs-lookup"><span data-stu-id="b4702-290"><paramref name="compareOptions" /> contains the <see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" />, <see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" />, or <see cref="F:System.Globalization.CompareOptions.StringSort" /> flag.</span></span></exception>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
      </Docs>
    </Member>
    <MemberGroup MemberName="EmulateRecognizeAsync">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary><span data-ttu-id="b4702-291">非同期音声認識に音声ではなくテキストを使用して、音声認識エンジンに対する入力をエミュレートします。</span><span class="sxs-lookup"><span data-stu-id="b4702-291">Emulates input to the speech recognizer, using text in place of audio for asynchronous speech recognition.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-292">これらのメソッドは、システムオーディオ入力をバイパスし、<xref:System.String> オブジェクトまたは <xref:System.Speech.Recognition.RecognizedWordUnit> オブジェクトの配列として認識エンジンにテキストを提供します。</span><span class="sxs-lookup"><span data-stu-id="b4702-292">These methods bypass the system audio input and provide text to the recognizer as <xref:System.String> objects or as an array of <xref:System.Speech.Recognition.RecognizedWordUnit> objects.</span></span> <span data-ttu-id="b4702-293">これは、アプリケーションまたは文法をテストまたはデバッグするときに役立ちます。</span><span class="sxs-lookup"><span data-stu-id="b4702-293">This can be helpful when you are testing or debugging an application or grammar.</span></span> <span data-ttu-id="b4702-294">たとえば、エミュレーションを使用して、単語が文法に含まれるかどうか、および単語が認識されたときにどのようなセマンティクスが返されるかを判断できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-294">For example, you can use emulation to determine whether a word is in a grammar and what semantics are returned when the word is recognized.</span></span> <span data-ttu-id="b4702-295"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> メソッドを使用して、エミュレーション操作中に音声認識エンジンへのオーディオ入力を無効にします。</span><span class="sxs-lookup"><span data-stu-id="b4702-295">Use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> method to disable audio input to the speech recognition engine during emulation operations.</span></span>  
  
 <span data-ttu-id="b4702-296">音声認識エンジンは、認識操作がエミュレートされていないかのように、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> のイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-296">The speech recognizer raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> events as if the recognition operation is not emulated.</span></span> <span data-ttu-id="b4702-297">レコグナイザーが非同期認識操作を完了すると、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> イベントが発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-297">When the recognizer completes the asynchronous recognition operation, it raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> event.</span></span> <span data-ttu-id="b4702-298">レコグナイザーは、新しい行と余分な空白文字を無視し、句読点をリテラル入力として扱います。</span><span class="sxs-lookup"><span data-stu-id="b4702-298">The recognizer ignores new lines and extra white space and treats punctuation as literal input.</span></span>  
  
> [!NOTE]
>  <span data-ttu-id="b4702-299">エミュレートされた入力への応答として音声認識エンジンによって生成される <xref:System.Speech.Recognition.RecognitionResult> オブジェクトは、その <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> プロパティに `null` の値を持ちます。</span><span class="sxs-lookup"><span data-stu-id="b4702-299">The <xref:System.Speech.Recognition.RecognitionResult> object generated by the speech recognizer in response to emulated input has a value of `null` for its <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> property.</span></span>  
  
 <span data-ttu-id="b4702-300">同期認識をエミュレートするには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-300">To emulate synchronous recognition, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (string inputText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(string inputText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub EmulateRecognizeAsync (inputText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(System::String ^ inputText);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : string -&gt; unit" Usage="speechRecognitionEngine.EmulateRecognizeAsync inputText" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="inputText"><span data-ttu-id="b4702-301">認識操作の入力。</span><span class="sxs-lookup"><span data-stu-id="b4702-301">The input for the recognition operation.</span></span></param>
        <summary><span data-ttu-id="b4702-302">非同期音声認識に音声ではなくテキストを使用して、音声認識エンジンに対する語句の入力をエミュレートします。</span><span class="sxs-lookup"><span data-stu-id="b4702-302">Emulates input of a phrase to the speech recognizer, using text in place of audio for asynchronous speech recognition.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-303">音声認識エンジンは、認識操作がエミュレートされていないかのように、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> のイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-303">The speech recognizer raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> events as if the recognition operation is not emulated.</span></span> <span data-ttu-id="b4702-304">レコグナイザーが非同期認識操作を完了すると、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> イベントが発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-304">When the recognizer completes the asynchronous recognition operation, it raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> event.</span></span>  
  
 <span data-ttu-id="b4702-305">Vista および Windows 7 に付属しているレコグナイザーは、文法規則を入力語句に適用するときに大文字と小文字の区別を無視します。</span><span class="sxs-lookup"><span data-stu-id="b4702-305">The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</span></span> <span data-ttu-id="b4702-306">この種類の比較の詳細については、<xref:System.Globalization.CompareOptions> 列挙値 <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> と <xref:System.Globalization.CompareOptions.IgnoreWidth>を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-306">For more information about this type of comparison, see the <xref:System.Globalization.CompareOptions> enumeration values <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> and <xref:System.Globalization.CompareOptions.IgnoreWidth>.</span></span> <span data-ttu-id="b4702-307">また、このレコグナイザーは新しい行と余分な空白を無視し、句読点をリテラル入力として扱います。</span><span class="sxs-lookup"><span data-stu-id="b4702-307">The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-308">次のコード例は、非同期のエミュレートされた入力、関連する認識結果、音声認識エンジンによって発生した関連イベントを示すコンソールアプリケーションの一部です。</span><span class="sxs-lookup"><span data-stu-id="b4702-308">The code example below is part of a console application that demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</span></span> <span data-ttu-id="b4702-309">この例では、次の出力が生成されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-309">The example generates the following output.</span></span>  
  
```  
  
TestRecognizeAsync("Smith")...  
 SpeechDetected event raised.  
 SpeechRecognized event raised.  
  Grammar = Smith; Text = Smith  
 EmulateRecognizeCompleted event raised.  
  Grammar = Smith; Text = Smith  
 Done.  
  
TestRecognizeAsync("Jones")...  
 SpeechDetected event raised.  
 SpeechRecognized event raised.  
  Grammar = Jones; Text = Jones  
 EmulateRecognizeCompleted event raised.  
  Grammar = Jones; Text = Jones  
 Done.  
  
TestRecognizeAsync("Mister")...  
 SpeechDetected event raised.  
 SpeechHypothesized event raised.  
  Grammar = Smith; Text = mister  
 SpeechRecognitionRejected event raised.  
  Grammar = <not available>; Text =  
 EmulateRecognizeCompleted event raised.  
  No recognition result available.  
 Done.  
  
TestRecognizeAsync("Mister Smith")...  
 SpeechDetected event raised.  
 SpeechRecognized event raised.  
  Grammar = Smith; Text = mister Smith  
 EmulateRecognizeCompleted event raised.  
  Grammar = Smith; Text = mister Smith  
 Done.  
  
press any key to exit...  
```  
  
```csharp  
using System;  
using System.Globalization;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SreEmulateRecognizeAsync  
{  
  class Program  
  {  
    // Indicate when an asynchronous operation is finished.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(new CultureInfo("en-US")))  
      {  
        // Load grammars.  
        recognizer.LoadGrammar(CreateNameGrammar("Smith"));  
        recognizer.LoadGrammar(CreateNameGrammar("Jones"));  
  
        // Configure the audio input.  
        recognizer.SetInputToNull();  
  
        // Add event handlers for the events raised by the  
        // EmulateRecognizeAsync method.  
        recognizer.SpeechDetected +=  
          new EventHandler<SpeechDetectedEventArgs>(  
            SpeechDetectedHandler);  
        recognizer.SpeechHypothesized +=  
          new EventHandler<SpeechHypothesizedEventArgs>(  
            SpeechHypothesizedHandler);  
        recognizer.SpeechRecognitionRejected +=  
          new EventHandler<SpeechRecognitionRejectedEventArgs>(  
            SpeechRecognitionRejectedHandler);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        // Start four asynchronous emulated recognition operations.  
        TestRecognizeAsync(recognizer, "Smith");  
        TestRecognizeAsync(recognizer, "Jones");  
        TestRecognizeAsync(recognizer, "Mister");  
        TestRecognizeAsync(recognizer, "Mister Smith");  
      }  
  
      Console.WriteLine("press any key to exit...");  
      Console.ReadKey(true);  
    }  
  
    // Create a simple name grammar.  
    // Set the grammar name to the surname.  
    private static Grammar CreateNameGrammar(string surname)  
    {  
      GrammarBuilder builder = new GrammarBuilder("mister", 0, 1);  
      builder.Append(surname);  
  
      Grammar nameGrammar = new Grammar(builder);  
      nameGrammar.Name = surname;  
  
      return nameGrammar;  
    }  
  
    // Send emulated input to the recognizer for asynchronous  
    // recognition.  
    private static void TestRecognizeAsync(  
      SpeechRecognitionEngine recognizer, string input)  
    {  
      completed = false;  
  
      Console.WriteLine("TestRecognizeAsync(\"{0}\")...", input);  
      recognizer.EmulateRecognizeAsync(input);  
  
      // Wait for the operation to complete.  
      while (!completed)  
      {  
        Thread.Sleep(333);  
      }  
  
      Console.WriteLine(" Done.");  
      Console.WriteLine();  
    }  
  
    static void SpeechDetectedHandler(  
      object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine(" SpeechDetected event raised.");  
    }  
  
    static void SpeechHypothesizedHandler(  
      object sender, SpeechHypothesizedEventArgs e)  
    {  
      Console.WriteLine(" SpeechHypothesized event raised.");  
      if (e.Result != null)  
      {  
        Console.WriteLine("  Grammar = {0}; Text = {1}",  
          e.Result.Grammar.Name ?? "<none>", e.Result.Text);  
      }  
      else  
      {  
        Console.WriteLine("  No recognition result available.");  
      }  
    }  
  
    // Handle events.  
    static void SpeechRecognitionRejectedHandler(  
      object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine(" SpeechRecognitionRejected event raised.");  
      if (e.Result != null)  
      {  
        string grammarName;  
        if (e.Result.Grammar != null)  
        {  
          grammarName = e.Result.Grammar.Name ?? "<none>";  
        }  
        else  
        {  
          grammarName = "<not available>";  
        }  
        Console.WriteLine("  Grammar = {0}; Text = {1}",  
          grammarName, e.Result.Text);  
      }  
      else  
      {  
        Console.WriteLine("  No recognition result available.");  
      }  
    }  
  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine(" SpeechRecognized event raised.");  
      if (e.Result != null)  
      {  
        Console.WriteLine("  Grammar = {0}; Text = {1}",  
          e.Result.Grammar.Name ?? "<none>", e.Result.Text );  
      }  
      else  
      {  
        Console.WriteLine("  No recognition result available.");  
      }  
    }  
  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      Console.WriteLine(" EmulateRecognizeCompleted event raised.");  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("  {0} exception encountered: {1}:",  
          e.Error.GetType().Name, e.Error.Message);  
      }  
      else if (e.Cancelled)  
      {  
        Console.WriteLine("  Operation cancelled.");  
      }  
      else if (e.Result != null)  
      {  
        Console.WriteLine("  Grammar = {0}; Text = {1}",  
          e.Result.Grammar.Name ?? "<none>", e.Result.Text);  
      }  
      else  
      {  
        Console.WriteLine("  No recognition result available.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.InvalidOperationException"><span data-ttu-id="b4702-310">認識エンジンに、読み込まれている音声認識文法がないか、認識エンジンに、未完了の非同期認識操作が存在しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-310">The recognizer has no speech recognition grammars loaded, or the recognizer has an asynchronous recognition operation that is not yet complete.</span></span></exception>
        <exception cref="T:System.ArgumentNullException"><span data-ttu-id="b4702-311"><paramref name="inputText" /> が <see langword="null" /> です。</span><span class="sxs-lookup"><span data-stu-id="b4702-311"><paramref name="inputText" /> is <see langword="null" />.</span></span></exception>
        <exception cref="T:System.ArgumentException"><span data-ttu-id="b4702-312"><paramref name="inputText" /> が空の文字列 ("") です。</span><span class="sxs-lookup"><span data-stu-id="b4702-312"><paramref name="inputText" /> is the empty string ("").</span></span></exception>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(class System.Speech.Recognition.RecognizedWordUnit[] wordUnits, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(cli::array &lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ wordUnits, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : System.Speech.Recognition.RecognizedWordUnit[] * System.Globalization.CompareOptions -&gt; unit" Usage="speechRecognitionEngine.EmulateRecognizeAsync (wordUnits, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="wordUnits" Type="System.Speech.Recognition.RecognizedWordUnit[]" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="wordUnits"><span data-ttu-id="b4702-313">認識操作のための必要を格納する単語単位の配列。</span><span class="sxs-lookup"><span data-stu-id="b4702-313">An array of word units that contains the input for the recognition operation.</span></span></param>
        <param name="compareOptions"><span data-ttu-id="b4702-314">エミュレートされた認識操作に使用する比較の種類を示す列挙値のビットごとの組み合わせ。</span><span class="sxs-lookup"><span data-stu-id="b4702-314">A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</span></span></param>
        <summary><span data-ttu-id="b4702-315">非同期音声認識にオーディオではなく <see cref="T:System.Speech.Recognition.RecognizedWordUnit" /> の配列を使用して、共有された音声認識エンジンに対する特定の語の入力をエミュレートし、語と読み込まれている音声認識文法との間で認識エンジンが Unicode 比較をどのように行うかを指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-315">Emulates input of specific words to the speech recognizer, using an array of <see cref="T:System.Speech.Recognition.RecognizedWordUnit" /> objects in place of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-316">音声認識エンジンは、認識操作がエミュレートされていないかのように、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> のイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-316">The speech recognizer raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> events as if the recognition operation is not emulated.</span></span> <span data-ttu-id="b4702-317">レコグナイザーが非同期認識操作を完了すると、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> イベントが発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-317">When the recognizer completes the asynchronous recognition operation, it raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> event.</span></span>  
  
 <span data-ttu-id="b4702-318">認識エンジンは、文法規則を入力語句に適用するときに `compareOptions` を使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-318">The recognizer uses `compareOptions` when it applies grammar rules to the input phrase.</span></span> <span data-ttu-id="b4702-319"><xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> または <xref:System.Globalization.CompareOptions.IgnoreCase> の値が存在する場合、Vista および Windows 7 に付属しているレコグナイザーは、大文字小文字を区別しません。</span><span class="sxs-lookup"><span data-stu-id="b4702-319">The recognizers that ship with Vista and Windows 7 ignore case if the <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> or <xref:System.Globalization.CompareOptions.IgnoreCase> value is present.</span></span> <span data-ttu-id="b4702-320">レコグナイザーは、文字幅を常に無視し、かなの種類を無視しません。</span><span class="sxs-lookup"><span data-stu-id="b4702-320">The recognizers always ignore the character width and never ignore the Kana type.</span></span> <span data-ttu-id="b4702-321">また、このレコグナイザーは新しい行と余分な空白を無視し、句読点をリテラル入力として扱います。</span><span class="sxs-lookup"><span data-stu-id="b4702-321">The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</span></span> <span data-ttu-id="b4702-322">文字幅とかなの種類の詳細については、<xref:System.Globalization.CompareOptions> 列挙体を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-322">For more information about character width and Kana type, see the <xref:System.Globalization.CompareOptions> enumeration.</span></span>  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.InvalidOperationException"><span data-ttu-id="b4702-323">認識エンジンに、読み込まれている音声認識文法がないか、認識エンジンに、未完了の非同期認識操作が存在しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-323">The recognizer has no speech recognition grammars loaded, or the recognizer has an asynchronous recognition operation that is not yet complete.</span></span></exception>
        <exception cref="T:System.ArgumentNullException"><span data-ttu-id="b4702-324"><paramref name="wordUnits" /> は <see langword="null" />です。</span><span class="sxs-lookup"><span data-stu-id="b4702-324"><paramref name="wordUnits" /> is <see langword="null" />.</span></span></exception>
        <exception cref="T:System.ArgumentException"><span data-ttu-id="b4702-325"><paramref name="wordUnits" /> は 1 つ以上の <see langword="null" /> 要素を含みます。</span><span class="sxs-lookup"><span data-stu-id="b4702-325"><paramref name="wordUnits" /> contains one or more <see langword="null" /> elements.</span></span></exception>
        <exception cref="T:System.NotSupportedException"><span data-ttu-id="b4702-326"><paramref name="compareOptions" /> は <see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" />、<see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" />、または <see cref="F:System.Globalization.CompareOptions.StringSort" /> フラグを含みます。</span><span class="sxs-lookup"><span data-stu-id="b4702-326"><paramref name="compareOptions" /> contains the <see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" />, <see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" />, or <see cref="F:System.Globalization.CompareOptions.StringSort" /> flag.</span></span></exception>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (string inputText, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(string inputText, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(System::String ^ inputText, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : string * System.Globalization.CompareOptions -&gt; unit" Usage="speechRecognitionEngine.EmulateRecognizeAsync (inputText, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="inputText"><span data-ttu-id="b4702-327">認識操作の入力語句。</span><span class="sxs-lookup"><span data-stu-id="b4702-327">The input phrase for the recognition operation.</span></span></param>
        <param name="compareOptions"><span data-ttu-id="b4702-328">エミュレートされた認識操作に使用する比較の種類を示す列挙値のビットごとの組み合わせ。</span><span class="sxs-lookup"><span data-stu-id="b4702-328">A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</span></span></param>
        <summary><span data-ttu-id="b4702-329">非同期音声認識にオーディオではなくテキストを使用して、音声認識エンジンに対するフレーズの入力をエミュレートし、フレーズと読み込まれている音声認識文法との間で認識エンジンが Unicode 比較をどのように行うかを指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-329">Emulates input of a phrase to the speech recognizer, using text in place of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-330">音声認識エンジンは、認識操作がエミュレートされていないかのように、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> のイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-330">The speech recognizer raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> events as if the recognition operation is not emulated.</span></span> <span data-ttu-id="b4702-331">レコグナイザーが非同期認識操作を完了すると、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> イベントが発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-331">When the recognizer completes the asynchronous recognition operation, it raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> event.</span></span>  
  
 <span data-ttu-id="b4702-332">認識エンジンは、文法規則を入力語句に適用するときに `compareOptions` を使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-332">The recognizer uses `compareOptions` when it applies grammar rules to the input phrase.</span></span> <span data-ttu-id="b4702-333"><xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> または <xref:System.Globalization.CompareOptions.IgnoreCase> の値が存在する場合、Vista および Windows 7 に付属しているレコグナイザーは、大文字小文字を区別しません。</span><span class="sxs-lookup"><span data-stu-id="b4702-333">The recognizers that ship with Vista and Windows 7 ignore case if the <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> or <xref:System.Globalization.CompareOptions.IgnoreCase> value is present.</span></span> <span data-ttu-id="b4702-334">レコグナイザーは、文字幅を常に無視し、かなの種類を無視しません。</span><span class="sxs-lookup"><span data-stu-id="b4702-334">The recognizers always ignore the character width and never ignore the Kana type.</span></span> <span data-ttu-id="b4702-335">また、このレコグナイザーは新しい行と余分な空白を無視し、句読点をリテラル入力として扱います。</span><span class="sxs-lookup"><span data-stu-id="b4702-335">The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</span></span> <span data-ttu-id="b4702-336">文字幅とかなの種類の詳細については、<xref:System.Globalization.CompareOptions> 列挙体を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-336">For more information about character width and Kana type, see the <xref:System.Globalization.CompareOptions> enumeration.</span></span>  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.InvalidOperationException"><span data-ttu-id="b4702-337">認識エンジンに、読み込まれている音声認識文法がないか、認識エンジンに、未完了の非同期認識操作が存在しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-337">The recognizer has no speech recognition grammars loaded, or the recognizer has an asynchronous recognition operation that is not yet complete.</span></span></exception>
        <exception cref="T:System.ArgumentNullException"><span data-ttu-id="b4702-338"><paramref name="inputText" /> が <see langword="null" /> です。</span><span class="sxs-lookup"><span data-stu-id="b4702-338"><paramref name="inputText" /> is <see langword="null" />.</span></span></exception>
        <exception cref="T:System.ArgumentException"><span data-ttu-id="b4702-339"><paramref name="inputText" /> が空の文字列 ("") です。</span><span class="sxs-lookup"><span data-stu-id="b4702-339"><paramref name="inputText" /> is the empty string ("").</span></span></exception>
        <exception cref="T:System.NotSupportedException"><span data-ttu-id="b4702-340"><paramref name="compareOptions" /> は <see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" />、<see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" />、または <see cref="F:System.Globalization.CompareOptions.StringSort" /> フラグを含みます。</span><span class="sxs-lookup"><span data-stu-id="b4702-340"><paramref name="compareOptions" /> contains the <see cref="F:System.Globalization.CompareOptions.IgnoreNonSpace" />, <see cref="F:System.Globalization.CompareOptions.IgnoreSymbols" />, or <see cref="F:System.Globalization.CompareOptions.StringSort" /> flag.</span></span></exception>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; EmulateRecognizeCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; EmulateRecognizeCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event EmulateRecognizeCompleted As EventHandler(Of EmulateRecognizeCompletedEventArgs) " FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::EmulateRecognizeCompletedEventArgs ^&gt; ^ EmulateRecognizeCompleted;" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeCompleted : EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; " Usage="member this.EmulateRecognizeCompleted : System.EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; " />
      <MemberSignature Language="VB.NET" Value="Public Event EmulateRecognizeCompleted As EventHandler(Of EmulateRecognizeCompletedEventArgs) " FrameworkAlternate="netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-341"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> がエミュレートされた入力の非同期認識操作を終了すると発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-341">Raised when the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> finalizes an asynchronous recognition operation of emulated input.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-342">各 <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> メソッドは、非同期認識操作を開始します。</span><span class="sxs-lookup"><span data-stu-id="b4702-342">Each <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> method begins an asynchronous recognition operation.</span></span> <span data-ttu-id="b4702-343"><xref:System.Speech.Recognition.SpeechRecognitionEngine> は、非同期操作を終了するときに <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> イベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-343">The <xref:System.Speech.Recognition.SpeechRecognitionEngine> raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> event when it finalizes the asynchronous operation.</span></span>  
  
 <span data-ttu-id="b4702-344"><xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> 操作では、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> のイベントを発生させることができます。</span><span class="sxs-lookup"><span data-stu-id="b4702-344">The <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> operation can raise the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> events.</span></span> <span data-ttu-id="b4702-345"><xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> イベントは、特定の操作でレコグナイザーが発生させる最後のイベントです。</span><span class="sxs-lookup"><span data-stu-id="b4702-345">The <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> event is the last such event that the recognizer raises for a given operation.</span></span>  
  
 <span data-ttu-id="b4702-346">エミュレートされた認識が成功した場合は、次のいずれかを使用して認識結果にアクセスできます。</span><span class="sxs-lookup"><span data-stu-id="b4702-346">If emulated recognition was successful, you can access the recognition result using the either of the following:</span></span>  
  
-   <span data-ttu-id="b4702-347"><xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> イベントのハンドラー内にある <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs> オブジェクトの <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A> プロパティ。</span><span class="sxs-lookup"><span data-stu-id="b4702-347">The <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A> property in the <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs> object in the handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> event.</span></span>  
  
-   <span data-ttu-id="b4702-348"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> イベントのハンドラーで、<xref:System.Speech.Recognition.SpeechRecognizedEventArgs> オブジェクトのプロパティを <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> します。</span><span class="sxs-lookup"><span data-stu-id="b4702-348"><xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> property in the <xref:System.Speech.Recognition.SpeechRecognizedEventArgs> object in the handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> event.</span></span>  
  
 <span data-ttu-id="b4702-349">エミュレートされた認識が失敗した場合、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> イベントは発生せず、<xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A> は null になります。</span><span class="sxs-lookup"><span data-stu-id="b4702-349">If emulated recognition was not successful, the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> event is not raised and the <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A> will be null.</span></span>  
  
 <span data-ttu-id="b4702-350"><xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs> は、<xref:System.ComponentModel.AsyncCompletedEventArgs> から派生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-350"><xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs> derives from <xref:System.ComponentModel.AsyncCompletedEventArgs>.</span></span>  
  
 <span data-ttu-id="b4702-351"><xref:System.Speech.Recognition.SpeechRecognizedEventArgs> は、<xref:System.Speech.Recognition.RecognitionEventArgs> から派生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-351"><xref:System.Speech.Recognition.SpeechRecognizedEventArgs> derives from <xref:System.Speech.Recognition.RecognitionEventArgs>.</span></span>  
  
 <span data-ttu-id="b4702-352"><xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> デリゲートを作成する場合は、イベントを処理するメソッドを指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-352">When you create an <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> delegate, you identify the method that will handle the event.</span></span> <span data-ttu-id="b4702-353">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="b4702-353">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="b4702-354">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-354">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="b4702-355">イベントハンドラーデリゲートの詳細については、「[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-355">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-356">次の例は、音声認識の文法を読み込み、非同期のエミュレートされた入力、関連する認識結果、音声認識エンジンによって発生した関連イベントを示すコンソールアプリケーションの一部です。</span><span class="sxs-lookup"><span data-stu-id="b4702-356">The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace InProcessRecognizer  
{  
  class Program  
  {  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of an in-process recognizer.  
      using (SpeechRecognitionEngine recognizer =   
        new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US")))  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call matches the grammar  
        // and generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar  
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Result of 1st call to EmulateRecognizeAsync = {0}",  
          e.Result.Text ?? "<no text>");  
        Console.WriteLine();  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the EmulateRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("Result of 2nd call to EmulateRecognizeAsync = No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
      </Docs>
    </Member>
    <Member MemberName="EndSilenceTimeout">
      <MemberSignature Language="C#" Value="public TimeSpan EndSilenceTimeout { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan EndSilenceTimeout" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout" />
      <MemberSignature Language="VB.NET" Value="Public Property EndSilenceTimeout As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan EndSilenceTimeout { TimeSpan get(); void set(TimeSpan value); };" />
      <MemberSignature Language="F#" Value="member this.EndSilenceTimeout : TimeSpan with get, set" Usage="System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>System.ComponentModel.EditorBrowsable(System.ComponentModel.EditorBrowsableState.Advanced)</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-357"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> が明確な入力の最後に認識操作を終了する前に受け入れる無音状態の間隔を取得または設定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-357">Gets or sets the interval of silence that the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> will accept at the end of unambiguous input before finalizing a recognition operation.</span></span></summary>
        <value><span data-ttu-id="b4702-358">無音状態の間隔の時間。</span><span class="sxs-lookup"><span data-stu-id="b4702-358">The duration of the interval of silence.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-359">音声認識エンジンは、認識入力が明確である場合に、このタイムアウト間隔を使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-359">The speech recognizer uses this timeout interval when the recognition input is unambiguous.</span></span> <span data-ttu-id="b4702-360">たとえば、"新しいゲームの作成" または "新しいゲーム"、"新しいゲーム" はあいまいな入力で、"新しいゲーム" はあいまいな入力であることを認識している音声認識文法では、</span><span class="sxs-lookup"><span data-stu-id="b4702-360">For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</span></span>  
  
 <span data-ttu-id="b4702-361">このプロパティは、認識操作を終了する前に、音声認識エンジンが追加の入力を待機する時間を決定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-361">This property determines how long the speech recognition engine will wait for additional input before finalizing a recognition operation.</span></span> <span data-ttu-id="b4702-362">タイムアウト間隔は、0秒から10秒までの範囲で指定できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-362">The timeout interval can be from 0 seconds to 10 seconds, inclusive.</span></span> <span data-ttu-id="b4702-363">既定値は150ミリ秒です。</span><span class="sxs-lookup"><span data-stu-id="b4702-363">The default is 150 milliseconds.</span></span>  
  
 <span data-ttu-id="b4702-364">あいまいな入力のタイムアウト間隔を設定するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-364">To set the timeout interval for ambiguous input, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> property.</span></span>  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.ArgumentOutOfRangeException"><span data-ttu-id="b4702-365">このプロパティが、0 秒未満または 10 秒を超える値に設定されています。</span><span class="sxs-lookup"><span data-stu-id="b4702-365">This property is set to less than 0 seconds or greater than 10 seconds.</span></span></exception>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      </Docs>
    </Member>
    <Member MemberName="EndSilenceTimeoutAmbiguous">
      <MemberSignature Language="C#" Value="public TimeSpan EndSilenceTimeoutAmbiguous { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan EndSilenceTimeoutAmbiguous" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous" />
      <MemberSignature Language="VB.NET" Value="Public Property EndSilenceTimeoutAmbiguous As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan EndSilenceTimeoutAmbiguous { TimeSpan get(); void set(TimeSpan value); };" />
      <MemberSignature Language="F#" Value="member this.EndSilenceTimeoutAmbiguous : TimeSpan with get, set" Usage="System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>System.ComponentModel.EditorBrowsable(System.ComponentModel.EditorBrowsableState.Advanced)</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-366"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> が不明確な入力の最後に認識操作を終了する前に受け入れる無音状態の間隔を取得または設定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-366">Gets or sets the interval of silence that the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> will accept at the end of ambiguous input before finalizing a recognition operation.</span></span></summary>
        <value><span data-ttu-id="b4702-367">無音状態の間隔の時間。</span><span class="sxs-lookup"><span data-stu-id="b4702-367">The duration of the interval of silence.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-368">音声認識エンジンは、認識入力があいまいな場合に、このタイムアウト間隔を使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-368">The speech recognizer uses this timeout interval when the recognition input is ambiguous.</span></span> <span data-ttu-id="b4702-369">たとえば、"新しいゲームの作成" または "新しいゲーム"、"新しいゲーム" はあいまいな入力で、"新しいゲーム" はあいまいな入力であることを認識している音声認識文法では、</span><span class="sxs-lookup"><span data-stu-id="b4702-369">For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</span></span>  
  
 <span data-ttu-id="b4702-370">このプロパティは、認識操作を終了する前に、音声認識エンジンが追加の入力を待機する時間を決定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-370">This property determines how long the speech recognition engine will wait for additional input before finalizing a recognition operation.</span></span> <span data-ttu-id="b4702-371">タイムアウト間隔は、0秒から10秒までの範囲で指定できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-371">The timeout interval can be from 0 seconds to 10 seconds, inclusive.</span></span> <span data-ttu-id="b4702-372">既定値は500ミリ秒です。</span><span class="sxs-lookup"><span data-stu-id="b4702-372">The default is 500 milliseconds.</span></span>  
  
 <span data-ttu-id="b4702-373">明確な入力のタイムアウト間隔を設定するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-373">To set the timeout interval for unambiguous input, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> property.</span></span>  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.ArgumentOutOfRangeException"><span data-ttu-id="b4702-374">このプロパティが、0 秒未満または 10 秒を超える値に設定されています。</span><span class="sxs-lookup"><span data-stu-id="b4702-374">This property is set to less than 0 seconds or greater than 10 seconds.</span></span></exception>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      </Docs>
    </Member>
    <Member MemberName="Grammars">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt; Grammars { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.Grammar&gt; Grammars" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognitionEngine.Grammars" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Grammars As ReadOnlyCollection(Of Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::Grammar ^&gt; ^ Grammars { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::Grammar ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Grammars : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt;" Usage="System.Speech.Recognition.SpeechRecognitionEngine.Grammars" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-375">この <see cref="T:System.Speech.Recognition.Grammar" /> インスタンスに読み込まれる <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> オブジェクトのコレクションを取得します。</span><span class="sxs-lookup"><span data-stu-id="b4702-375">Gets a collection of the <see cref="T:System.Speech.Recognition.Grammar" /> objects that are loaded in this <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> instance.</span></span></summary>
        <value><span data-ttu-id="b4702-376"><see cref="T:System.Speech.Recognition.Grammar" /> オブジェクトのコレクション。</span><span class="sxs-lookup"><span data-stu-id="b4702-376">The collection of <see cref="T:System.Speech.Recognition.Grammar" /> objects.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 <span data-ttu-id="b4702-377">次の例では、音声認識エンジンによって現在読み込まれている音声認識文法ごとに情報をコンソールに出力します。</span><span class="sxs-lookup"><span data-stu-id="b4702-377">The following example outputs information to the console for each speech recognition grammar that is currently loaded by a speech recognizer.</span></span>  
  
> [!IMPORTANT]
>  <span data-ttu-id="b4702-378">コレクションが変更された場合にエラーが発生しないように、文法コレクションをコピーします。このメソッドは、コレクションの要素を列挙します。</span><span class="sxs-lookup"><span data-stu-id="b4702-378">Copy the grammar collection to avoid errors if the collection is modified while this method enumerates the elements of the collection.</span></span>  
  
```csharp  
  
private static void ListGrammars(SpeechRecognitionEngine recognizer)  
{  
  string qualifier;  
  List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
  foreach (Grammar g in grammars)  
  {  
    qualifier = (g.Enabled) ? "enabled" : "disabled";  
  
    Console.WriteLine("Grammar {0} is loaded and is {1}.",  
      g.Name, qualifier);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
      </Docs>
    </Member>
    <Member MemberName="InitialSilenceTimeout">
      <MemberSignature Language="C#" Value="public TimeSpan InitialSilenceTimeout { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan InitialSilenceTimeout" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout" />
      <MemberSignature Language="VB.NET" Value="Public Property InitialSilenceTimeout As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan InitialSilenceTimeout { TimeSpan get(); void set(TimeSpan value); };" />
      <MemberSignature Language="F#" Value="member this.InitialSilenceTimeout : TimeSpan with get, set" Usage="System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>System.ComponentModel.EditorBrowsable(System.ComponentModel.EditorBrowsableState.Advanced)</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-379"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> が認識を終了する前に無音状態のみを含む入力を受け入れる時間間隔を取得または設定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-379">Gets or sets the time interval during which a <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> accepts input containing only silence before finalizing recognition.</span></span></summary>
        <value><span data-ttu-id="b4702-380">無音状態の間隔の時間。</span><span class="sxs-lookup"><span data-stu-id="b4702-380">The duration of the interval of silence.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-381">各音声認識エンジンには、無音と音声を区別するためのアルゴリズムが用意されています。</span><span class="sxs-lookup"><span data-stu-id="b4702-381">Each speech recognizer has an algorithm to distinguish between silence and speech.</span></span> <span data-ttu-id="b4702-382">最初のサイレント状態のタイムアウト期間中にレコグナイザー入力が無音になっている場合、レコグナイザーは認識操作を終了します。</span><span class="sxs-lookup"><span data-stu-id="b4702-382">If the recognizer input is silence during the initial silence timeout period, then the recognizer finalizes that recognition operation.</span></span>  
  
-   <span data-ttu-id="b4702-383">非同期の認識操作とエミュレーションでは、レコグナイザーによって <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> イベントが発生し、<xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=nameWithType> プロパティは `true`、<xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=nameWithType> プロパティは `null`ます。</span><span class="sxs-lookup"><span data-stu-id="b4702-383">For asynchronous recognition operations and emulation, the recognizer raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> event, where the <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=nameWithType> property is `true`, and the <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=nameWithType> property is `null`.</span></span>  
  
-   <span data-ttu-id="b4702-384">同期認識操作とエミュレーションでは、認識エンジンは有効な <xref:System.Speech.Recognition.RecognitionResult>ではなく `null`を返します。</span><span class="sxs-lookup"><span data-stu-id="b4702-384">For synchronous recognition operations and emulation, the recognizer returns `null`, instead of a valid <xref:System.Speech.Recognition.RecognitionResult>.</span></span>  
  
 <span data-ttu-id="b4702-385">最初のサイレント状態のタイムアウト間隔が0に設定されている場合、レコグナイザーは最初のサイレント状態のタイムアウトチェックを実行しません。</span><span class="sxs-lookup"><span data-stu-id="b4702-385">If the initial silence timeout interval is set to 0, the recognizer does not perform an initial silence timeout check.</span></span> <span data-ttu-id="b4702-386">タイムアウト間隔には、負でない値を指定できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-386">The timeout interval can be any non-negative value.</span></span> <span data-ttu-id="b4702-387">既定値は0秒です。</span><span class="sxs-lookup"><span data-stu-id="b4702-387">The default is 0 seconds.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-388">次の例は、基本的な音声認識を示すコンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-388">The following example shows part of a console application that demonstrates basic speech recognition.</span></span> <span data-ttu-id="b4702-389">この例では、音声認識を開始する前に <xref:System.Speech.Recognition.SpeechRecognitionEngine> の <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> と <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> のプロパティを設定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-389">The example sets the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> before initiating speech recognition.</span></span> <span data-ttu-id="b4702-390">音声認識エンジンの <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged> イベントと <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> イベントのハンドラーは、イベント情報をコンソールに出力して、<xref:System.Speech.Recognition.SpeechRecognitionEngine> プロパティの <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> プロパティが認識操作にどのように影響するかを示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-390">Handlers for the speech recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> events output event information to the console to demonstrate how the <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> properties affect recognition operations.</span></span>  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
  
namespace SpeechRecognitionApp  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognizer.  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(  
          new System.Globalization.CultureInfo("en-US")))  
      {  
        // Load a Grammar object.  
        recognizer.LoadGrammar(CreateServicesGrammar("FindServices"));  
  
        // Add event handlers.  
        recognizer.AudioStateChanged +=  
          new EventHandler<AudioStateChangedEventArgs>(  
            AudioStateChangedHandler);  
        recognizer.RecognizeCompleted +=  
          new EventHandler<RecognizeCompletedEventArgs>(  
            RecognizeCompletedHandler);  
  
        // Configure input to the speech recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(3);  
        recognizer.BabbleTimeout = TimeSpan.FromSeconds(2);  
        recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1);  
        recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.5);  
  
        Console.WriteLine("BabbleTimeout: {0}", recognizer.BabbleTimeout);  
        Console.WriteLine("InitialSilenceTimeout: {0}", recognizer.InitialSilenceTimeout);  
        Console.WriteLine("EndSilenceTimeout: {0}", recognizer.EndSilenceTimeout);  
        Console.WriteLine("EndSilenceTimeoutAmbiguous: {0}", recognizer.EndSilenceTimeoutAmbiguous);  
        Console.WriteLine();  
  
        // Start asynchronous speech recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Single);  
  
        // Keep the console window open.  
        while (true)  
        {  
          Console.ReadLine();  
        }  
      }  
    }  
  
    // Create a grammar and build it into a Grammar object.   
    static Grammar CreateServicesGrammar(string grammarName)  
    {  
  
      // Create a grammar for finding services in different cities.  
      Choices services = new Choices(new string[] { "restaurants", "hotels", "gas stations" });  
      Choices cities = new Choices(new string[] { "Seattle", "Boston", "Dallas" });  
  
      GrammarBuilder findServices = new GrammarBuilder("Find");  
      findServices.Append(services);  
      findServices.Append("near");  
      findServices.Append(cities);  
  
      // Create a Grammar object from the GrammarBuilder. 
      Grammar servicesGrammar = new Grammar(findServices);  
      servicesGrammar.Name = ("FindServices");  
      return servicesGrammar;  
    }  
  
    // Handle the AudioStateChanged event.  
    static void AudioStateChangedHandler(  
      object sender, AudioStateChangedEventArgs e)  
    {  
      Console.WriteLine("AudioStateChanged ({0}): {1}",  
        DateTime.Now.ToString("mm:ss.f"), e.AudioState);  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void RecognizeCompletedHandler(  
      object sender, RecognizeCompletedEventArgs e)  
    {  
      Console.WriteLine("RecognizeCompleted ({0}):",  
        DateTime.Now.ToString("mm:ss.f"));  
  
      string resultText;  
      if (e.Result != null) { resultText = e.Result.Text; }  
      else { resultText = "<null>"; }  
  
      Console.WriteLine(  
        " BabbleTimeout: {0}; InitialSilenceTimeout: {1}; Result text: {2}",  
        e.BabbleTimeout, e.InitialSilenceTimeout, resultText);  
      if (e.Error != null)  
      {  
        Console.WriteLine(" Exception message: ", e.Error.Message);  
      }  
  
      // Start the next asynchronous recognition operation.  
      ((SpeechRecognitionEngine)sender).RecognizeAsync(RecognizeMode.Single);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.ArgumentOutOfRangeException"><span data-ttu-id="b4702-391">このプロパティが 0 秒未満の値に設定されています。</span><span class="sxs-lookup"><span data-stu-id="b4702-391">This property is set to less than 0 seconds.</span></span></exception>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      </Docs>
    </Member>
    <Member MemberName="InstalledRecognizers">
      <MemberSignature Language="C#" Value="public static System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizerInfo&gt; InstalledRecognizers ();" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.RecognizerInfo&gt; InstalledRecognizers() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function InstalledRecognizers () As ReadOnlyCollection(Of RecognizerInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; static System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizerInfo ^&gt; ^ InstalledRecognizers();" />
      <MemberSignature Language="F#" Value="static member InstalledRecognizers : unit -&gt; System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizerInfo&gt;" Usage="System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizerInfo&gt;</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary><span data-ttu-id="b4702-392">現在のシステムにインストールされているすべての音声認識に関する情報を返します。</span><span class="sxs-lookup"><span data-stu-id="b4702-392">Returns information for all of the installed speech recognizers on the current system.</span></span></summary>
        <returns><span data-ttu-id="b4702-393">インストールされたレコグナイザーを記述する <see cref="T:System.Speech.Recognition.RecognizerInfo" /> オブジェクトの読み取り専用コレクション。</span><span class="sxs-lookup"><span data-stu-id="b4702-393">A read-only collection of the <see cref="T:System.Speech.Recognition.RecognizerInfo" /> objects that describe the installed recognizers.</span></span></returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-394">現在の認識エンジンに関する情報を取得するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A> プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-394">To get information about the current recognizer, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A> property.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-395">次の例は、基本的な音声認識を示すコンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-395">The following example shows part of a console application that demonstrates basic speech recognition.</span></span> <span data-ttu-id="b4702-396">この例では、<xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A> メソッドによって返されるコレクションを使用して、英語をサポートする音声認識エンジンを検索します。</span><span class="sxs-lookup"><span data-stu-id="b4702-396">The example uses the collection returned by the <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A> method to find a speech recognizer that supports the English language.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SpeechRecognitionApp  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Select a speech recognizer that supports English.  
      RecognizerInfo info = null;  
      foreach (RecognizerInfo ri in SpeechRecognitionEngine.InstalledRecognizers())  
      {  
        if (ri.Culture.TwoLetterISOLanguageName.Equals("en"))  
        {  
          info = ri;  
          break;  
        }  
      }  
      if (info == null) return;  
  
      // Create the selected recognizer.  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(info))  
      {  
  
        // Create and load a dictation grammar.  
        recognizer.LoadGrammar(new DictationGrammar());  
  
        // Add a handler for the speech recognized event.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Configure input to the speech recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Start asynchronous, continuous speech recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
  
        // Keep the console window open.  
        while (true)  
        {  
          Console.ReadLine();  
        }  
      }  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Recognized text: " + e.Result.Text);  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammar">
      <MemberSignature Language="C#" Value="public void LoadGrammar (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void LoadGrammar(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void LoadGrammar(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.LoadGrammar : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognitionEngine.LoadGrammar grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar"><span data-ttu-id="b4702-397">読み込む文法オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="b4702-397">The grammar object to load.</span></span></param>
        <summary><span data-ttu-id="b4702-398"><see cref="T:System.Speech.Recognition.Grammar" /> オブジェクトを同期的に読み込みます。</span><span class="sxs-lookup"><span data-stu-id="b4702-398">Synchronously loads a <see cref="T:System.Speech.Recognition.Grammar" /> object.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-399"><xref:System.Speech.Recognition.Grammar> オブジェクトが既に読み込まれている、非同期に読み込まれている、または認識エンジンへの読み込みに失敗した場合、レコグナイザーは例外をスローします。</span><span class="sxs-lookup"><span data-stu-id="b4702-399">The recognizer throws an exception if the <xref:System.Speech.Recognition.Grammar> object is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</span></span> <span data-ttu-id="b4702-400">同じ <xref:System.Speech.Recognition.Grammar> オブジェクトを <xref:System.Speech.Recognition.SpeechRecognitionEngine>の複数のインスタンスに読み込むことはできません。</span><span class="sxs-lookup"><span data-stu-id="b4702-400">You cannot load the same <xref:System.Speech.Recognition.Grammar> object into multiple instances of <xref:System.Speech.Recognition.SpeechRecognitionEngine>.</span></span> <span data-ttu-id="b4702-401">代わりに、<xref:System.Speech.Recognition.SpeechRecognitionEngine> インスタンスごとに新しい <xref:System.Speech.Recognition.Grammar> オブジェクトを作成します。</span><span class="sxs-lookup"><span data-stu-id="b4702-401">Instead, create a new <xref:System.Speech.Recognition.Grammar> object for each <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance.</span></span>  
  
 <span data-ttu-id="b4702-402">レコグナイザーが実行されている場合、アプリケーションは、文法の読み込み、アンロード、有効化、または無効化の前に、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> を使用して音声認識エンジンを一時停止する必要があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-402">If the recognizer is running, applications must use <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</span></span>  
  
 <span data-ttu-id="b4702-403">文法を読み込むと、既定で有効になります。</span><span class="sxs-lookup"><span data-stu-id="b4702-403">When you load a grammar, it is enabled by default.</span></span> <span data-ttu-id="b4702-404">読み込まれた文法を無効にするには、<xref:System.Speech.Recognition.Grammar.Enabled%2A> プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-404">To disable a loaded grammar, use the <xref:System.Speech.Recognition.Grammar.Enabled%2A> property.</span></span>  
  
 <span data-ttu-id="b4702-405"><xref:System.Speech.Recognition.Grammar> オブジェクトを非同期的に読み込むには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-405">To load a <xref:System.Speech.Recognition.Grammar> object asynchronously, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> method.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-406">次の例は、基本的な音声認識を示すコンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-406">The following example shows part of a console application that demonstrates basic speech recognition.</span></span> <span data-ttu-id="b4702-407">この例では、<xref:System.Speech.Recognition.DictationGrammar> を作成し、音声認識エンジンに読み込みます。</span><span class="sxs-lookup"><span data-stu-id="b4702-407">The example creates a <xref:System.Speech.Recognition.DictationGrammar> and loads it into a speech recognizer.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SpeechRecognitionApp  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
  
      // Create an in-process speech recognizer for the en-US locale.  
      using (  
      SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(  
          new System.Globalization.CultureInfo("en-US")))  
      {  
  
        // Create and load a dictation grammar.  
        recognizer.LoadGrammar(new DictationGrammar());  
  
        // Add a handler for the speech recognized event.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Configure input to the speech recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Start asynchronous, continuous speech recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
  
        // Keep the console window open.  
        while (true)  
        {  
          Console.ReadLine();  
        }  
      }  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Recognized text: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.ArgumentNullException"><span data-ttu-id="b4702-408"><paramref name="Grammar" /> が <see langword="null" /> です。</span><span class="sxs-lookup"><span data-stu-id="b4702-408"><paramref name="Grammar" /> is <see langword="null" />.</span></span></exception>
        <exception cref="T:System.InvalidOperationException"><span data-ttu-id="b4702-409"><paramref name="Grammar" /> が有効な状態ではありません。</span><span class="sxs-lookup"><span data-stu-id="b4702-409"><paramref name="Grammar" /> is not in a valid state.</span></span></exception>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammarAsync">
      <MemberSignature Language="C#" Value="public void LoadGrammarAsync (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void LoadGrammarAsync(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void LoadGrammarAsync(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.LoadGrammarAsync : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognitionEngine.LoadGrammarAsync grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar"><span data-ttu-id="b4702-410">読み込む音声認識文法。</span><span class="sxs-lookup"><span data-stu-id="b4702-410">The speech recognition grammar to load.</span></span></param>
        <summary><span data-ttu-id="b4702-411">非同期的に音声認識文法を読み込みます。</span><span class="sxs-lookup"><span data-stu-id="b4702-411">Asynchronously loads a speech recognition grammar.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-412">レコグナイザーが <xref:System.Speech.Recognition.Grammar> オブジェクトの読み込みを完了すると、<xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted> イベントが発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-412">When the recognizer completes loading a <xref:System.Speech.Recognition.Grammar> object, it raises a <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted> event.</span></span> <span data-ttu-id="b4702-413"><xref:System.Speech.Recognition.Grammar> オブジェクトが既に読み込まれている、非同期に読み込まれている、または認識エンジンへの読み込みに失敗した場合、レコグナイザーは例外をスローします。</span><span class="sxs-lookup"><span data-stu-id="b4702-413">The recognizer throws an exception if the <xref:System.Speech.Recognition.Grammar> object is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</span></span> <span data-ttu-id="b4702-414">同じ <xref:System.Speech.Recognition.Grammar> オブジェクトを <xref:System.Speech.Recognition.SpeechRecognitionEngine>の複数のインスタンスに読み込むことはできません。</span><span class="sxs-lookup"><span data-stu-id="b4702-414">You cannot load the same <xref:System.Speech.Recognition.Grammar> object into multiple instances of <xref:System.Speech.Recognition.SpeechRecognitionEngine>.</span></span> <span data-ttu-id="b4702-415">代わりに、<xref:System.Speech.Recognition.SpeechRecognitionEngine> インスタンスごとに新しい <xref:System.Speech.Recognition.Grammar> オブジェクトを作成します。</span><span class="sxs-lookup"><span data-stu-id="b4702-415">Instead, create a new <xref:System.Speech.Recognition.Grammar> object for each <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance.</span></span>  
  
 <span data-ttu-id="b4702-416">レコグナイザーが実行されている場合、アプリケーションは、文法の読み込み、アンロード、有効化、または無効化の前に、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> を使用して音声認識エンジンを一時停止する必要があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-416">If the recognizer is running, applications must use <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</span></span>  
  
 <span data-ttu-id="b4702-417">文法を読み込むと、既定で有効になります。</span><span class="sxs-lookup"><span data-stu-id="b4702-417">When you load a grammar, it is enabled by default.</span></span> <span data-ttu-id="b4702-418">読み込まれた文法を無効にするには、<xref:System.Speech.Recognition.Grammar.Enabled%2A> プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-418">To disable a loaded grammar, use the <xref:System.Speech.Recognition.Grammar.Enabled%2A> property.</span></span>  
  
 <span data-ttu-id="b4702-419">音声認識の文法を同期的に読み込むには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-419">To load a speech recognition grammar synchronously, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.ArgumentNullException"><span data-ttu-id="b4702-420"><paramref name="Grammar" /> は <see langword="null" />です。</span><span class="sxs-lookup"><span data-stu-id="b4702-420"><paramref name="Grammar" /> is <see langword="null" />.</span></span></exception>
        <exception cref="T:System.InvalidOperationException"><span data-ttu-id="b4702-421"><paramref name="Grammar" /> が有効な状態ではありません。</span><span class="sxs-lookup"><span data-stu-id="b4702-421"><paramref name="Grammar" /> is not in a valid state.</span></span></exception>
        <exception cref="T:System.OperationCanceledException"><span data-ttu-id="b4702-422">非同期操作は取り消されました。</span><span class="sxs-lookup"><span data-stu-id="b4702-422">The asynchronous operation was canceled.</span></span></exception>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammarCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; LoadGrammarCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; LoadGrammarCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event LoadGrammarCompleted As EventHandler(Of LoadGrammarCompletedEventArgs) " FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::LoadGrammarCompletedEventArgs ^&gt; ^ LoadGrammarCompleted;" />
      <MemberSignature Language="F#" Value="member this.LoadGrammarCompleted : EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; " Usage="member this.LoadGrammarCompleted : System.EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; " />
      <MemberSignature Language="VB.NET" Value="Public Event LoadGrammarCompleted As EventHandler(Of LoadGrammarCompletedEventArgs) " FrameworkAlternate="netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-423"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> が <see cref="T:System.Speech.Recognition.Grammar" /> オブジェクトの非同期読み込みを終了するときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-423">Raised when the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> finishes the asynchronous loading of a <see cref="T:System.Speech.Recognition.Grammar" /> object.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-424">レコグナイザーの <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> メソッドは、非同期操作を開始します。</span><span class="sxs-lookup"><span data-stu-id="b4702-424">The recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> method initiates an asynchronous operation.</span></span> <span data-ttu-id="b4702-425"><xref:System.Speech.Recognition.SpeechRecognitionEngine> は、操作の完了時にこのイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-425">The <xref:System.Speech.Recognition.SpeechRecognitionEngine> raises this event when it completes the operation.</span></span> <span data-ttu-id="b4702-426">認識エンジンによって読み込まれた <xref:System.Speech.Recognition.Grammar> オブジェクトを取得するには、関連付けられた <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>の <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A> プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-426">To get the <xref:System.Speech.Recognition.Grammar> object that the recognizer loaded, use the <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A> property of the associated <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>.</span></span> <span data-ttu-id="b4702-427">レコグナイザーによって読み込まれた現在の <xref:System.Speech.Recognition.Grammar> オブジェクトを取得するには、レコグナイザーの <xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A> プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-427">To get the current <xref:System.Speech.Recognition.Grammar> objects the recognizer has loaded, use the recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A> property.</span></span>  
  
 <span data-ttu-id="b4702-428">レコグナイザーが実行されている場合、アプリケーションは、文法の読み込み、アンロード、有効化、または無効化の前に、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> を使用して音声認識エンジンを一時停止する必要があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-428">If the recognizer is running, applications must use <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</span></span>  
  
 <span data-ttu-id="b4702-429"><xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted> デリゲートを作成する場合は、イベントを処理するメソッドを指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-429">When you create a <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted> delegate, you identify the method that will handle the event.</span></span> <span data-ttu-id="b4702-430">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="b4702-430">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="b4702-431">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-431">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="b4702-432">イベントハンドラーデリゲートの詳細については、「[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-432">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-433">次の例では、インプロセス音声認識エンジンを作成し、特定の単語を認識し、無料のディクテーションを受け入れるために2種類の文法を作成します。</span><span class="sxs-lookup"><span data-stu-id="b4702-433">The following example creates an in-process speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</span></span> <span data-ttu-id="b4702-434">この例では、完成した音声認識文法のそれぞれから <xref:System.Speech.Recognition.Grammar> オブジェクトを構築し、<xref:System.Speech.Recognition.Grammar> オブジェクトを <xref:System.Speech.Recognition.SpeechRecognitionEngine> インスタンスに非同期的に読み込みます。</span><span class="sxs-lookup"><span data-stu-id="b4702-434">The example constructs a <xref:System.Speech.Recognition.Grammar> object from each of the completed speech recognition grammars, then asynchronously loads the <xref:System.Speech.Recognition.Grammar> objects to the <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance.</span></span> <span data-ttu-id="b4702-435">レコグナイザーの <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted> イベントと <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> イベントのハンドラーは、認識と認識結果のテキストをそれぞれ実行するために使用された <xref:System.Speech.Recognition.Grammar> オブジェクトの名前をそれぞれコンソールに書き込みます。</span><span class="sxs-lookup"><span data-stu-id="b4702-435">Handlers for the recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> events write to the console the name of the <xref:System.Speech.Recognition.Grammar> object that was used to perform the recognition and the text of the recognition result, respectively.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognition engine and set its input.  
      recognizer = new SpeechRecognitionEngine();  
      recognizer.SetInputToDefaultAudioDevice();  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted +=  
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the SpeechRecognized event.  
      recognizer.SpeechRecognized +=  
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
      // Create the "yesno" grammar.  
      Choices yesChoices = new Choices(new string[] { "yes", "yup", "yeah" });  
      SemanticResultValue yesValue =  
          new SemanticResultValue(yesChoices, (bool)true);  
      Choices noChoices = new Choices(new string[] { "no", "nope", "neah" });  
      SemanticResultValue noValue =  
          new SemanticResultValue(noChoices, (bool)false);  
      SemanticResultKey yesNoKey =  
          new SemanticResultKey("yesno", new Choices(new GrammarBuilder[] { yesValue, noValue }));  
      Grammar yesnoGrammar = new Grammar(yesNoKey);  
      yesnoGrammar.Name = "yesNo";  
  
      // Create the "done" grammar.  
      Grammar doneGrammar =  
        new Grammar(new Choices(new string[] { "done", "exit", "quit", "stop" }));  
      doneGrammar.Name = "Done";  
  
      // Create a dictation grammar.  
      Grammar dictation = new DictationGrammar();  
      dictation.Name = "Dictation";  
  
      // Load grammars to the recognizer.  
      recognizer.LoadGrammarAsync(yesnoGrammar);  
      recognizer.LoadGrammarAsync(doneGrammar);  
      recognizer.LoadGrammarAsync(dictation);  
  
      // Start asynchronous, continuous recognition.  
      recognizer.RecognizeAsync(RecognizeMode.Multiple);  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded.",  
      grammarName, (grammarLoaded) ? "is" : "is not");  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
  
      // Add event handler code here.  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" />
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.LoadGrammarCompletedEventArgs" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.Grammars" />
      </Docs>
    </Member>
    <Member MemberName="MaxAlternates">
      <MemberSignature Language="C#" Value="public int MaxAlternates { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 MaxAlternates" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates" />
      <MemberSignature Language="VB.NET" Value="Public Property MaxAlternates As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int MaxAlternates { int get(); void set(int value); };" />
      <MemberSignature Language="F#" Value="member this.MaxAlternates : int with get, set" Usage="System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-436"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> が各認識操作に対して返す代替認識結果の最大数を取得または設定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-436">Gets or sets the maximum number of alternate recognition results that the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> returns for each recognition operation.</span></span></summary>
        <value><span data-ttu-id="b4702-437">返される代替結果の数。</span><span class="sxs-lookup"><span data-stu-id="b4702-437">The number of alternate results to return.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-438"><xref:System.Speech.Recognition.RecognitionResult> クラスの <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> プロパティには、入力の考えられる解釈を表す <xref:System.Speech.Recognition.RecognizedPhrase> オブジェクトのコレクションが含まれています。</span><span class="sxs-lookup"><span data-stu-id="b4702-438">The <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> property of the <xref:System.Speech.Recognition.RecognitionResult> class contains the collection of <xref:System.Speech.Recognition.RecognizedPhrase> objects that represent possible interpretations of the input.</span></span>  
  
 <span data-ttu-id="b4702-439"><xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A> の既定値は10です。</span><span class="sxs-lookup"><span data-stu-id="b4702-439">The default value for <xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A> is 10.</span></span>  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.ArgumentOutOfRangeException"><span data-ttu-id="b4702-440"><see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates" /> が 0 未満の値に設定されています。</span><span class="sxs-lookup"><span data-stu-id="b4702-440"><see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates" /> is set to a value less than 0.</span></span></exception>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
      </Docs>
    </Member>
    <Member MemberName="QueryRecognizerSetting">
      <MemberSignature Language="C#" Value="public object QueryRecognizerSetting (string settingName);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance object QueryRecognizerSetting(string settingName) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Function QueryRecognizerSetting (settingName As String) As Object" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Object ^ QueryRecognizerSetting(System::String ^ settingName);" />
      <MemberSignature Language="F#" Value="member this.QueryRecognizerSetting : string -&gt; obj" Usage="speechRecognitionEngine.QueryRecognizerSetting settingName" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Object</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="settingName" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="settingName"><span data-ttu-id="b4702-441">返す設定の名前です。</span><span class="sxs-lookup"><span data-stu-id="b4702-441">The name of the setting to return.</span></span></param>
        <summary><span data-ttu-id="b4702-442">レコグナイザーの設定の値を返します。</span><span class="sxs-lookup"><span data-stu-id="b4702-442">Returns the values of settings for the recognizer.</span></span></summary>
        <returns><span data-ttu-id="b4702-443">設定値。</span><span class="sxs-lookup"><span data-stu-id="b4702-443">The value of the setting.</span></span></returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-444">レコグナイザーの設定には、文字列、64ビットの整数、またはメモリアドレスデータを含めることができます。</span><span class="sxs-lookup"><span data-stu-id="b4702-444">Recognizer settings can contain string, 64-bit integer, or memory address data.</span></span> <span data-ttu-id="b4702-445">次の表では、Microsoft Speech API (SAPI) 準拠のレコグナイザーに対して定義されている設定について説明します。</span><span class="sxs-lookup"><span data-stu-id="b4702-445">The following table describes the settings that are defined for a Microsoft Speech API (SAPI)-compliant recognizer.</span></span> <span data-ttu-id="b4702-446">次の設定は、設定をサポートする各レコグナイザーに対して同じ範囲である必要があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-446">The following settings must have the same range for each recognizer that supports the setting.</span></span> <span data-ttu-id="b4702-447">SAPI 準拠のレコグナイザーは、これらの設定をサポートするために必要ではなく、他の設定をサポートできます。</span><span class="sxs-lookup"><span data-stu-id="b4702-447">A SAPI-compliant recognizer is not required to support these settings and can support other settings.</span></span>  
  
|<span data-ttu-id="b4702-448">name</span><span class="sxs-lookup"><span data-stu-id="b4702-448">Name</span></span>|<span data-ttu-id="b4702-449">説明</span><span class="sxs-lookup"><span data-stu-id="b4702-449">Description</span></span>|  
|----------|-----------------|  
|`ResourceUsage`|<span data-ttu-id="b4702-450">レコグナイザーの CPU 使用量を指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-450">Specifies the recognizer's CPU consumption.</span></span> <span data-ttu-id="b4702-451">範囲は 0 ~ 100 です。</span><span class="sxs-lookup"><span data-stu-id="b4702-451">The range is from 0 to 100.</span></span> <span data-ttu-id="b4702-452">既定値は 50 です。</span><span class="sxs-lookup"><span data-stu-id="b4702-452">The default value is 50.</span></span>|  
|`ResponseSpeed`|<span data-ttu-id="b4702-453">音声認識エンジンが認識操作を完了する前に、明確な入力の最後に無音の長さを示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-453">Indicates the length of silence at the end of unambiguous input before the speech recognizer completes a recognition operation.</span></span> <span data-ttu-id="b4702-454">範囲は 0 ~ 1万ミリ秒 (ms) です。</span><span class="sxs-lookup"><span data-stu-id="b4702-454">The range is from 0 to 10,000 milliseconds (ms).</span></span> <span data-ttu-id="b4702-455">この設定は、レコグナイザーの <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> プロパティに対応しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-455">This setting corresponds to the recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> property.</span></span>  <span data-ttu-id="b4702-456">既定値は150ミリ秒です。</span><span class="sxs-lookup"><span data-stu-id="b4702-456">Default = 150ms.</span></span>|  
|`ComplexResponseSpeed`|<span data-ttu-id="b4702-457">音声認識エンジンが認識操作を完了する前に、あいまいな入力の最後に無音の長さを示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-457">Indicates the length of silence at the end of ambiguous input before the speech recognizer completes a recognition operation.</span></span> <span data-ttu-id="b4702-458">範囲は 0 ~ 10, 000ms 秒です。</span><span class="sxs-lookup"><span data-stu-id="b4702-458">The range is from 0 to 10,000ms.</span></span> <span data-ttu-id="b4702-459">この設定は、レコグナイザーの <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> プロパティに対応しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-459">This setting corresponds to the recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> property.</span></span> <span data-ttu-id="b4702-460">既定値は500ミリ秒です。</span><span class="sxs-lookup"><span data-stu-id="b4702-460">Default = 500ms.</span></span>|  
|`AdaptationOn`|<span data-ttu-id="b4702-461">音響モデルの適応がオン (値 = `1`) かオフ (値 = `0`) かを示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-461">Indicates whether adaptation of the acoustic model is ON (value = `1`) or OFF (value = `0`).</span></span> <span data-ttu-id="b4702-462">既定値は `1` (ON) です。</span><span class="sxs-lookup"><span data-stu-id="b4702-462">The default value is `1` (ON).</span></span>|  
|`PersistedBackgroundAdaptation`|<span data-ttu-id="b4702-463">バックグラウンドの適応がオン (値 = `1`) かオフ (値 = `0`) かを示し、レジストリに設定を保持します。</span><span class="sxs-lookup"><span data-stu-id="b4702-463">Indicates whether background adaptation is ON (value = `1`) or OFF (value = `0`), and persists the setting in the registry.</span></span> <span data-ttu-id="b4702-464">既定値は `1` (ON) です。</span><span class="sxs-lookup"><span data-stu-id="b4702-464">The default value is `1` (ON).</span></span>|  
  
 <span data-ttu-id="b4702-465">レコグナイザーの設定を更新するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> メソッドのいずれかを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-465">To update a setting for the recognizer, use one of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> methods.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-466">次の例は、en-us ロケールをサポートする認識エンジンに対して定義されているさまざまな設定の値を出力するコンソールアプリケーションの一部です。</span><span class="sxs-lookup"><span data-stu-id="b4702-466">The following example is part of a console application that outputs the values for a number of the settings defined for the recognizer that supports the en-US locale.</span></span> <span data-ttu-id="b4702-467">この例では、次の出力が生成されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-467">The example generates the following output.</span></span>  
  
```  
Settings for recognizer MS-1033-80-DESK:  
  
  ResourceUsage                  is not supported by this recognizer.  
  ResponseSpeed                  = 150  
  ComplexResponseSpeed           = 500  
  AdaptationOn                   = 1  
  PersistedBackgroundAdaptation  = 1  
  
Press any key to exit...  
```  
  
```csharp  
  
using System;  
using System.Globalization;  
using System.Speech.Recognition;  
  
namespace RecognizerSettings  
{  
  class Program  
  {  
    static readonly string[] settings = new string[] {  
      "ResourceUsage",  
      "ResponseSpeed",  
      "ComplexResponseSpeed",  
      "AdaptationOn",  
      "PersistedBackgroundAdaptation"  
    };  
  
    static void Main(string[] args)  
    {  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US")))  
      {  
        Console.WriteLine("Settings for recognizer {0}:",  
          recognizer.RecognizerInfo.Name);  
        Console.WriteLine();  
  
        foreach (string setting in settings)  
        {  
          try  
          {  
            object value = recognizer.QueryRecognizerSetting(setting);  
            Console.WriteLine("  {0,-30} = {1}", setting, value);  
          }  
          catch  
          {  
            Console.WriteLine("  {0,-30} is not supported by this recognizer.",  
              setting);  
          }  
        }  
      }  
      Console.WriteLine();  
  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.ArgumentNullException"><span data-ttu-id="b4702-468"><paramref name="settingName" /> が <see langword="null" /> です。</span><span class="sxs-lookup"><span data-stu-id="b4702-468"><paramref name="settingName" /> is <see langword="null" />.</span></span></exception>
        <exception cref="T:System.ArgumentException"><span data-ttu-id="b4702-469"><paramref name="settingName" /> が空の文字列 ("") です。</span><span class="sxs-lookup"><span data-stu-id="b4702-469"><paramref name="settingName" /> is the empty string ("").</span></span></exception>
        <exception cref="T:System.Collections.Generic.KeyNotFoundException"><span data-ttu-id="b4702-470">認識エンジンは、その名前で設定されていません。</span><span class="sxs-lookup"><span data-stu-id="b4702-470">The recognizer does not have a setting by that name.</span></span></exception>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous" />
      </Docs>
    </Member>
    <MemberGroup MemberName="Recognize">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary><span data-ttu-id="b4702-471">同期音声認識操作を開始します。</span><span class="sxs-lookup"><span data-stu-id="b4702-471">Starts a synchronous speech recognition operation.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-472">これらのメソッドは、単一の同期認識操作を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-472">These methods perform a single, synchronous recognition operation.</span></span> <span data-ttu-id="b4702-473">レコグナイザーは、読み込まれ、有効になっている音声認識文法に対してこの操作を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-473">The recognizer performs this operation against its loaded and enabled speech recognition grammars.</span></span>  
  
 <span data-ttu-id="b4702-474">このメソッドの呼び出し中に、レコグナイザーは次のイベントを発生させることができます。</span><span class="sxs-lookup"><span data-stu-id="b4702-474">During a call to this method, the recognizer can raise the following events:</span></span>  
  
-   <span data-ttu-id="b4702-475"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>。</span><span class="sxs-lookup"><span data-stu-id="b4702-475"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</span></span>  <span data-ttu-id="b4702-476">認識エンジンが音声として識別できる入力を検出したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-476">Raised when the recognizer detects input that it can identify as speech.</span></span>  
  
-   <span data-ttu-id="b4702-477"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>。</span><span class="sxs-lookup"><span data-stu-id="b4702-477"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</span></span>  <span data-ttu-id="b4702-478">入力時に、アクティブな文法の1つとあいまいな一致が作成されると発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-478">Raised when input creates an ambiguous match with one of the active grammars.</span></span>  
  
-   <span data-ttu-id="b4702-479"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>。</span><span class="sxs-lookup"><span data-stu-id="b4702-479"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</span></span> <span data-ttu-id="b4702-480">レコグナイザーが認識操作を終了したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-480">Raised when the recognizer finalizes a recognition operation.</span></span>  
  
 <span data-ttu-id="b4702-481"><xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> メソッドのいずれかを使用している場合、レコグナイザーは <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> イベントを発生させません。</span><span class="sxs-lookup"><span data-stu-id="b4702-481">The recognizer does not raise the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> event when using one of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> methods.</span></span>  
  
 <span data-ttu-id="b4702-482"><xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> メソッドは <xref:System.Speech.Recognition.RecognitionResult> オブジェクトを返します。操作が成功しなかった場合、またはレコグナイザーが有効になっていない場合は `null` します。</span><span class="sxs-lookup"><span data-stu-id="b4702-482">The <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> methods return a <xref:System.Speech.Recognition.RecognitionResult> object, or `null` if the operation is not successful or the recognizer is not enabled.</span></span>  
  
 <span data-ttu-id="b4702-483">同期認識操作は、次の理由により失敗する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-483">A synchronous recognition operation can fail for the following reasons:</span></span>  
  
-   <span data-ttu-id="b4702-484"><xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> のプロパティ、または <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> メソッドの `initialSilenceTimeout` パラメーターのタイムアウト間隔が経過する前に、音声が検出されません。</span><span class="sxs-lookup"><span data-stu-id="b4702-484">Speech is not detected before the timeout intervals expire for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> properties, or for the `initialSilenceTimeout` parameter of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> method.</span></span>  
  
-   <span data-ttu-id="b4702-485">認識エンジンは音声を検出しますが、読み込まれ、有効になっている <xref:System.Speech.Recognition.Grammar> オブジェクトのいずれにも一致するものが見つかりません。</span><span class="sxs-lookup"><span data-stu-id="b4702-485">The recognition engine detects speech but finds no matches in any of its loaded and enabled <xref:System.Speech.Recognition.Grammar> objects.</span></span>  
  
 <span data-ttu-id="b4702-486">認識に関して認識エンジンが音声や無音のタイミングをどのように処理するかを変更するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> の各プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-486">To modify how the recognizer handles the timing of speech or silence with respect to recognition, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> properties.</span></span>  
  
 <span data-ttu-id="b4702-487">認識を実行する前に、<xref:System.Speech.Recognition.SpeechRecognitionEngine> に少なくとも1つの <xref:System.Speech.Recognition.Grammar> オブジェクトが読み込まれている必要があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-487">The <xref:System.Speech.Recognition.SpeechRecognitionEngine> must have at least one <xref:System.Speech.Recognition.Grammar> object loaded before performing recognition.</span></span> <span data-ttu-id="b4702-488">音声認識文法を読み込むには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-488">To load a speech recognition grammar, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> method.</span></span>  
  
 <span data-ttu-id="b4702-489">非同期認識を実行するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> メソッドのいずれかを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-489">To perform asynchronous recognition, use one of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> methods.</span></span>  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="Recognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult Recognize ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult Recognize() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize" />
      <MemberSignature Language="VB.NET" Value="Public Function Recognize () As RecognitionResult" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ Recognize();" />
      <MemberSignature Language="F#" Value="member this.Recognize : unit -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognitionEngine.Recognize " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary><span data-ttu-id="b4702-490">同期音声認識操作を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-490">Performs a synchronous speech recognition operation.</span></span></summary>
        <returns><span data-ttu-id="b4702-491">入力の認識結果。操作が不適切だったり、認識エンジンが有効でない場合は <see langword="null" />。</span><span class="sxs-lookup"><span data-stu-id="b4702-491">The recognition result for the input, or <see langword="null" /> if the operation is not successful or the recognizer is not enabled.</span></span></returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-492">このメソッドは、単一の認識操作を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-492">This method performs a single recognition operation.</span></span> <span data-ttu-id="b4702-493">レコグナイザーは、読み込まれ、有効になっている音声認識文法に対してこの操作を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-493">The recognizer performs this operation against its loaded and enabled speech recognition grammars.</span></span>  
  
 <span data-ttu-id="b4702-494">このメソッドの呼び出し中に、レコグナイザーは次のイベントを発生させることができます。</span><span class="sxs-lookup"><span data-stu-id="b4702-494">During a call to this method, the recognizer can raise the following events:</span></span>  
  
-   <span data-ttu-id="b4702-495"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>。</span><span class="sxs-lookup"><span data-stu-id="b4702-495"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</span></span>  <span data-ttu-id="b4702-496">認識エンジンが音声として識別できる入力を検出したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-496">Raised when the recognizer detects input that it can identify as speech.</span></span>  
  
-   <span data-ttu-id="b4702-497"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>。</span><span class="sxs-lookup"><span data-stu-id="b4702-497"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</span></span>  <span data-ttu-id="b4702-498">入力時に、アクティブな文法の1つとあいまいな一致が作成されると発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-498">Raised when input creates an ambiguous match with one of the active grammars.</span></span>  
  
-   <span data-ttu-id="b4702-499"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>。</span><span class="sxs-lookup"><span data-stu-id="b4702-499"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</span></span> <span data-ttu-id="b4702-500">レコグナイザーが認識操作を終了したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-500">Raised when the recognizer finalizes a recognition operation.</span></span>  
  
 <span data-ttu-id="b4702-501">このメソッドを使用する場合、レコグナイザーは <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> イベントを発生させません。</span><span class="sxs-lookup"><span data-stu-id="b4702-501">The recognizer does not raise the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> event when using this method.</span></span>  
  
 <span data-ttu-id="b4702-502"><xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize> メソッドは <xref:System.Speech.Recognition.RecognitionResult> オブジェクトを返します。操作が失敗した場合は `null` します。</span><span class="sxs-lookup"><span data-stu-id="b4702-502">The <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize> method returns a <xref:System.Speech.Recognition.RecognitionResult> object, or `null` if the operation is not successful.</span></span>  
  
 <span data-ttu-id="b4702-503">同期認識操作は、次の理由により失敗する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-503">A synchronous recognition operation can fail for the following reasons:</span></span>  
  
-   <span data-ttu-id="b4702-504"><xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> プロパティのタイムアウト間隔が経過する前に、音声が検出されません。</span><span class="sxs-lookup"><span data-stu-id="b4702-504">Speech is not detected before the timeout intervals expire for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> properties.</span></span>  
  
-   <span data-ttu-id="b4702-505">認識エンジンは音声を検出しますが、読み込まれ、有効になっている <xref:System.Speech.Recognition.Grammar> オブジェクトのいずれにも一致するものが見つかりません。</span><span class="sxs-lookup"><span data-stu-id="b4702-505">The recognition engine detects speech but finds no matches in any of its loaded and enabled <xref:System.Speech.Recognition.Grammar> objects.</span></span>  
  
 <span data-ttu-id="b4702-506">非同期認識を実行するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> メソッドのいずれかを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-506">To perform asynchronous recognition, use one of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> methods.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-507">次の例は、基本的な音声認識を示すコンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-507">The following example shows part of a console application that demonstrates basic speech recognition.</span></span> <span data-ttu-id="b4702-508">この例では、<xref:System.Speech.Recognition.DictationGrammar>を作成し、それをインプロセス音声認識エンジンに読み込み、1つの認識操作を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-508">The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs one recognition operation.</span></span>  
  
```  
  
using System;  
using System.Speech.Recognition;  
  
namespace SynchronousRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      // Create an in-process speech recognizer for the en-US locale.  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(  
          new System.Globalization.CultureInfo("en-US")))  
      {  
  
        // Create and load a dictation grammar.  
        recognizer.LoadGrammar(new DictationGrammar());  
  
        // Configure input to the speech recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Modify the initial silence time-out value.  
        recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5);  
  
        // Start synchronous speech recognition.  
        RecognitionResult result = recognizer.Recognize();  
  
        if (result != null)  
        {  
          Console.WriteLine("Recognized text = {0}", result.Text);  
        }  
        else  
        {  
          Console.WriteLine("No recognition result available.");  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to continue...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)" />
      </Docs>
    </Member>
    <Member MemberName="Recognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult Recognize (TimeSpan initialSilenceTimeout);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult Recognize(valuetype System.TimeSpan initialSilenceTimeout) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)" />
      <MemberSignature Language="VB.NET" Value="Public Function Recognize (initialSilenceTimeout As TimeSpan) As RecognitionResult" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ Recognize(TimeSpan initialSilenceTimeout);" />
      <MemberSignature Language="F#" Value="member this.Recognize : TimeSpan -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognitionEngine.Recognize initialSilenceTimeout" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="initialSilenceTimeout" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="initialSilenceTimeout"><span data-ttu-id="b4702-509">音声認識エンジンが認識を終了するまでに無音のみを含む入力を受け入れる時間間隔。</span><span class="sxs-lookup"><span data-stu-id="b4702-509">The interval of time a speech recognizer accepts input containing only silence before finalizing recognition.</span></span></param>
        <summary><span data-ttu-id="b4702-510">指定した最初のサイレント状態のタイムアウト期間の同期音声認識の操作を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-510">Performs a synchronous speech recognition operation with a specified initial silence timeout period.</span></span></summary>
        <returns><span data-ttu-id="b4702-511">入力の認識結果。操作が不適切だったり、認識エンジンが有効でない場合は <see langword="null" />。</span><span class="sxs-lookup"><span data-stu-id="b4702-511">The recognition result for the input, or <see langword="null" /> if the operation is not successful or the recognizer is not enabled.</span></span></returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-512">`initialSilenceTimeout` 引数で指定された時間間隔内に音声認識エンジンが音声を検出すると、<xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%28System.TimeSpan%29> は単一の認識操作を実行して終了します。</span><span class="sxs-lookup"><span data-stu-id="b4702-512">If the speech recognition engine detects speech within the time interval specified by `initialSilenceTimeout` argument, <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%28System.TimeSpan%29> performs a single recognition operation and then terminates.</span></span>  <span data-ttu-id="b4702-513">`initialSilenceTimeout` パラメーターは、レコグナイザーの <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> プロパティよりも優先されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-513">The `initialSilenceTimeout` parameter supersedes the recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> property.</span></span>  
  
 <span data-ttu-id="b4702-514">このメソッドの呼び出し中に、レコグナイザーは次のイベントを発生させることができます。</span><span class="sxs-lookup"><span data-stu-id="b4702-514">During a call to this method, the recognizer can raise the following events:</span></span>  
  
-   <span data-ttu-id="b4702-515"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>。</span><span class="sxs-lookup"><span data-stu-id="b4702-515"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</span></span>  <span data-ttu-id="b4702-516">認識エンジンが音声として識別できる入力を検出したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-516">Raised when the recognizer detects input that it can identify as speech.</span></span>  
  
-   <span data-ttu-id="b4702-517"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>。</span><span class="sxs-lookup"><span data-stu-id="b4702-517"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</span></span>  <span data-ttu-id="b4702-518">入力時に、アクティブな文法の1つとあいまいな一致が作成されると発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-518">Raised when input creates an ambiguous match with one of the active grammars.</span></span>  
  
-   <span data-ttu-id="b4702-519"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>。</span><span class="sxs-lookup"><span data-stu-id="b4702-519"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</span></span> <span data-ttu-id="b4702-520">レコグナイザーが認識操作を終了したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-520">Raised when the recognizer finalizes a recognition operation.</span></span>  
  
 <span data-ttu-id="b4702-521">このメソッドを使用する場合、レコグナイザーは <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> イベントを発生させません。</span><span class="sxs-lookup"><span data-stu-id="b4702-521">The recognizer does not raise the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> event when using this method.</span></span>  
  
 <span data-ttu-id="b4702-522"><xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize> メソッドは <xref:System.Speech.Recognition.RecognitionResult> オブジェクトを返します。操作が失敗した場合は `null` します。</span><span class="sxs-lookup"><span data-stu-id="b4702-522">The <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize> method returns a <xref:System.Speech.Recognition.RecognitionResult> object, or `null` if the operation is not successful.</span></span>  
  
 <span data-ttu-id="b4702-523">同期認識操作は、次の理由により失敗する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-523">A synchronous recognition operation can fail for the following reasons:</span></span>  
  
-   <span data-ttu-id="b4702-524"><xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> または `initialSilenceTimeout` パラメーターのタイムアウト間隔が経過する前に、音声が検出されません。</span><span class="sxs-lookup"><span data-stu-id="b4702-524">Speech is not detected before the timeout intervals expire for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> or for the `initialSilenceTimeout` parameter.</span></span>  
  
-   <span data-ttu-id="b4702-525">認識エンジンは音声を検出しますが、読み込まれ、有効になっている <xref:System.Speech.Recognition.Grammar> オブジェクトのいずれにも一致するものが見つかりません。</span><span class="sxs-lookup"><span data-stu-id="b4702-525">The recognition engine detects speech but finds no matches in any of its loaded and enabled <xref:System.Speech.Recognition.Grammar> objects.</span></span>  
  
 <span data-ttu-id="b4702-526">非同期認識を実行するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> メソッドのいずれかを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-526">To perform asynchronous recognition, use one of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> methods.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-527">次の例は、基本的な音声認識を示すコンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-527">The following example shows part of a console application that demonstrates basic speech recognition.</span></span> <span data-ttu-id="b4702-528">この例では、<xref:System.Speech.Recognition.DictationGrammar>を作成し、それをインプロセス音声認識エンジンに読み込み、1つの認識操作を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-528">The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs one recognition operation.</span></span>  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
  
namespace SynchronousRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      // Create an in-process speech recognizer for the en-US locale.  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(  
          new System.Globalization.CultureInfo("en-US")))  
      {  
        // Create and load a dictation grammar.  
        recognizer.LoadGrammar(new DictationGrammar());  
  
        // Configure input to the speech recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Start synchronous speech recognition.  
        RecognitionResult result = recognizer.Recognize(TimeSpan.FromSeconds(5));  
  
        if (result != null)  
        {  
          Console.WriteLine("Recognized text = {0}", result.Text);  
        }  
        else  
        {  
          Console.WriteLine("No recognition result available.");  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to continue...");  
      Console.ReadKey();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)" />
      </Docs>
    </Member>
    <MemberGroup MemberName="RecognizeAsync">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary><span data-ttu-id="b4702-529">非同期音声認識操作を開始します。</span><span class="sxs-lookup"><span data-stu-id="b4702-529">Starts an asynchronous speech recognition operation.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-530">これらのメソッドは、1つまたは複数の非同期認識操作を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-530">These methods perform single or multiple, asynchronous recognition operations.</span></span> <span data-ttu-id="b4702-531">認識エンジンは、読み込まれ、有効になっている音声認識文法に対して各操作を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-531">The recognizer performs each operation against its loaded and enabled speech recognition grammars.</span></span>  
  
 <span data-ttu-id="b4702-532">このメソッドの呼び出し中に、レコグナイザーは次のイベントを発生させることができます。</span><span class="sxs-lookup"><span data-stu-id="b4702-532">During a call to this method, the recognizer can raise the following events:</span></span>  
  
-   <span data-ttu-id="b4702-533"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>。</span><span class="sxs-lookup"><span data-stu-id="b4702-533"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</span></span>  <span data-ttu-id="b4702-534">認識エンジンが音声として識別できる入力を検出したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-534">Raised when the recognizer detects input that it can identify as speech.</span></span>  
  
-   <span data-ttu-id="b4702-535"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>。</span><span class="sxs-lookup"><span data-stu-id="b4702-535"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</span></span>  <span data-ttu-id="b4702-536">入力時に、アクティブな文法の1つとあいまいな一致が作成されると発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-536">Raised when input creates an ambiguous match with one of the active grammars.</span></span>  
  
-   <span data-ttu-id="b4702-537"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>。</span><span class="sxs-lookup"><span data-stu-id="b4702-537"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</span></span> <span data-ttu-id="b4702-538">レコグナイザーが認識操作を終了したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-538">Raised when the recognizer finalizes a recognition operation.</span></span>  
  
-   <span data-ttu-id="b4702-539"><xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>。</span><span class="sxs-lookup"><span data-stu-id="b4702-539"><xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>.</span></span> <span data-ttu-id="b4702-540"><xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> 操作が終了したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-540">Raised when a <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> operation finishes.</span></span>  
  
 <span data-ttu-id="b4702-541">非同期認識操作の結果を取得するには、レコグナイザーの <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> イベントにイベントハンドラーをアタッチします。</span><span class="sxs-lookup"><span data-stu-id="b4702-541">To retrieve the result of an asynchronous recognition operation, attach an event handler to the recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> event.</span></span> <span data-ttu-id="b4702-542">レコグナイザーは、同期または非同期の認識操作が正常に完了するたびに、このイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-542">The recognizer raises this event whenever it successfully completes a synchronous or asynchronous recognition operation.</span></span> <span data-ttu-id="b4702-543">認識が成功しなかった場合、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> イベントのハンドラーでアクセスできる <xref:System.Speech.Recognition.RecognizeCompletedEventArgs> オブジェクトの <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A> プロパティが `null`されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-543">If recognition was not successful, the <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A> property on <xref:System.Speech.Recognition.RecognizeCompletedEventArgs> object, which you can access in the handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> event, will be `null`.</span></span>  
  
 <span data-ttu-id="b4702-544">非同期認識操作は、次の理由により失敗する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-544">An asynchronous recognition operation can fail for the following reasons:</span></span>  
  
-   <span data-ttu-id="b4702-545"><xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> プロパティのタイムアウト間隔が経過する前に、音声が検出されません。</span><span class="sxs-lookup"><span data-stu-id="b4702-545">Speech is not detected before the timeout intervals expire for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> properties.</span></span>  
  
-   <span data-ttu-id="b4702-546">認識エンジンは音声を検出しますが、読み込まれ、有効になっている <xref:System.Speech.Recognition.Grammar> オブジェクトのいずれにも一致するものが見つかりません。</span><span class="sxs-lookup"><span data-stu-id="b4702-546">The recognition engine detects speech but finds no matches in any of its loaded and enabled <xref:System.Speech.Recognition.Grammar> objects.</span></span>  
  
-   <span data-ttu-id="b4702-547">認識を実行する前に、<xref:System.Speech.Recognition.SpeechRecognitionEngine> に少なくとも1つの <xref:System.Speech.Recognition.Grammar> オブジェクトが読み込まれている必要があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-547">The <xref:System.Speech.Recognition.SpeechRecognitionEngine> must have at least one <xref:System.Speech.Recognition.Grammar> object loaded before performing recognition.</span></span> <span data-ttu-id="b4702-548">音声認識文法を読み込むには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-548">To load a speech recognition grammar, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> method.</span></span>  
  
-   <span data-ttu-id="b4702-549">認識に関して認識エンジンが音声や無音のタイミングをどのように処理するかを変更するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> の各プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-549">To modify how the recognizer handles the timing of speech or silence with respect to recognition, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> properties.</span></span>  
  
-   <span data-ttu-id="b4702-550">同期認識を実行するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> メソッドのいずれかを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-550">To perform synchronous recognition, use one of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> methods.</span></span>  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="RecognizeAsync">
      <MemberSignature Language="C#" Value="public void RecognizeAsync ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RecognizeAsync() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
      <MemberSignature Language="VB.NET" Value="Public Sub RecognizeAsync ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RecognizeAsync();" />
      <MemberSignature Language="F#" Value="member this.RecognizeAsync : unit -&gt; unit" Usage="speechRecognitionEngine.RecognizeAsync " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary><span data-ttu-id="b4702-551">単一の非同期音声認識操作を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-551">Performs a single, asynchronous speech recognition operation.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-552">このメソッドは、単一の非同期認識操作を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-552">This method performs a single, asynchronous recognition operation.</span></span> <span data-ttu-id="b4702-553">認識エンジンは、読み込まれ、有効になっている音声認識文法に対して操作を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-553">The recognizer performs the operation against its loaded and enabled speech recognition grammars.</span></span>  
  
 <span data-ttu-id="b4702-554">このメソッドの呼び出し中に、レコグナイザーは次のイベントを発生させることができます。</span><span class="sxs-lookup"><span data-stu-id="b4702-554">During a call to this method, the recognizer can raise the following events:</span></span>  
  
-   <span data-ttu-id="b4702-555"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>。</span><span class="sxs-lookup"><span data-stu-id="b4702-555"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</span></span>  <span data-ttu-id="b4702-556">認識エンジンが音声として識別できる入力を検出したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-556">Raised when the recognizer detects input that it can identify as speech.</span></span>  
  
-   <span data-ttu-id="b4702-557"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>。</span><span class="sxs-lookup"><span data-stu-id="b4702-557"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</span></span>  <span data-ttu-id="b4702-558">入力時に、アクティブな文法の1つとあいまいな一致が作成されると発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-558">Raised when input creates an ambiguous match with one of the active grammars.</span></span>  
  
-   <span data-ttu-id="b4702-559"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>。</span><span class="sxs-lookup"><span data-stu-id="b4702-559"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</span></span> <span data-ttu-id="b4702-560">レコグナイザーが認識操作を終了したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-560">Raised when the recognizer finalizes a recognition operation.</span></span>  
  
-   <span data-ttu-id="b4702-561"><xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>。</span><span class="sxs-lookup"><span data-stu-id="b4702-561"><xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>.</span></span> <span data-ttu-id="b4702-562"><xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> 操作が終了したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-562">Raised when a <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> operation finishes.</span></span>  
  
 <span data-ttu-id="b4702-563">非同期認識操作の結果を取得するには、レコグナイザーの <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> イベントにイベントハンドラーをアタッチします。</span><span class="sxs-lookup"><span data-stu-id="b4702-563">To retrieve the result of an asynchronous recognition operation, attach an event handler to the recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> event.</span></span> <span data-ttu-id="b4702-564">レコグナイザーは、同期または非同期の認識操作が正常に完了するたびに、このイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-564">The recognizer raises this event whenever it successfully completes a synchronous or asynchronous recognition operation.</span></span> <span data-ttu-id="b4702-565">認識が成功しなかった場合、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> イベントのハンドラーでアクセスできる <xref:System.Speech.Recognition.RecognizeCompletedEventArgs> オブジェクトの <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A> プロパティが `null`されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-565">If recognition was not successful, the <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A> property on <xref:System.Speech.Recognition.RecognizeCompletedEventArgs> object, which you can access in the handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> event, will be `null`.</span></span>  
  
 <span data-ttu-id="b4702-566">同期認識を実行するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> メソッドのいずれかを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-566">To perform synchronous recognition, use one of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> methods.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-567">次の例は、基本的な非同期音声認識を示すコンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-567">The following example shows part of a console application that demonstrates basic asynchronous speech recognition.</span></span> <span data-ttu-id="b4702-568">この例では、<xref:System.Speech.Recognition.DictationGrammar>を作成し、それをインプロセス音声認識エンジンに読み込み、1つの非同期認識操作を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-568">The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs one asynchronous recognition operation.</span></span> <span data-ttu-id="b4702-569">イベントハンドラーは、操作中にレコグナイザーによって発生するイベントを示すために含まれています。</span><span class="sxs-lookup"><span data-stu-id="b4702-569">Event handlers are included to demonstrate the events that the recognizer raises during the operation.</span></span>  
  
```csharp  
using System;  
using System.Globalization;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace AsynchronousRecognition  
{  
  class Program  
  {  
    // Indicate whether asynchronous recognition is complete.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      // Create an in-process speech recognizer.  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(new CultureInfo("en-US")))  
      {  
        // Create a grammar for choosing cities for a flight.  
        Choices cities = new Choices(new string[]   
        { "Los Angeles", "New York", "Chicago", "San Francisco", "Miami", "Dallas" });  
  
        GrammarBuilder gb = new GrammarBuilder();  
        gb.Append("I want to fly from");  
        gb.Append(cities);  
        gb.Append("to");  
        gb.Append(cities);  
  
        // Construct a Grammar object and load it to the recognizer.  
        Grammar cityChooser = new Grammar(gb);  
        cityChooser.Name = ("City Chooser");  
        recognizer.LoadGrammarAsync(cityChooser);  
  
        // Attach event handlers.  
        recognizer.SpeechDetected +=  
          new EventHandler<SpeechDetectedEventArgs>(  
            SpeechDetectedHandler);  
        recognizer.SpeechHypothesized +=  
          new EventHandler<SpeechHypothesizedEventArgs>(  
            SpeechHypothesizedHandler);  
        recognizer.SpeechRecognitionRejected +=  
          new EventHandler<SpeechRecognitionRejectedEventArgs>(  
            SpeechRecognitionRejectedHandler);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.RecognizeCompleted +=  
          new EventHandler<RecognizeCompletedEventArgs>(  
            RecognizeCompletedHandler);  
  
        // Assign input to the recognizer and start an asynchronous  
        // recognition operation.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        completed = false;  
        Console.WriteLine("Starting asynchronous recognition...");  
        recognizer.RecognizeAsync();  
  
        // Wait for the operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
        Console.WriteLine("Done.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechDetected event.  
    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine(" In SpeechDetectedHandler:");  
      Console.WriteLine(" - AudioPosition = {0}", e.AudioPosition);  
    }  
  
    // Handle the SpeechHypothesized event.  
    static void SpeechHypothesizedHandler(  
      object sender, SpeechHypothesizedEventArgs e)  
    {  
      Console.WriteLine(" In SpeechHypothesizedHandler:");  
  
      string grammarName = "<not available>";  
      string resultText = "<not available>";  
      if (e.Result != null)  
      {  
        if (e.Result.Grammar != null)  
        {  
          grammarName = e.Result.Grammar.Name;  
        }  
        resultText = e.Result.Text;  
      }  
  
      Console.WriteLine(" - Grammar Name = {0}; Result Text = {1}",  
        grammarName, resultText);  
    }  
  
    // Handle the SpeechRecognitionRejected event.  
    static void SpeechRecognitionRejectedHandler(  
      object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine(" In SpeechRecognitionRejectedHandler:");  
  
      string grammarName = "<not available>";  
      string resultText = "<not available>";  
      if (e.Result != null)  
      {  
        if (e.Result.Grammar != null)  
        {  
          grammarName = e.Result.Grammar.Name;  
        }  
        resultText = e.Result.Text;  
      }  
  
      Console.WriteLine(" - Grammar Name = {0}; Result Text = {1}",  
        grammarName, resultText);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine(" In SpeechRecognizedHandler.");  
  
      string grammarName = "<not available>";  
      string resultText = "<not available>";  
      if (e.Result != null)  
      {  
        if (e.Result.Grammar != null)  
        {  
          grammarName = e.Result.Grammar.Name;  
        }  
        resultText = e.Result.Text;  
      }  
  
      Console.WriteLine(" - Grammar Name = {0}; Result Text = {1}",  
        grammarName, resultText);  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void RecognizeCompletedHandler(  
      object sender, RecognizeCompletedEventArgs e)  
    {  
      Console.WriteLine(" In RecognizeCompletedHandler.");  
  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          " - Error occurred during recognition: {0}", e.Error);  
        return;  
      }  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          " - BabbleTimeout = {0}; InitialSilenceTimeout = {1}",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          " - AudioPosition = {0}; InputStreamEnded = {1}",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
      if (e.Result != null)  
      {  
        Console.WriteLine(  
          " - Grammar = {0}; Text = {1}; Confidence = {2}",  
          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  
        Console.WriteLine(" - AudioPosition = {0}", e.AudioPosition);  
      }  
      else  
      {  
        Console.WriteLine(" - No result.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)" />
      </Docs>
    </Member>
    <Member MemberName="RecognizeAsync">
      <MemberSignature Language="C#" Value="public void RecognizeAsync (System.Speech.Recognition.RecognizeMode mode);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RecognizeAsync(valuetype System.Speech.Recognition.RecognizeMode mode) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)" />
      <MemberSignature Language="VB.NET" Value="Public Sub RecognizeAsync (mode As RecognizeMode)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RecognizeAsync(System::Speech::Recognition::RecognizeMode mode);" />
      <MemberSignature Language="F#" Value="member this.RecognizeAsync : System.Speech.Recognition.RecognizeMode -&gt; unit" Usage="speechRecognitionEngine.RecognizeAsync mode" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="mode" Type="System.Speech.Recognition.RecognizeMode" />
      </Parameters>
      <Docs>
        <param name="mode"><span data-ttu-id="b4702-570">1 つまたは複数の認識操作を実行するかどうかを示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-570">Indicates whether to perform one or multiple recognition operations.</span></span></param>
        <summary><span data-ttu-id="b4702-571">1 つ以上の非同期音声認識操作を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-571">Performs one or more asynchronous speech recognition operations.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-572">`mode` が <xref:System.Speech.Recognition.RecognizeMode.Multiple>場合、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A> メソッドが呼び出されるまで、レコグナイザーは非同期認識操作の実行を継続します。</span><span class="sxs-lookup"><span data-stu-id="b4702-572">If `mode` is <xref:System.Speech.Recognition.RecognizeMode.Multiple>, the recognizer continues performing asynchronous recognition operations until the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A> method is called.</span></span>  
  
 <span data-ttu-id="b4702-573">このメソッドの呼び出し中に、レコグナイザーは次のイベントを発生させることができます。</span><span class="sxs-lookup"><span data-stu-id="b4702-573">During a call to this method, the recognizer can raise the following events:</span></span>  
  
-   <span data-ttu-id="b4702-574"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>。</span><span class="sxs-lookup"><span data-stu-id="b4702-574"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</span></span>  <span data-ttu-id="b4702-575">認識エンジンが音声として識別できる入力を検出したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-575">Raised when the recognizer detects input that it can identify as speech.</span></span>  
  
-   <span data-ttu-id="b4702-576"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>。</span><span class="sxs-lookup"><span data-stu-id="b4702-576"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</span></span>  <span data-ttu-id="b4702-577">入力時に、アクティブな文法の1つとあいまいな一致が作成されると発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-577">Raised when input creates an ambiguous match with one of the active grammars.</span></span>  
  
-   <span data-ttu-id="b4702-578"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>。</span><span class="sxs-lookup"><span data-stu-id="b4702-578"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</span></span> <span data-ttu-id="b4702-579">レコグナイザーが認識操作を終了したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-579">Raised when the recognizer finalizes a recognition operation.</span></span>  
  
-   <span data-ttu-id="b4702-580"><xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>。</span><span class="sxs-lookup"><span data-stu-id="b4702-580"><xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>.</span></span> <span data-ttu-id="b4702-581"><xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> 操作が終了したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-581">Raised when a <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> operation finishes.</span></span>  
  
 <span data-ttu-id="b4702-582">非同期認識操作の結果を取得するには、レコグナイザーの <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> イベントにイベントハンドラーをアタッチします。</span><span class="sxs-lookup"><span data-stu-id="b4702-582">To retrieve the result of an asynchronous recognition operation, attach an event handler to the recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> event.</span></span> <span data-ttu-id="b4702-583">レコグナイザーは、同期または非同期の認識操作が正常に完了するたびに、このイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-583">The recognizer raises this event whenever it successfully completes a synchronous or asynchronous recognition operation.</span></span> <span data-ttu-id="b4702-584">認識が成功しなかった場合、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> イベントのハンドラーでアクセスできる <xref:System.Speech.Recognition.RecognizeCompletedEventArgs> オブジェクトの <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A> プロパティが `null`されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-584">If recognition was not successful, the <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A> property on <xref:System.Speech.Recognition.RecognizeCompletedEventArgs> object, which you can access in the handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> event, will be `null`.</span></span>  
  
 <span data-ttu-id="b4702-585">非同期認識操作は、次の理由により失敗する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-585">An asynchronous recognition operation can fail for the following reasons:</span></span>  
  
-   <span data-ttu-id="b4702-586"><xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> プロパティのタイムアウト間隔が経過する前に、音声が検出されません。</span><span class="sxs-lookup"><span data-stu-id="b4702-586">Speech is not detected before the timeout intervals expire for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> properties.</span></span>  
  
-   <span data-ttu-id="b4702-587">認識エンジンは音声を検出しますが、読み込まれ、有効になっている <xref:System.Speech.Recognition.Grammar> オブジェクトのいずれにも一致するものが見つかりません。</span><span class="sxs-lookup"><span data-stu-id="b4702-587">The recognition engine detects speech but finds no matches in any of its loaded and enabled <xref:System.Speech.Recognition.Grammar> objects.</span></span>  
  
 <span data-ttu-id="b4702-588">同期認識を実行するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> メソッドのいずれかを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-588">To perform synchronous recognition, use one of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> methods.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-589">次の例は、基本的な非同期音声認識を示すコンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-589">The following example shows part of a console application that demonstrates basic asynchronous speech recognition.</span></span> <span data-ttu-id="b4702-590">この例では、<xref:System.Speech.Recognition.DictationGrammar>を作成し、それをインプロセス音声認識エンジンに読み込んで、複数の非同期認識操作を実行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-590">The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs multiple asynchronous recognition operations.</span></span> <span data-ttu-id="b4702-591">非同期操作は30秒後にキャンセルされます。</span><span class="sxs-lookup"><span data-stu-id="b4702-591">The asynchronous operations are cancelled after 30 seconds.</span></span> <span data-ttu-id="b4702-592">イベントハンドラーは、操作中にレコグナイザーによって発生するイベントを示すために含まれています。</span><span class="sxs-lookup"><span data-stu-id="b4702-592">Event handlers are included to demonstrate the events that the recognizer raises during the operation.</span></span>  
  
```csharp  
using System;  
using System.Globalization;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace AsynchronousRecognition  
{  
  class Program  
  {  
    // Indicate whether asynchronous recognition is complete.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      // Create an in-process speech recognizer.  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(new CultureInfo("en-US")))  
      {  
        // Create a grammar for choosing cities for a flight.  
        Choices cities = new Choices(new string[] { "Los Angeles", "New York", "Chicago", "San Francisco", "Miami", "Dallas" });  
  
        GrammarBuilder gb = new GrammarBuilder();  
        gb.Append("I want to fly from");  
        gb.Append(cities);  
        gb.Append("to");  
        gb.Append(cities);  
  
        // Construct a Grammar object and load it to the recognizer.  
        Grammar cityChooser = new Grammar(gb);  
        cityChooser.Name = ("City Chooser");  
        recognizer.LoadGrammarAsync(cityChooser);  
  
        // Attach event handlers.  
        recognizer.SpeechDetected +=  
          new EventHandler<SpeechDetectedEventArgs>(  
            SpeechDetectedHandler);  
        recognizer.SpeechHypothesized +=  
          new EventHandler<SpeechHypothesizedEventArgs>(  
            SpeechHypothesizedHandler);  
        recognizer.SpeechRecognitionRejected +=  
          new EventHandler<SpeechRecognitionRejectedEventArgs>(  
            SpeechRecognitionRejectedHandler);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.RecognizeCompleted +=  
          new EventHandler<RecognizeCompletedEventArgs>(  
            RecognizeCompletedHandler);  
  
        // Assign input to the recognizer and start asynchronous  
        // recognition.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        completed = false;  
        Console.WriteLine("Starting asynchronous recognition...");  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
  
        // Wait 30 seconds, and then cancel asynchronous recognition.  
        Thread.Sleep(TimeSpan.FromSeconds(30));  
        recognizer.RecognizeAsyncCancel();  
  
        // Wait for the operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
        Console.WriteLine("Done.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechDetected event.  
    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine(" In SpeechDetectedHandler:");  
      Console.WriteLine(" - AudioPosition = {0}", e.AudioPosition);  
    }  
  
    // Handle the SpeechHypothesized event.  
    static void SpeechHypothesizedHandler(  
      object sender, SpeechHypothesizedEventArgs e)  
    {  
      Console.WriteLine(" In SpeechHypothesizedHandler:");  
  
      string grammarName = "<not available>";  
      string resultText = "<not available>";  
      if (e.Result != null)  
      {  
        if (e.Result.Grammar != null)  
        {  
          grammarName = e.Result.Grammar.Name;  
        }  
        resultText = e.Result.Text;  
      }  
  
      Console.WriteLine(" - Grammar Name = {0}; Result Text = {1}",  
        grammarName, resultText);  
    }  
  
    // Handle the SpeechRecognitionRejected event.  
    static void SpeechRecognitionRejectedHandler(  
      object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine(" In SpeechRecognitionRejectedHandler:");  
  
      string grammarName = "<not available>";  
      string resultText = "<not available>";  
      if (e.Result != null)  
      {  
        if (e.Result.Grammar != null)  
        {  
          grammarName = e.Result.Grammar.Name;  
        }  
        resultText = e.Result.Text;  
      }  
  
      Console.WriteLine(" - Grammar Name = {0}; Result Text = {1}",  
        grammarName, resultText);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine(" In SpeechRecognizedHandler.");  
  
      string grammarName = "<not available>";  
      string resultText = "<not available>";  
      if (e.Result != null)  
      {  
        if (e.Result.Grammar != null)  
        {  
          grammarName = e.Result.Grammar.Name;  
        }  
        resultText = e.Result.Text;  
      }  
  
      Console.WriteLine(" - Grammar Name = {0}; Result Text = {1}",  
        grammarName, resultText);  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void RecognizeCompletedHandler(  
      object sender, RecognizeCompletedEventArgs e)  
    {  
      Console.WriteLine(" In RecognizeCompletedHandler.");  
  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          " - Error occurred during recognition: {0}", e.Error);  
        return;  
      }  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          " - BabbleTimeout = {0}; InitialSilenceTimeout = {1}",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          " - AudioPosition = {0}; InputStreamEnded = {1}",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
      if (e.Result != null)  
      {  
        Console.WriteLine(  
          " - Grammar = {0}; Text = {1}; Confidence = {2}",  
          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  
        Console.WriteLine(" - AudioPosition = {0}", e.AudioPosition);  
      }  
      else  
      {  
        Console.WriteLine(" - No result.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)" />
      </Docs>
    </Member>
    <Member MemberName="RecognizeAsyncCancel">
      <MemberSignature Language="C#" Value="public void RecognizeAsyncCancel ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RecognizeAsyncCancel() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel" />
      <MemberSignature Language="VB.NET" Value="Public Sub RecognizeAsyncCancel ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RecognizeAsyncCancel();" />
      <MemberSignature Language="F#" Value="member this.RecognizeAsyncCancel : unit -&gt; unit" Usage="speechRecognitionEngine.RecognizeAsyncCancel " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary><span data-ttu-id="b4702-593">現在の認識操作の完了を待たずに非同期認識を終了します。</span><span class="sxs-lookup"><span data-stu-id="b4702-593">Terminates asynchronous recognition without waiting for the current recognition operation to complete.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-594">このメソッドは、非同期認識を直ちに終了します。</span><span class="sxs-lookup"><span data-stu-id="b4702-594">This method immediately finalizes asynchronous recognition.</span></span> <span data-ttu-id="b4702-595">現在の非同期認識操作が入力を受信している場合、入力は切り捨てられ、操作は既存の入力で完了します。</span><span class="sxs-lookup"><span data-stu-id="b4702-595">If the current asynchronous recognition operation is receiving input, the input is truncated and the operation completes with the existing input.</span></span> <span data-ttu-id="b4702-596">このレコグナイザーは、非同期操作が取り消されたときに <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> イベントまたは <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> イベントを発生させ、<xref:System.Speech.Recognition.RecognizeCompletedEventArgs> の <xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A> プロパティを `true`に設定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-596">The recognizer raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> event when an asynchronous operation is canceled, and sets the <xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A> property of the <xref:System.Speech.Recognition.RecognizeCompletedEventArgs> to `true`.</span></span> <span data-ttu-id="b4702-597">このメソッドは、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> および <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> メソッドによって開始される非同期操作をキャンセルします。</span><span class="sxs-lookup"><span data-stu-id="b4702-597">This method cancels asynchronous operations initiated by the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> methods.</span></span>  
  
 <span data-ttu-id="b4702-598">入力を切り捨てずに非同期認識を停止するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-598">To stop asynchronous recognition without truncating the input, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A> method.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-599">次の例は、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A> メソッドの使用方法を示すコンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-599">The following example shows part of a console application that demonstrates the use of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A> method.</span></span> <span data-ttu-id="b4702-600">この例では、音声認識の文法を作成して読み込み、継続的な非同期認識操作を開始した後、2秒間を一時停止してから操作をキャンセルします。</span><span class="sxs-lookup"><span data-stu-id="b4702-600">The example creates and loads a speech recognition grammar, initiates a continuing asynchronous recognition operation, and then pauses 2 seconds before it cancels the operation.</span></span> <span data-ttu-id="b4702-601">このレコグナイザーは、c:\temp\audioinput\sample.wav. ファイルから入力を受け取ります。</span><span class="sxs-lookup"><span data-stu-id="b4702-601">The recognizer receives input from the file, c:\temp\audioinput\sample.wav.</span></span> <span data-ttu-id="b4702-602">イベントハンドラーは、操作中にレコグナイザーによって発生するイベントを示すために含まれています。</span><span class="sxs-lookup"><span data-stu-id="b4702-602">Event handlers are included to demonstrate the events that the recognizer raises during the operation.</span></span>  
  
```csharp  
  
using System;  
using System.Globalization;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace AsynchronousRecognition  
{  
  class Program  
  {  
    // Indicate whether asynchronous recognition is complete.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      // Create an in-process speech recognizer.  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(new CultureInfo("en-US")))  
      {  
        // Create and load a dictation grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation Grammar";  
  
        recognizer.LoadGrammar(dictation);  
  
        // Attach event handlers.  
        recognizer.SpeechDetected +=  
          new EventHandler<SpeechDetectedEventArgs>(  
            SpeechDetectedHandler);  
        recognizer.SpeechHypothesized +=  
          new EventHandler<SpeechHypothesizedEventArgs>(  
            SpeechHypothesizedHandler);  
        recognizer.SpeechRecognitionRejected +=  
          new EventHandler<SpeechRecognitionRejectedEventArgs>(  
            SpeechRecognitionRejectedHandler);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.RecognizeCompleted +=  
          new EventHandler<RecognizeCompletedEventArgs>(  
            RecognizeCompletedHandler);  
  
        // Begin asynchronous recognition from pre-recorded input.  
        recognizer.SetInputToWaveFile(@"c:\temp\audioinput\sample.wav");  
  
        completed = false;  
        Console.WriteLine("Begin continuing asynchronous recognition...");  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
  
        // Wait 2 seconds and then cancel the recognition operation.  
        Thread.Sleep(TimeSpan.FromSeconds(2));  
        recognizer.RecognizeAsyncCancel();  
  
        // Wait for the operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        Console.WriteLine("Done.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechDetected event.  
    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine(" In SpeechDetectedHandler:");  
      Console.WriteLine(" - AudioPosition = {0}", e.AudioPosition);  
    }  
  
    // Handle the SpeechHypothesized event.  
    static void SpeechHypothesizedHandler(  
      object sender, SpeechHypothesizedEventArgs e)  
    {  
      Console.WriteLine(" In SpeechHypothesizedHandler:");  
  
      string grammarName = "<not available>";  
      string resultText = "<not available>";  
      if (e.Result != null)  
      {  
        if (e.Result.Grammar != null)  
        {  
          grammarName = e.Result.Grammar.Name;  
        }  
        resultText = e.Result.Text;  
      }  
  
      Console.WriteLine(" - Grammar Name = {0}; Result Text = {1}",  
        grammarName, resultText);  
    }  
  
    // Handle the SpeechRecognitionRejected event.  
    static void SpeechRecognitionRejectedHandler(  
      object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine(" In SpeechRecognitionRejectedHandler:");  
  
      string grammarName = "<not available>";  
      string resultText = "<not available>";  
      if (e.Result != null)  
      {  
        if (e.Result.Grammar != null)  
        {  
          grammarName = e.Result.Grammar.Name;  
        }  
        resultText = e.Result.Text;  
      }  
  
      Console.WriteLine(" - Grammar Name = {0}; Result Text = {1}",  
        grammarName, resultText);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine(" In SpeechRecognizedHandler.");  
  
      string grammarName = "<not available>";  
      string resultText = "<not available>";  
      if (e.Result != null)  
      {  
        if (e.Result.Grammar != null)  
        {  
          grammarName = e.Result.Grammar.Name;  
        }  
        resultText = e.Result.Text;  
      }  
  
      Console.WriteLine(" - Grammar Name = {0}; Result Text = {1}",  
        grammarName, resultText);  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void RecognizeCompletedHandler(  
      object sender, RecognizeCompletedEventArgs e)  
    {  
      Console.WriteLine(" In RecognizeCompletedHandler.");  
  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          " - Error occurred during recognition: {0}", e.Error);  
        return;  
      }  
      if (e.Cancelled)  
      {  
        Console.WriteLine(" - asynchronous operation canceled.");  
      }  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          " - BabbleTimeout = {0}; InitialSilenceTimeout = {1}",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          " - AudioPosition = {0}; InputStreamEnded = {1}",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
      if (e.Result != null)  
      {  
        Console.WriteLine(  
          " - Grammar = {0}; Text = {1}; Confidence = {2}",  
          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  
      }  
      else  
      {  
        Console.WriteLine(" - No result.");  
      }  
  
      completed = true;  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted" />
      </Docs>
    </Member>
    <Member MemberName="RecognizeAsyncStop">
      <MemberSignature Language="C#" Value="public void RecognizeAsyncStop ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RecognizeAsyncStop() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop" />
      <MemberSignature Language="VB.NET" Value="Public Sub RecognizeAsyncStop ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RecognizeAsyncStop();" />
      <MemberSignature Language="F#" Value="member this.RecognizeAsyncStop : unit -&gt; unit" Usage="speechRecognitionEngine.RecognizeAsyncStop " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary><span data-ttu-id="b4702-603">現在の認識操作の完了後に非同期認識を停止します。</span><span class="sxs-lookup"><span data-stu-id="b4702-603">Stops asynchronous recognition after the current recognition operation completes.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-604">このメソッドは、入力を切り捨てずに非同期認識を終了します。</span><span class="sxs-lookup"><span data-stu-id="b4702-604">This method finalizes asynchronous recognition without truncating input.</span></span> <span data-ttu-id="b4702-605">現在の非同期認識操作が入力を受信している場合、認識エンジンは、現在の認識操作が完了するまで入力の受け入れを続行します。</span><span class="sxs-lookup"><span data-stu-id="b4702-605">If the current asynchronous recognition operation is receiving input, the recognizer continues accepting input until the current recognition operation is completed.</span></span> <span data-ttu-id="b4702-606">このレコグナイザーは、非同期操作が停止したときに <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> イベントまたは <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> イベントを発生させ、<xref:System.Speech.Recognition.RecognizeCompletedEventArgs> の <xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A> プロパティを `true`に設定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-606">The recognizer raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> event when an asynchronous operation is stopped, and sets the <xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A> property of the <xref:System.Speech.Recognition.RecognizeCompletedEventArgs> to `true`.</span></span> <span data-ttu-id="b4702-607">このメソッドは、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> および <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> メソッドによって開始される非同期操作を停止します。</span><span class="sxs-lookup"><span data-stu-id="b4702-607">This method stops asynchronous operations initiated by the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> methods.</span></span>  
  
 <span data-ttu-id="b4702-608">既存の入力のみを使用して非同期認識を直ちに取り消すには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-608">To immediately cancel asynchronous recognition with only the existing input, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A> method.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-609">次の例は、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A> メソッドの使用方法を示すコンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-609">The following example shows part of a console application that demonstrates the use of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A> method.</span></span> <span data-ttu-id="b4702-610">この例では、音声認識の文法を作成して読み込み、継続的な非同期認識操作を開始した後、2秒間を一時停止してから操作を停止します。</span><span class="sxs-lookup"><span data-stu-id="b4702-610">The example creates and loads a speech recognition grammar, initiates a continuing asynchronous recognition operation, and then pauses 2 seconds before it stops the operation.</span></span> <span data-ttu-id="b4702-611">このレコグナイザーは、c:\temp\audioinput\sample.wav. ファイルから入力を受け取ります。</span><span class="sxs-lookup"><span data-stu-id="b4702-611">The recognizer receives input from the file, c:\temp\audioinput\sample.wav.</span></span> <span data-ttu-id="b4702-612">イベントハンドラーは、操作中にレコグナイザーによって発生するイベントを示すために含まれています。</span><span class="sxs-lookup"><span data-stu-id="b4702-612">Event handlers are included to demonstrate the events that the recognizer raises during the operation.</span></span>  
  
```csharp  
  
using System;  
using System.Globalization;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace AsynchronousRecognition  
{  
  class Program  
  {  
    // Indicate whether asynchronous recognition is complete.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      // Create an in-process speech recognizer.  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(new CultureInfo("en-US")))  
      {  
        // Create and load a dictation grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation Grammar";  
  
        recognizer.LoadGrammar(dictation);  
  
        // Attach event handlers.  
        recognizer.SpeechDetected +=  
          new EventHandler<SpeechDetectedEventArgs>(  
            SpeechDetectedHandler);  
        recognizer.SpeechHypothesized +=  
          new EventHandler<SpeechHypothesizedEventArgs>(  
            SpeechHypothesizedHandler);  
        recognizer.SpeechRecognitionRejected +=  
          new EventHandler<SpeechRecognitionRejectedEventArgs>(  
            SpeechRecognitionRejectedHandler);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.RecognizeCompleted +=  
          new EventHandler<RecognizeCompletedEventArgs>(  
            RecognizeCompletedHandler);  
  
        // Begin asynchronous recognition from pre-recorded input.  
        recognizer.SetInputToWaveFile(@"c:\temp\audioinput\sample.wav");  
  
        completed = false;  
        Console.WriteLine("Begin continuing asynchronous recognition...");  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
  
        // Wait 2 seconds and then stop the recognition operation.  
        Thread.Sleep(TimeSpan.FromSeconds(2));  
        recognizer.RecognizeAsyncStop();  
  
        // Wait for the operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        Console.WriteLine("Done.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechDetected event.  
    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine(" In SpeechDetectedHandler:");  
      Console.WriteLine(" - AudioPosition = {0}", e.AudioPosition);  
    }  
  
    // Handle the SpeechHypothesized event.  
    static void SpeechHypothesizedHandler(  
      object sender, SpeechHypothesizedEventArgs e)  
    {  
      Console.WriteLine(" In SpeechHypothesizedHandler:");  
  
      string grammarName = "<not available>";  
      string resultText = "<not available>";  
      if (e.Result != null)  
      {  
        if (e.Result.Grammar != null)  
        {  
          grammarName = e.Result.Grammar.Name;  
        }  
        resultText = e.Result.Text;  
      }  
  
      Console.WriteLine(" - Grammar Name = {0}; Result Text = {1}",  
        grammarName, resultText);  
    }  
  
    // Handle the SpeechRecognitionRejected event.  
    static void SpeechRecognitionRejectedHandler(  
      object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine(" In SpeechRecognitionRejectedHandler:");  
  
      string grammarName = "<not available>";  
      string resultText = "<not available>";  
      if (e.Result != null)  
      {  
        if (e.Result.Grammar != null)  
        {  
          grammarName = e.Result.Grammar.Name;  
        }  
        resultText = e.Result.Text;  
      }  
  
      Console.WriteLine(" - Grammar Name = {0}; Result Text = {1}",  
        grammarName, resultText);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine(" In SpeechRecognizedHandler.");  
  
      string grammarName = "<not available>";  
      string resultText = "<not available>";  
      if (e.Result != null)  
      {  
        if (e.Result.Grammar != null)  
        {  
          grammarName = e.Result.Grammar.Name;  
        }  
        resultText = e.Result.Text;  
      }  
  
      Console.WriteLine(" - Grammar Name = {0}; Result Text = {1}",  
        grammarName, resultText);  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void RecognizeCompletedHandler(  
      object sender, RecognizeCompletedEventArgs e)  
    {  
      Console.WriteLine(" In RecognizeCompletedHandler.");  
  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          " - Error occurred during recognition: {0}", e.Error);  
        return;  
      }  
      if (e.Cancelled)  
      {  
        Console.WriteLine(" - asynchronous operation canceled.");  
      }  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          " - BabbleTimeout = {0}; InitialSilenceTimeout = {1}",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          " - AudioPosition = {0}; InputStreamEnded = {1}",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
      if (e.Result != null)  
      {  
        Console.WriteLine(  
          " - Grammar = {0}; Text = {1}; Confidence = {2}",  
          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  
      }  
      else  
      {  
        Console.WriteLine(" - No result.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted" />
      </Docs>
    </Member>
    <Member MemberName="RecognizeCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.RecognizeCompletedEventArgs&gt; RecognizeCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.RecognizeCompletedEventArgs&gt; RecognizeCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event RecognizeCompleted As EventHandler(Of RecognizeCompletedEventArgs) " FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::RecognizeCompletedEventArgs ^&gt; ^ RecognizeCompleted;" />
      <MemberSignature Language="F#" Value="member this.RecognizeCompleted : EventHandler&lt;System.Speech.Recognition.RecognizeCompletedEventArgs&gt; " Usage="member this.RecognizeCompleted : System.EventHandler&lt;System.Speech.Recognition.RecognizeCompletedEventArgs&gt; " />
      <MemberSignature Language="VB.NET" Value="Public Event RecognizeCompleted As EventHandler(Of RecognizeCompletedEventArgs) " FrameworkAlternate="netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-613"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> が非同期認識操作を終了すると発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-613">Raised when the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> finalizes an asynchronous recognition operation.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-614"><xref:System.Speech.Recognition.SpeechRecognitionEngine> オブジェクトの <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> メソッドは、非同期認識操作を開始します。</span><span class="sxs-lookup"><span data-stu-id="b4702-614">The <xref:System.Speech.Recognition.SpeechRecognitionEngine> object's <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> method initiates an asynchronous recognition operation.</span></span> <span data-ttu-id="b4702-615">レコグナイザーが非同期操作を終了すると、このイベントが発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-615">When the recognizer finalizes the asynchronous operation, it raises this event.</span></span>  
  
 <span data-ttu-id="b4702-616"><xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> イベントのハンドラーを使用すると、<xref:System.Speech.Recognition.RecognizeCompletedEventArgs> オブジェクトの <xref:System.Speech.Recognition.RecognitionResult> にアクセスできます。</span><span class="sxs-lookup"><span data-stu-id="b4702-616">Using the handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> event, you can access the <xref:System.Speech.Recognition.RecognitionResult> in the <xref:System.Speech.Recognition.RecognizeCompletedEventArgs> object.</span></span> <span data-ttu-id="b4702-617">認識が成功しなかった場合は、<xref:System.Speech.Recognition.RecognitionResult> が `null`されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-617">If recognition was not successful, <xref:System.Speech.Recognition.RecognitionResult> will be `null`.</span></span> <span data-ttu-id="b4702-618">タイムアウトまたはオーディオ入力の中断によって認識が失敗したかどうかを判断するために、<xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A>、<xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A>、または <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A>のプロパティにアクセスできます。</span><span class="sxs-lookup"><span data-stu-id="b4702-618">To determine whether a timeout or an interruption in audio input caused recognition to fail, you can access the properties for <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A>, or <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A>.</span></span>  
  
 <span data-ttu-id="b4702-619">詳細については、<xref:System.Speech.Recognition.RecognizeCompletedEventArgs> クラスを参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-619">See the <xref:System.Speech.Recognition.RecognizeCompletedEventArgs> class for more information.</span></span>  
  
 <span data-ttu-id="b4702-620">最も拒否されている認識候補の詳細を取得するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> イベントのハンドラーをアタッチします。</span><span class="sxs-lookup"><span data-stu-id="b4702-620">To obtain details on the best rejected recognition candidates, attach a handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> event.</span></span>  
  
 <span data-ttu-id="b4702-621"><xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> デリゲートを作成する場合は、イベントを処理するメソッドを指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-621">When you create a <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> delegate, you identify the method that will handle the event.</span></span> <span data-ttu-id="b4702-622">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="b4702-622">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="b4702-623">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-623">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="b4702-624">イベントハンドラーデリゲートの詳細については、「[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-624">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-625">次の例では、"ジャズカテゴリのアーティストの一覧を表示する" または "アルバムの表示 gospel" のような語句を認識しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-625">The following example recognizes phrases such as "Display the list of artists in the jazz category" or "Display albums gospel".</span></span> <span data-ttu-id="b4702-626">この例では、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> イベントのハンドラーを使用して、コンソールでの認識の結果に関する情報を表示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-626">The example uses a handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> event to display information about the results of recognition in the console.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize an in-process speech recognition engine.  
    {  
      using (SpeechRecognitionEngine recognizer =  
         new SpeechRecognitionEngine())  
      {  
  
        //  Create lists of alternative choices.  
        Choices listTypes = new Choices(new string[] { "albums", "artists" });  
        Choices genres = new Choices(new string[] {   
          "blues", "classical", "gospel", "jazz", "rock" });  
  
        //  Create a GrammarBuilder object and assemble the grammar components.  
        GrammarBuilder mediaMenu = new GrammarBuilder("Display");  
        mediaMenu.Append("the list of", 0, 1);  
        mediaMenu.Append(listTypes);  
        mediaMenu.Append("in the", 0, 1);  
        mediaMenu.Append(genres);  
        mediaMenu.Append("category.", 0, 1);  
  
        //  Build a Grammar object from the GrammarBuilder.  
        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  
        mediaMenuGrammar.Name = "Media Chooser";  
  
        // Attach event handlers.  
        recognizer.RecognizeCompleted +=  
          new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  
        recognizer.LoadGrammarCompleted +=   
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(mediaMenuGrammar);  
  
        // Set the input to the recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Start asynchronous, continuous recognition.  
        recognizer.RecognizeAsync();  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  
    {  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted, error occurred during recognition: {0}", e.Error);  
        return;  
      }  
  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
  
      if (e.Result != null)  
      {  
        Console.WriteLine("RecognizeCompleted:");  
        Console.WriteLine("  Grammar: " + e.Result.Grammar.Name);  
        Console.WriteLine("  Recognized text: " + e.Result.Text);  
        Console.WriteLine("  Confidence score: " + e.Result.Confidence);  
        Console.WriteLine("  Audio position: " + e.AudioPosition);  
      }  
  
      else  
      {  
        Console.WriteLine("RecognizeCompleted: No result.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded:  " + e.Grammar.Name);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizeCompletedEventArgs" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerAudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan RecognizerAudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan RecognizerAudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property RecognizerAudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan RecognizerAudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.RecognizerAudioPosition : TimeSpan" Usage="System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-627">処理中のオーディオ入力内の <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> の現在の位置を取得します。</span><span class="sxs-lookup"><span data-stu-id="b4702-627">Gets the current location of the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> in the audio input that it is processing.</span></span></summary>
        <value><span data-ttu-id="b4702-628">処理中のオーディオ入力の認識エンジンの位置。</span><span class="sxs-lookup"><span data-stu-id="b4702-628">The position of the recognizer in the audio input that it is processing.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-629">オーディオの位置は、各音声認識エンジンに固有です。</span><span class="sxs-lookup"><span data-stu-id="b4702-629">The audio position is specific to each speech recognizer.</span></span> <span data-ttu-id="b4702-630">入力ストリームの0の値は、有効になったときに確立されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-630">The zero value of an input stream is established when it is enabled.</span></span>  
  
 <span data-ttu-id="b4702-631"><xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> プロパティは、そのオーディオ入力内の <xref:System.Speech.Recognition.SpeechRecognitionEngine> オブジェクトの位置を参照します。</span><span class="sxs-lookup"><span data-stu-id="b4702-631">The <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> property references the <xref:System.Speech.Recognition.SpeechRecognitionEngine> object's position within its audio input.</span></span> <span data-ttu-id="b4702-632">これに対し、<xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> プロパティは、生成されたオーディオストリーム内の入力デバイスの位置を参照します。</span><span class="sxs-lookup"><span data-stu-id="b4702-632">By contrast, the <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> property references the input device's position in its generated audio stream.</span></span> <span data-ttu-id="b4702-633">これらの位置は異なる場合があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-633">These positions can be different.</span></span> <span data-ttu-id="b4702-634">たとえば、認識結果がまだ生成されていない認識エンジンが入力を受け取った場合、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> プロパティの値は <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> プロパティの値よりも小さくなります。</span><span class="sxs-lookup"><span data-stu-id="b4702-634">For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> property is less than the value of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> property.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerInfo">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizerInfo RecognizerInfo { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.RecognizerInfo RecognizerInfo" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property RecognizerInfo As RecognizerInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizerInfo ^ RecognizerInfo { System::Speech::Recognition::RecognizerInfo ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.RecognizerInfo : System.Speech.Recognition.RecognizerInfo" Usage="System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-635"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> の現在のインスタンスに関する情報を取得します。</span><span class="sxs-lookup"><span data-stu-id="b4702-635">Gets information about the current instance of <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />.</span></span></summary>
        <value><span data-ttu-id="b4702-636">現在の音声認識エンジンに関する情報です。</span><span class="sxs-lookup"><span data-stu-id="b4702-636">Information about the current speech recognizer.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-637">現在のシステムにインストールされているすべての音声認識エンジンに関する情報を取得するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-637">To get information about all of the installed speech recognizers for the current system, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A> method.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-638">次の例では、現在のインプロセス音声認識エンジンのデータの一部を取得します。</span><span class="sxs-lookup"><span data-stu-id="b4702-638">The following example gets a partial list of data for the current in-process speech recognition engine.</span></span> <span data-ttu-id="b4702-639">詳細については、「<xref:System.Speech.Recognition.RecognizerInfo>」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-639">For more information, see <xref:System.Speech.Recognition.RecognizerInfo>.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace RecognitionEngine  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      using (SpeechRecognitionEngine recognizer = new SpeechRecognitionEngine())  
      {  
        Console.WriteLine("Information for the current speech recognition engine:");  
        Console.WriteLine("  Name: {0}", recognizer.RecognizerInfo.Name);  
        Console.WriteLine("  Culture: {0}", recognizer.RecognizerInfo.Culture.ToString());  
        Console.WriteLine("  Description: {0}", recognizer.RecognizerInfo.Description);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerUpdateReached">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; RecognizerUpdateReached;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; RecognizerUpdateReached" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event RecognizerUpdateReached As EventHandler(Of RecognizerUpdateReachedEventArgs) " FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::RecognizerUpdateReachedEventArgs ^&gt; ^ RecognizerUpdateReached;" />
      <MemberSignature Language="F#" Value="member this.RecognizerUpdateReached : EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; " Usage="member this.RecognizerUpdateReached : System.EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; " />
      <MemberSignature Language="VB.NET" Value="Public Event RecognizerUpdateReached As EventHandler(Of RecognizerUpdateReachedEventArgs) " FrameworkAlternate="netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-640">変更を受け入れるために実行中の <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> を一時停止すると発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-640">Raised when a running <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> pauses to accept modifications.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-641">アプリケーションでは、設定またはその <xref:System.Speech.Recognition.Grammar> オブジェクトを変更する前に、<xref:System.Speech.Recognition.SpeechRecognitionEngine> の実行中のインスタンスを一時停止するために <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> を使用する必要があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-641">Applications must use <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> to pause a running instance of <xref:System.Speech.Recognition.SpeechRecognitionEngine> before modifying its settings or its <xref:System.Speech.Recognition.Grammar> objects.</span></span> <span data-ttu-id="b4702-642"><xref:System.Speech.Recognition.SpeechRecognitionEngine> は、変更を受け入れる準備が整ったときにこのイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-642">The <xref:System.Speech.Recognition.SpeechRecognitionEngine> raises this event when it is ready to accept modifications.</span></span>  
  
 <span data-ttu-id="b4702-643">たとえば、<xref:System.Speech.Recognition.SpeechRecognitionEngine> が一時停止されている間、<xref:System.Speech.Recognition.Grammar> オブジェクトの読み込み、アンロード、有効化、無効化、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> の各プロパティの値の変更を行うことができます。</span><span class="sxs-lookup"><span data-stu-id="b4702-643">For example, while the <xref:System.Speech.Recognition.SpeechRecognitionEngine> is paused, you can load, unload, enable, and disable <xref:System.Speech.Recognition.Grammar> objects, and modify values for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> properties.</span></span> <span data-ttu-id="b4702-644">詳細については、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> メソッドを参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-644">For more information, see the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> method.</span></span>  
  
 <span data-ttu-id="b4702-645"><xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> デリゲートを作成する場合は、イベントを処理するメソッドを指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-645">When you create a <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> delegate, you identify the method that will handle the event.</span></span> <span data-ttu-id="b4702-646">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="b4702-646">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="b4702-647">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-647">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="b4702-648">イベントハンドラーデリゲートの詳細については、「[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-648">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-649">次の例は、<xref:System.Speech.Recognition.Grammar> オブジェクトを読み込んでアンロードするコンソールアプリケーションを示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-649">The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects.</span></span> <span data-ttu-id="b4702-650">アプリケーションでは、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> メソッドを使用して音声認識エンジンが一時停止するように要求し、更新プログラムを受信できるようにします。</span><span class="sxs-lookup"><span data-stu-id="b4702-650">The application uses the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> method to request the speech recognition engine to pause so it can receive an update.</span></span> <span data-ttu-id="b4702-651">その後、アプリケーションは、<xref:System.Speech.Recognition.Grammar> オブジェクトを読み込むかアンロードします。</span><span class="sxs-lookup"><span data-stu-id="b4702-651">The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.</span></span>  
  
 <span data-ttu-id="b4702-652">更新のたびに、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> イベントのハンドラーが、現在読み込まれている <xref:System.Speech.Recognition.Grammar> オブジェクトの名前と状態をコンソールに書き込みます。</span><span class="sxs-lookup"><span data-stu-id="b4702-652">At each update, a handler for <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console.</span></span> <span data-ttu-id="b4702-653">文法が読み込まれてアンロードされると、アプリケーションは最初にファームの動物の名前、次にファームの動物の名前と果物の名前を認識し、次に果物の名前のみを認識します。</span><span class="sxs-lookup"><span data-stu-id="b4702-653">As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognition engine and configure its input.  
      using (recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US")))  
      {  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Create the first grammar - Farm.  
        Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
        GrammarBuilder farm = new GrammarBuilder(animals);  
        Grammar farmAnimals = new Grammar(farm);  
        farmAnimals.Name = "Farm";  
  
        // Create the second grammar - Fruit.  
        Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
        GrammarBuilder favorite = new GrammarBuilder(fruit);  
        Grammar favoriteFruit = new Grammar(favorite);  
        favoriteFruit.Name = "Fruit";  
  
        // Attach event handlers.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.RecognizerUpdateReached +=  
          new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
        recognizer.SpeechRecognitionRejected +=  
          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  
  
        // Load the Farm grammar.  
        recognizer.LoadGrammar(farmAnimals);  
  
        // Start asynchronous, continuous recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
        Console.WriteLine("Starting asynchronous, continuous recognition");  
        Console.WriteLine("  Farm grammar is loaded and enabled.");  
  
        // Pause to recognize farm animals.  
        Thread.Sleep(7000);  
        Console.WriteLine();  
  
        // Request an update and load the Fruit grammar.  
        recognizer.RequestRecognizerUpdate();  
        recognizer.LoadGrammarAsync(favoriteFruit);  
        Thread.Sleep(7000);  
  
        // Request an update and unload the Farm grammar.  
        recognizer.RequestRecognizerUpdate();  
        recognizer.UnloadGrammar(farmAnimals);  
        Thread.Sleep(7000);  
      }  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // At the update, get the names and enabled status of the currently loaded grammars.  
    public static void recognizer_RecognizerUpdateReached(  
      object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  {0} grammar is loaded and {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("    Speech recognized: " + e.Result.Text);  
    }  
  
    // Write a message to the console when recognition fails.  
    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine("    Recognition attempt failed");  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerUpdateReachedEventArgs" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate" />
        <altmember cref="T:System.Speech.Recognition.SpeechDetectedEventArgs" />
      </Docs>
    </Member>
    <MemberGroup MemberName="RequestRecognizerUpdate">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary><span data-ttu-id="b4702-654">認識エンジンが状態の更新を停止することを要求します。</span><span class="sxs-lookup"><span data-stu-id="b4702-654">Requests that the recognizer pauses to update its state.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-655">このメソッドを使用して、認識エンジンに対する変更を同期します。</span><span class="sxs-lookup"><span data-stu-id="b4702-655">Use this method to synchronize changes to the recognizer.</span></span> <span data-ttu-id="b4702-656">たとえば、レコグナイザーが入力を処理しているときに音声認識文法を読み込んだりアンロードしたりする場合は、このメソッドと <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> イベントを使用して、アプリケーションの動作とレコグナイザーの状態を同期します。</span><span class="sxs-lookup"><span data-stu-id="b4702-656">For example, if you load or unload a speech recognition grammar while the recognizer is processing input, use this method and the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event to synchronize your application behavior with the state of the recognizer.</span></span>  
  
 <span data-ttu-id="b4702-657">このメソッドが呼び出されると、レコグナイザーは非同期操作を一時停止または完了し、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> イベントを生成します。</span><span class="sxs-lookup"><span data-stu-id="b4702-657">When this method is called, the recognizer pauses or completes asynchronous operations and generates a <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event.</span></span> <span data-ttu-id="b4702-658">これにより、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> のイベントハンドラーは、認識操作の間でレコグナイザーの状態を変更できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-658">A <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event handler can then modify the state of the recognizer in between recognition operations.</span></span> <span data-ttu-id="b4702-659"><xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> イベントを処理する場合、レコグナイザーはイベントハンドラーが戻るまで一時停止します。</span><span class="sxs-lookup"><span data-stu-id="b4702-659">When handling <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> events, the recognizer pauses until the event handler returns.</span></span>  
  
> [!NOTE]
>  <span data-ttu-id="b4702-660">レコグナイザーが <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> イベントを発生させる前に認識エンジンへの入力が変更された場合、要求は破棄されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-660">If the input to the recognizer is changed before the recognizer raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event, the request is discarded.</span></span>  
  
 <span data-ttu-id="b4702-661">このメソッドが呼び出されたとき:</span><span class="sxs-lookup"><span data-stu-id="b4702-661">When this method is called:</span></span>  
  
-   <span data-ttu-id="b4702-662">認識エンジンが入力を処理していない場合、レコグナイザーは直ちに <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> イベントを生成します。</span><span class="sxs-lookup"><span data-stu-id="b4702-662">If the recognizer is not processing input, the recognizer immediately generates the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event.</span></span>  
  
-   <span data-ttu-id="b4702-663">レコグナイザーが、無音またはバックグラウンドノイズで構成される入力を処理している場合、認識エンジンは認識操作を一時停止し、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> イベントを生成します。</span><span class="sxs-lookup"><span data-stu-id="b4702-663">If the recognizer is processing input that consists of silence or background noise, the recognizer pauses the recognition operation and generates the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event.</span></span>  
  
-   <span data-ttu-id="b4702-664">レコグナイザーが、無音またはバックグラウンドノイズで構成されていない入力を処理している場合、認識エンジンは認識操作を完了し、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> イベントを生成します。</span><span class="sxs-lookup"><span data-stu-id="b4702-664">If the recognizer is processing input that does not consist of silence or background noise, the recognizer completes the recognition operation and then generates the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event.</span></span>  
  
 <span data-ttu-id="b4702-665">認識エンジンは <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> イベントを処理しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-665">While the recognizer is handling the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event:</span></span>  
  
-   <span data-ttu-id="b4702-666">認識エンジンは入力を処理しません。 <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> プロパティの値は変わりません。</span><span class="sxs-lookup"><span data-stu-id="b4702-666">The recognizer does not process input, and the value of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> property remains the same.</span></span>  
  
-   <span data-ttu-id="b4702-667">認識エンジンは引き続き入力を収集し、<xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> プロパティの値は変更される可能性があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-667">The recognizer continues to collect input, and the value of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> property can change.</span></span>  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate();" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : unit -&gt; unit" Usage="speechRecognitionEngine.RequestRecognizerUpdate " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary><span data-ttu-id="b4702-668">認識エンジンが状態の更新を停止することを要求します。</span><span class="sxs-lookup"><span data-stu-id="b4702-668">Requests that the recognizer pauses to update its state.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-669">レコグナイザーで <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> イベントが生成されると、<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> の <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> プロパティが `null`ます。</span><span class="sxs-lookup"><span data-stu-id="b4702-669">When the recognizer generates the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event, the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> property of the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> is `null`.</span></span>  
  
 <span data-ttu-id="b4702-670">ユーザートークンを提供するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-670">To provide a user token, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> method.</span></span> <span data-ttu-id="b4702-671">オーディオ位置のオフセットを指定するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-671">To specify an audio position offset, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> method.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-672">次の例は、<xref:System.Speech.Recognition.Grammar> オブジェクトを読み込んでアンロードするコンソールアプリケーションを示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-672">The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects.</span></span> <span data-ttu-id="b4702-673">アプリケーションでは、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> メソッドを使用して音声認識エンジンが一時停止するように要求し、更新プログラムを受信できるようにします。</span><span class="sxs-lookup"><span data-stu-id="b4702-673">The application uses the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> method to request the speech recognition engine to pause so it can receive an update.</span></span> <span data-ttu-id="b4702-674">その後、アプリケーションは、<xref:System.Speech.Recognition.Grammar> オブジェクトを読み込むかアンロードします。</span><span class="sxs-lookup"><span data-stu-id="b4702-674">The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.</span></span>  
  
 <span data-ttu-id="b4702-675">更新のたびに、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> イベントのハンドラーが、現在読み込まれている <xref:System.Speech.Recognition.Grammar> オブジェクトの名前と状態をコンソールに書き込みます。</span><span class="sxs-lookup"><span data-stu-id="b4702-675">At each update, a handler for <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console.</span></span> <span data-ttu-id="b4702-676">文法が読み込まれてアンロードされると、アプリケーションは最初にファームの動物の名前、次にファームの動物の名前と果物の名前を認識し、次に果物の名前のみを認識します。</span><span class="sxs-lookup"><span data-stu-id="b4702-676">As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognition engine and configure its input.  
      using (recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US")))  
      {  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Create the first grammar - Farm.  
        Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
        GrammarBuilder farm = new GrammarBuilder(animals);  
        Grammar farmAnimals = new Grammar(farm);  
        farmAnimals.Name = "Farm";  
  
        // Create the second grammar - Fruit.  
        Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
        GrammarBuilder favorite = new GrammarBuilder(fruit);  
        Grammar favoriteFruit = new Grammar(favorite);  
        favoriteFruit.Name = "Fruit";  
  
        // Attach event handlers.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.RecognizerUpdateReached +=  
          new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
        recognizer.SpeechRecognitionRejected +=  
          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  
  
        // Load the Farm grammar.  
        recognizer.LoadGrammar(farmAnimals);  
  
        // Start asynchronous, continuous recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
        Console.WriteLine("Starting asynchronous, continuous recognition");  
        Console.WriteLine("  Farm grammar is loaded and enabled.");  
  
        // Pause to recognize farm animals.  
        Thread.Sleep(7000);  
        Console.WriteLine();  
  
        // Request an update and load the Fruit grammar.  
        recognizer.RequestRecognizerUpdate();  
        recognizer.LoadGrammarAsync(favoriteFruit);  
        Thread.Sleep(7000);  
  
        // Request an update and unload the Farm grammar.  
        recognizer.RequestRecognizerUpdate();  
        recognizer.UnloadGrammar(farmAnimals);  
        Thread.Sleep(7000);  
      }  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // At the update, get the names and enabled status of the currently loaded grammars.  
    public static void recognizer_RecognizerUpdateReached(  
      object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  {0} grammar is loaded and {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("    Speech recognized: " + e.Result.Text);  
    }  
  
    // Write a message to the console when recognition fails.  
    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine("    Recognition attempt failed");  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate (object userToken);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate(object userToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate (userToken As Object)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate(System::Object ^ userToken);" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : obj -&gt; unit" Usage="speechRecognitionEngine.RequestRecognizerUpdate userToken" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="userToken" Type="System.Object" />
      </Parameters>
      <Docs>
        <param name="userToken"><span data-ttu-id="b4702-677">操作に関する情報を含むユーザー定義情報。</span><span class="sxs-lookup"><span data-stu-id="b4702-677">User-defined information that contains information for the operation.</span></span></param>
        <summary><span data-ttu-id="b4702-678">認識エンジンが状態の更新を停止し、関連イベントのユーザー トークンを提供することを要求します。</span><span class="sxs-lookup"><span data-stu-id="b4702-678">Requests that the recognizer pauses to update its state and provides a user token for the associated event.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-679">レコグナイザーで <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> イベントが生成されると、<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> の <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> プロパティに `userToken` パラメーターの値が含まれます。</span><span class="sxs-lookup"><span data-stu-id="b4702-679">When the recognizer generates the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event, the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> property of the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> contains the value of the `userToken` parameter.</span></span>  
  
 <span data-ttu-id="b4702-680">オーディオ位置のオフセットを指定するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-680">To specify an audio position offset, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate (object userToken, TimeSpan audioPositionAheadToRaiseUpdate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate(object userToken, valuetype System.TimeSpan audioPositionAheadToRaiseUpdate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate (userToken As Object, audioPositionAheadToRaiseUpdate As TimeSpan)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate(System::Object ^ userToken, TimeSpan audioPositionAheadToRaiseUpdate);" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : obj * TimeSpan -&gt; unit" Usage="speechRecognitionEngine.RequestRecognizerUpdate (userToken, audioPositionAheadToRaiseUpdate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="userToken" Type="System.Object" />
        <Parameter Name="audioPositionAheadToRaiseUpdate" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="userToken"><span data-ttu-id="b4702-681">操作に関する情報を含むユーザー定義情報。</span><span class="sxs-lookup"><span data-stu-id="b4702-681">User-defined information that contains information for the operation.</span></span></param>
        <param name="audioPositionAheadToRaiseUpdate"><span data-ttu-id="b4702-682">要求を遅延するための、現在の <see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition" /> からのオフセット。</span><span class="sxs-lookup"><span data-stu-id="b4702-682">The offset from the current <see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition" /> to delay the request.</span></span></param>
        <summary><span data-ttu-id="b4702-683">認識エンジンが状態の更新を停止し、関連イベントのオフセットとユーザー トークンを提供することを要求します。</span><span class="sxs-lookup"><span data-stu-id="b4702-683">Requests that the recognizer pauses to update its state and provides an offset and a user token for the associated event.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-684">認識エンジンは、レコグナイザーの <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> が現在の <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> プラス `audioPositionAheadToRaiseUpdate`に等しいまで、レコグナイザー更新要求を開始しません。</span><span class="sxs-lookup"><span data-stu-id="b4702-684">The recognizer does not initiate the recognizer update request until the recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> equals the current <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> plus `audioPositionAheadToRaiseUpdate`.</span></span>  
  
 <span data-ttu-id="b4702-685">レコグナイザーで <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> イベントが生成されると、<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> の <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> プロパティに `userToken` パラメーターの値が含まれます。</span><span class="sxs-lookup"><span data-stu-id="b4702-685">When the recognizer generates the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event, the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> property of the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> contains the value of the `userToken` parameter.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="SetInputToAudioStream">
      <MemberSignature Language="C#" Value="public void SetInputToAudioStream (System.IO.Stream audioSource, System.Speech.AudioFormat.SpeechAudioFormatInfo audioFormat);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetInputToAudioStream(class System.IO.Stream audioSource, class System.Speech.AudioFormat.SpeechAudioFormatInfo audioFormat) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetInputToAudioStream (audioSource As Stream, audioFormat As SpeechAudioFormatInfo)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetInputToAudioStream(System::IO::Stream ^ audioSource, System::Speech::AudioFormat::SpeechAudioFormatInfo ^ audioFormat);" />
      <MemberSignature Language="F#" Value="member this.SetInputToAudioStream : System.IO.Stream * System.Speech.AudioFormat.SpeechAudioFormatInfo -&gt; unit" Usage="speechRecognitionEngine.SetInputToAudioStream (audioSource, audioFormat)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audioSource" Type="System.IO.Stream" />
        <Parameter Name="audioFormat" Type="System.Speech.AudioFormat.SpeechAudioFormatInfo" />
      </Parameters>
      <Docs>
        <param name="audioSource"><span data-ttu-id="b4702-686">オーディオ入力ストリーム。</span><span class="sxs-lookup"><span data-stu-id="b4702-686">The audio input stream.</span></span></param>
        <param name="audioFormat"><span data-ttu-id="b4702-687">オーディオ入力の形式。</span><span class="sxs-lookup"><span data-stu-id="b4702-687">The format of the audio input.</span></span></param>
        <summary><span data-ttu-id="b4702-688"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> オブジェクトを、オーディオ ストリームからの入力を受け取るように構成します。</span><span class="sxs-lookup"><span data-stu-id="b4702-688">Configures the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> object to receive input from an audio stream.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-689">認識操作中に認識エンジンが入力ストリームの末尾に到達した場合、認識操作は使用可能な入力で終了します。</span><span class="sxs-lookup"><span data-stu-id="b4702-689">If the recognizer reaches the end of the input stream during a recognition operation, the recognition operation finalizes with the available input.</span></span> <span data-ttu-id="b4702-690">入力をレコグナイザーに更新しない限り、それ以降のすべての認識操作で例外が発生する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-690">Any subsequent recognition operations can generate an exception, unless you update the input to the recognizer.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-691">次の例は、基本的な音声認識を示すコンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-691">The following example shows part of a console application that demonstrates basic speech recognition.</span></span> <span data-ttu-id="b4702-692">この例では、"テストテスト 1 2 3" と "mister cooper" を一時停止で区切って、オーディオファイルの例 .wav から入力を使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-692">The example uses input from an audio file, example.wav, that contains the phrases, "testing testing one two three" and "mister cooper", separated by a pause.</span></span> <span data-ttu-id="b4702-693">この例では、次の出力が生成されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-693">The example generates the following output.</span></span>  
  
```  
  
Starting asynchronous recognition...  
  Recognized text =  Testing testing 123  
  Recognized text =  Mr. Cooper  
  End of stream encountered.  
Done.  
  
Press any key to exit...  
```  
  
```csharp  
  
using System;  
using System.Globalization;  
using System.IO;  
using System.Speech.AudioFormat;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace InputExamples  
{  
  class Program  
  {  
    // Indicate whether asynchronous recognition is complete.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(new CultureInfo("en-US")))  
      {  
  
        // Create and load a grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation Grammar";  
  
        recognizer.LoadGrammar(dictation);  
  
        // Configure the input to the recognizer.  
        recognizer.SetInputToAudioStream(  
          File.OpenRead(@"c:\temp\audioinput\example.wav"),  
          new SpeechAudioFormatInfo(  
            44100, AudioBitsPerSample.Sixteen, AudioChannel.Mono));  
  
        // Attach event handlers.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.RecognizeCompleted +=  
          new EventHandler<RecognizeCompletedEventArgs>(  
            RecognizeCompletedHandler);  
  
        // Perform recognition of the whole file.  
        Console.WriteLine("Starting asynchronous recognition...");  
        completed = false;  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
        Console.WriteLine("Done.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null && e.Result.Text != null)  
      {  
        Console.WriteLine("  Recognized text =  {0}", e.Result.Text);  
      }  
      else  
      {  
        Console.WriteLine("  Recognized text not available.");  
      }  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void RecognizeCompletedHandler(  
      object sender, RecognizeCompletedEventArgs e)  
    {  
      if (e.Error != null)  
      {  
        Console.WriteLine("  Error encountered, {0}: {1}",  
          e.Error.GetType().Name, e.Error.Message);  
      }  
      if (e.Cancelled)  
      {  
        Console.WriteLine("  Operation cancelled.");  
      }  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine("  End of stream encountered.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
      </Docs>
    </Member>
    <Member MemberName="SetInputToDefaultAudioDevice">
      <MemberSignature Language="C#" Value="public void SetInputToDefaultAudioDevice ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetInputToDefaultAudioDevice() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetInputToDefaultAudioDevice ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetInputToDefaultAudioDevice();" />
      <MemberSignature Language="F#" Value="member this.SetInputToDefaultAudioDevice : unit -&gt; unit" Usage="speechRecognitionEngine.SetInputToDefaultAudioDevice " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary><span data-ttu-id="b4702-694"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> オブジェクトを、既定のオーディオ デバイスからの入力を受け取るように構成します。</span><span class="sxs-lookup"><span data-stu-id="b4702-694">Configures the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> object to receive input from the default audio device.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 <span data-ttu-id="b4702-695">次の例は、基本的な音声認識を示すコンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-695">The following example shows part of a console application that demonstrates basic speech recognition.</span></span> <span data-ttu-id="b4702-696">この例では、既定のオーディオデバイスからの出力を使用して、複数の非同期認識操作を実行し、ユーザーが "exit" という語句を使用したときに終了します。</span><span class="sxs-lookup"><span data-stu-id="b4702-696">The example uses output from the default audio device, performs multiple, asynchronous recognition operations, and exits when a user utters the phrase, "exit".</span></span>  
  
```csharp  
  
using System;  
using System.Globalization;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace DefaultInput  
{  
  class Program  
  {  
    // Indicate whether asynchronous recognition has finished.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(new CultureInfo("en-US")))  
      {  
  
        // Create and load the exit grammar.  
        Grammar exitGrammar = new Grammar(new GrammarBuilder("exit"));  
        exitGrammar.Name = "Exit Grammar";  
        recognizer.LoadGrammar(exitGrammar);  
  
        // Create and load the dictation grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation Grammar";  
        recognizer.LoadGrammar(dictation);  
  
        // Attach event handlers to the recognizer.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.RecognizeCompleted +=  
          new EventHandler<RecognizeCompletedEventArgs>(  
            RecognizeCompletedHandler);  
  
        // Assign input to the recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Begin asynchronous recognition.  
        Console.WriteLine("Starting recognition...");  
        completed = false;  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
  
        // Wait for recognition to finish.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
        Console.WriteLine("Done.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("  Speech recognized:");  
      string grammarName = "<not available>";  
      if (e.Result.Grammar.Name != null &&  
        !e.Result.Grammar.Name.Equals(string.Empty))  
      {  
        grammarName = e.Result.Grammar.Name;  
      }  
      Console.WriteLine("    {0,-17} - {1}",  
        grammarName, e.Result.Text);  
  
      if (grammarName.Equals("Exit Grammar"))  
      {  
        ((SpeechRecognitionEngine)sender).RecognizeAsyncCancel();  
      }  
    }  
  
    static void RecognizeCompletedHandler(  
      object sender, RecognizeCompletedEventArgs e)  
    {  
      Console.WriteLine("  Recognition completed.");  
      completed = true;  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
      </Docs>
    </Member>
    <Member MemberName="SetInputToNull">
      <MemberSignature Language="C#" Value="public void SetInputToNull ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetInputToNull() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetInputToNull ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetInputToNull();" />
      <MemberSignature Language="F#" Value="member this.SetInputToNull : unit -&gt; unit" Usage="speechRecognitionEngine.SetInputToNull " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary><span data-ttu-id="b4702-697">音声レコグナイザーに対する入力を無効にします。</span><span class="sxs-lookup"><span data-stu-id="b4702-697">Disables the input to the speech recognizer.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-698"><xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> および <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> メソッドを使用するとき、または認識エンジンを一時的にオフにするときに、入力なしの <xref:System.Speech.Recognition.SpeechRecognitionEngine> オブジェクトを構成します。</span><span class="sxs-lookup"><span data-stu-id="b4702-698">Configure the <xref:System.Speech.Recognition.SpeechRecognitionEngine> object for no input when using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> methods, or when taking a recognition engine temporarily off line.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)" />
      </Docs>
    </Member>
    <Member MemberName="SetInputToWaveFile">
      <MemberSignature Language="C#" Value="public void SetInputToWaveFile (string path);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetInputToWaveFile(string path) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetInputToWaveFile (path As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetInputToWaveFile(System::String ^ path);" />
      <MemberSignature Language="F#" Value="member this.SetInputToWaveFile : string -&gt; unit" Usage="speechRecognitionEngine.SetInputToWaveFile path" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="path" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="path"><span data-ttu-id="b4702-699">入力として使用するファイルのパス。</span><span class="sxs-lookup"><span data-stu-id="b4702-699">The path of the file to use as input.</span></span></param>
        <summary><span data-ttu-id="b4702-700"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> オブジェクトを、WAVE オーディオ形式 (.wav) ファイルからの入力を受け取るように構成します。</span><span class="sxs-lookup"><span data-stu-id="b4702-700">Configures the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> object to receive input from a Waveform audio format (.wav) file.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-701">認識操作中に認識エンジンが入力ファイルの末尾に到達した場合、認識操作は使用可能な入力で終了します。</span><span class="sxs-lookup"><span data-stu-id="b4702-701">If the recognizer reaches the end of the input file during a recognition operation, the recognition operation finalizes with the available input.</span></span> <span data-ttu-id="b4702-702">入力をレコグナイザーに更新しない限り、それ以降のすべての認識操作で例外が発生する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-702">Any subsequent recognition operations can generate an exception, unless you update the input to the recognizer.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-703">次の例では、.wav ファイルのオーディオに対する認識を実行し、認識されたテキストをコンソールに書き込みます。</span><span class="sxs-lookup"><span data-stu-id="b4702-703">The following example performs recognition on the audio in a .wav file and writes the recognized text to the console.</span></span>  
  
```  
using System;  
using System.IO;  
using System.Speech.Recognition;  
using System.Speech.AudioFormat;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static bool completed;  
  
    static void Main(string[] args)  
  
    // Initialize an in-process speech recognition engine.  
    {  
      using (SpeechRecognitionEngine recognizer =  
         new SpeechRecognitionEngine())  
      {  
  
        // Create and load a grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation Grammar";  
  
        recognizer.LoadGrammar(dictation);  
  
        // Configure the input to the recognizer.  
recognizer.SetInputToWaveFile(@"c:\temp\SampleWAVInput.wav");  
  
        // Attach event handlers for the results of recognition.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.RecognizeCompleted +=   
          new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  
  
        // Perform recognition on the entire file.  
        Console.WriteLine("Starting asynchronous recognition...");  
        completed = false;  
        recognizer.RecognizeAsync();  
  
        // Keep the console window open.  
        while (!completed)  
        {  
          Console.ReadLine();  
        }  
        Console.WriteLine("Done.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null && e.Result.Text != null)  
      {  
        Console.WriteLine("  Recognized text =  {0}", e.Result.Text);  
      }  
      else  
      {  
        Console.WriteLine("  Recognized text not available.");  
      }  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  
    {  
      if (e.Error != null)  
      {  
        Console.WriteLine("  Error encountered, {0}: {1}",  
        e.Error.GetType().Name, e.Error.Message);  
      }  
      if (e.Cancelled)  
      {  
        Console.WriteLine("  Operation cancelled.");  
      }  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine("  End of stream encountered.");  
      }  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
      </Docs>
    </Member>
    <Member MemberName="SetInputToWaveStream">
      <MemberSignature Language="C#" Value="public void SetInputToWaveStream (System.IO.Stream audioSource);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetInputToWaveStream(class System.IO.Stream audioSource) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetInputToWaveStream (audioSource As Stream)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetInputToWaveStream(System::IO::Stream ^ audioSource);" />
      <MemberSignature Language="F#" Value="member this.SetInputToWaveStream : System.IO.Stream -&gt; unit" Usage="speechRecognitionEngine.SetInputToWaveStream audioSource" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audioSource" Type="System.IO.Stream" />
      </Parameters>
      <Docs>
        <param name="audioSource"><span data-ttu-id="b4702-704">オーディオ データが含まれるストリーム。</span><span class="sxs-lookup"><span data-stu-id="b4702-704">The stream containing the audio data.</span></span></param>
        <summary><span data-ttu-id="b4702-705"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> オブジェクトを、WAVE オーディオ形式 (.wav) データを含むストリームからの入力を受け取るように構成します。</span><span class="sxs-lookup"><span data-stu-id="b4702-705">Configures the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> object to receive input from a stream that contains Waveform audio format (.wav) data.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-706">認識操作中に認識エンジンが入力ストリームの末尾に到達した場合、認識操作は使用可能な入力で終了します。</span><span class="sxs-lookup"><span data-stu-id="b4702-706">If the recognizer reaches the end of the input stream during a recognition operation, the recognition operation finalizes with the available input.</span></span> <span data-ttu-id="b4702-707">入力をレコグナイザーに更新しない限り、それ以降のすべての認識操作で例外が発生する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-707">Any subsequent recognition operations can generate an exception, unless you update the input to the recognizer.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
      </Docs>
    </Member>
    <Member MemberName="SpeechDetected">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; SpeechDetected;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechDetectedEventArgs&gt; SpeechDetected" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event SpeechDetected As EventHandler(Of SpeechDetectedEventArgs) " FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechDetectedEventArgs ^&gt; ^ SpeechDetected;" />
      <MemberSignature Language="F#" Value="member this.SpeechDetected : EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; " Usage="member this.SpeechDetected : System.EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; " />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechDetected As EventHandler(Of SpeechDetectedEventArgs) " FrameworkAlternate="netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-708"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> が音声として識別できる入力を検出すると発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-708">Raised when the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> detects input that it can identify as speech.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-709">各音声認識エンジンには、無音と音声を区別するためのアルゴリズムが用意されています。</span><span class="sxs-lookup"><span data-stu-id="b4702-709">Each speech recognizer has an algorithm to distinguish between silence and speech.</span></span> <span data-ttu-id="b4702-710"><xref:System.Speech.Recognition.SpeechRecognitionEngine> が音声認識操作を実行すると、そのアルゴリズムが音声として入力を識別すると、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> イベントが発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-710">When the <xref:System.Speech.Recognition.SpeechRecognitionEngine> performs a speech recognition operation, it raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> event when its algorithm identifies the input as speech.</span></span> <span data-ttu-id="b4702-711">関連付けられた <xref:System.Speech.Recognition.SpeechDetectedEventArgs> オブジェクトの <xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A> プロパティは、認識エンジンが音声を検出した入力ストリーム内の位置を示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-711">The <xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A> property of the associated <xref:System.Speech.Recognition.SpeechDetectedEventArgs> object indicates location in the input stream where the recognizer detected speech.</span></span> <span data-ttu-id="b4702-712"><xref:System.Speech.Recognition.SpeechRecognitionEngine> は、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>、または <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> イベントを発生させる前に、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> イベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-712">The <xref:System.Speech.Recognition.SpeechRecognitionEngine> raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> event before it raises any of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>, or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> events.</span></span>  
  
 <span data-ttu-id="b4702-713">詳細については、<xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> の各メソッドを参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-713">For more information see the <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> methods.</span></span>  
  
 <span data-ttu-id="b4702-714"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> デリゲートを作成する場合は、イベントを処理するメソッドを指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-714">When you create a <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> delegate, you identify the method that will handle the event.</span></span> <span data-ttu-id="b4702-715">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="b4702-715">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="b4702-716">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-716">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="b4702-717">イベントハンドラーデリゲートの詳細については、「[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-717">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-718">次の例は、フライトの発信元と送信先の市区町村を選択するためのコンソールアプリケーションの一部です。</span><span class="sxs-lookup"><span data-stu-id="b4702-718">The following example is part of a console application for choosing origin and destination cities for a flight.</span></span> <span data-ttu-id="b4702-719">アプリケーションでは、"マイアミからシカゴに向けて飛ぶことができます" などの語句を認識します。</span><span class="sxs-lookup"><span data-stu-id="b4702-719">The application recognizes phrases such as "I want to fly from Miami to Chicago."</span></span>  <span data-ttu-id="b4702-720">この例では、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> イベントを使用して、音声が検出されるたびに <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> を報告します。</span><span class="sxs-lookup"><span data-stu-id="b4702-720">The example uses the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> event to report the <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> each time speech is detected.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize an in-process speech recognition engine.  
    {  
      using (SpeechRecognitionEngine recognizer =  
         new SpeechRecognitionEngine())  
      {  
  
        // Create a grammar.  
        Choices cities = new Choices(new string[] {   
          "Los Angeles", "New York", "Chicago", "San Francisco", "Miami", "Dallas" });  
  
        GrammarBuilder gb = new GrammarBuilder();  
        gb.Append("I would like to fly from");  
        gb.Append(cities);  
        gb.Append("to");  
        gb.Append(cities);  
  
        // Create a Grammar object and load it to the recognizer.  
        Grammar g = new Grammar(gb);  
        g.Name = ("City Chooser");  
        recognizer.LoadGrammarAsync(g);  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechDetected +=  
          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Set the input to the recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Start recognition.  
        recognizer.RecognizeAsync();  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechDetected event.  
    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine("  Speech detected at AudioPosition = {0}", e.AudioPosition);  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("  Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechDetectedEventArgs" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="SpeechHypothesized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; SpeechHypothesized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; SpeechHypothesized" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event SpeechHypothesized As EventHandler(Of SpeechHypothesizedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechHypothesizedEventArgs ^&gt; ^ SpeechHypothesized;" />
      <MemberSignature Language="F#" Value="member this.SpeechHypothesized : EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; " Usage="member this.SpeechHypothesized : System.EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-721"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> が文法の複数の完全な語句のコンポーネントである可能性がある単語を認識した場合に発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-721">Raised when the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> has recognized a word or words that may be a component of multiple complete phrases in a grammar.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-722"><xref:System.Speech.Recognition.SpeechRecognitionEngine> は、入力語句を識別しようとしたときに多数の <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> イベントを生成します。</span><span class="sxs-lookup"><span data-stu-id="b4702-722">The <xref:System.Speech.Recognition.SpeechRecognitionEngine> generates numerous <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> events as it attempts to identify an input phrase.</span></span> <span data-ttu-id="b4702-723">部分的に認識された語句のテキストにアクセスするには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> イベントのハンドラーで <xref:System.Speech.Recognition.SpeechHypothesizedEventArgs> オブジェクトの <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> プロパティを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-723">You can access the text of partially recognized phrases in the <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> property of the <xref:System.Speech.Recognition.SpeechHypothesizedEventArgs> object in the handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> event.</span></span> <span data-ttu-id="b4702-724">通常、これらのイベントの処理はデバッグにのみ役立ちます。</span><span class="sxs-lookup"><span data-stu-id="b4702-724">Typically, handling these events is useful only for debugging.</span></span>  
  
 <span data-ttu-id="b4702-725"><xref:System.Speech.Recognition.SpeechHypothesizedEventArgs> は、<xref:System.Speech.Recognition.RecognitionEventArgs> から派生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-725"><xref:System.Speech.Recognition.SpeechHypothesizedEventArgs> derives from <xref:System.Speech.Recognition.RecognitionEventArgs>.</span></span>  
  
 <span data-ttu-id="b4702-726">詳細については、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> プロパティ、<xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> の各メソッドを参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-726">For more information see the <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> property and the <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> methods.</span></span>  
  
 <span data-ttu-id="b4702-727"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> デリゲートを作成する場合は、イベントを処理するメソッドを指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-727">When you create a <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> delegate, you identify the method that will handle the event.</span></span> <span data-ttu-id="b4702-728">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="b4702-728">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="b4702-729">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-729">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="b4702-730">イベントハンドラーデリゲートの詳細については、「[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-730">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-731">次の例では、"ジャズカテゴリのアーティストの一覧を表示する" などの語句を認識しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-731">The following example recognizes phrases such as "Display the list of artists in the jazz category".</span></span> <span data-ttu-id="b4702-732">この例では、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> イベントを使用して、認識されたときに不完全な語句フラグメントをコンソールに表示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-732">The example uses the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> event to display incomplete phrase fragments in the console as they are recognized.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize an in-process speech recognition engine.  
    {  
      using (SpeechRecognitionEngine recognizer =  
         new SpeechRecognitionEngine())  
      {  
  
        // Create a grammar.  
        //  Create lists of alternative choices.  
        Choices listTypes = new Choices(new string[] { "albums", "artists" });  
        Choices genres = new Choices(new string[] {   
          "blues", "classical", "gospel", "jazz", "rock" });  
  
        //  Create a GrammarBuilder object and assemble the grammar components.  
        GrammarBuilder mediaMenu = new GrammarBuilder("Display the list of");  
        mediaMenu.Append(listTypes);  
        mediaMenu.Append("in the");  
        mediaMenu.Append(genres);  
        mediaMenu.Append("category.");  
  
        //  Build a Grammar object from the GrammarBuilder.  
        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  
        mediaMenuGrammar.Name = "Media Chooser";  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.SpeechHypothesized +=  
          new EventHandler<SpeechHypothesizedEventArgs>(recognizer_SpeechHypothesized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(mediaMenuGrammar);  
  
        // Set the input to the recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Start asynchronous recognition.  
        recognizer.RecognizeAsync();  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechHypothesized event.  
    static void recognizer_SpeechHypothesized(object sender, SpeechHypothesizedEventArgs e)  
    {  
      Console.WriteLine("Speech hypothesized: " + e.Result.Text);  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
      Console.WriteLine();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine();   
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechDetectedEventArgs" />
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
      </Docs>
    </Member>
    <Member MemberName="SpeechRecognitionRejected">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; SpeechRecognitionRejected;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; SpeechRecognitionRejected" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event SpeechRecognitionRejected As EventHandler(Of SpeechRecognitionRejectedEventArgs) " FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechRecognitionRejectedEventArgs ^&gt; ^ SpeechRecognitionRejected;" />
      <MemberSignature Language="F#" Value="member this.SpeechRecognitionRejected : EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; " Usage="member this.SpeechRecognitionRejected : System.EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; " />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechRecognitionRejected As EventHandler(Of SpeechRecognitionRejectedEventArgs) " FrameworkAlternate="netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-733"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> が読み込み済みで有効な <see cref="T:System.Speech.Recognition.Grammar" /> オブジェクトのどのリストにも一致しない入力を受け取ると、発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-733">Raised when the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> receives input that does not match any of its loaded and enabled <see cref="T:System.Speech.Recognition.Grammar" /> objects.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-734">認識エンジンは、入力が読み込まれ、有効になっている <xref:System.Speech.Recognition.Grammar> オブジェクトが十分に一致しないと判断した場合に、このイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="b4702-734">The recognizer raises this event if it determines that input does not match with sufficient confidence any of its loaded and enabled <xref:System.Speech.Recognition.Grammar> objects.</span></span> <span data-ttu-id="b4702-735"><xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> の <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> プロパティに、拒否された <xref:System.Speech.Recognition.RecognitionResult> オブジェクトが含まれています。</span><span class="sxs-lookup"><span data-stu-id="b4702-735">The <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> property of the <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> contains the rejected <xref:System.Speech.Recognition.RecognitionResult> object.</span></span> <span data-ttu-id="b4702-736"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> イベントのハンドラーを使用すると、拒否された認識 <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> とその <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> スコアを取得できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-736">You can use the handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> event to retrieve recognition <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> that were rejected and their <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> scores.</span></span>  
  
 <span data-ttu-id="b4702-737">アプリケーションで <xref:System.Speech.Recognition.SpeechRecognitionEngine> インスタンスを使用している場合は、いずれかの <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> 方法で音声入力が受け入れられるか拒否されるかを示す信頼レベルを変更できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-737">If your application is using a <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance, you can modify the confidence level at which speech input is accepted or rejected with one of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> methods.</span></span> <span data-ttu-id="b4702-738"><xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> の各プロパティを使用して、音声認識が音声以外の入力にどのように応答するかを変更できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-738">You can modify how the speech recognition responds to non-speech input using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> properties.</span></span>  
  
 <span data-ttu-id="b4702-739"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> デリゲートを作成する場合は、イベントを処理するメソッドを指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-739">When you create a <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> delegate, you identify the method that will handle the event.</span></span> <span data-ttu-id="b4702-740">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="b4702-740">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="b4702-741">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-741">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="b4702-742">イベントハンドラーデリゲートの詳細については、「[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-742">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-743">次の例では、"ジャズカテゴリのアーティストの一覧を表示する" または "アルバムの表示 gospel" のような語句を認識しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-743">The following example recognizes phrases such as "Display the list of artists in the jazz category" or "Display albums gospel".</span></span> <span data-ttu-id="b4702-744">この例では、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> イベントのハンドラーを使用して、音声入力を十分な <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> を持つ文法の内容と照合して、正常な認識を生成することができない場合に、コンソールに通知を表示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-744">The example uses a handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> to produce a successful recognition.</span></span> <span data-ttu-id="b4702-745">また、信頼度が低いために拒否された <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> 認識結果も表示されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-745">The handler also displays recognition result <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> that were rejected because of low confidence scores.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize an in-process speech recognition engine.  
    {  
      using (SpeechRecognitionEngine recognizer =  
         new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US")))  
      {  
  
        // Create a grammar.  
        //  Create lists of alternative choices.  
        Choices listTypes = new Choices(new string[] { "albums", "artists" });  
        Choices genres = new Choices(new string[] {   
          "blues", "classical", "gospel", "jazz", "rock" });  
  
        //  Create a GrammarBuilder object and assemble the grammar components.  
        GrammarBuilder mediaMenu = new GrammarBuilder("Display");  
        mediaMenu.Append("the list of", 0, 1);  
        mediaMenu.Append(listTypes);  
        mediaMenu.Append("in the", 0, 1);  
        mediaMenu.Append(genres);  
        mediaMenu.Append("category", 0, 1);  
  
        //  Build a Grammar object from the GrammarBuilder.  
        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  
        mediaMenuGrammar.Name = "Media Chooser";  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.SpeechRecognitionRejected +=  
          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(mediaMenuGrammar);  
  
        // Set the input to the recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Start recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechRecognitionRejected event.  
    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine("Speech input was rejected.");  
      foreach (RecognizedPhrase phrase in e.Result.Alternates)  
      {  
      Console.WriteLine("  Rejected phrase: " + phrase.Text);  
      Console.WriteLine("  Confidence score: " + phrase.Confidence);  
      }  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
      Console.WriteLine("  Confidence score: " + e.Result.Confidence);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechDetectedEventArgs" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="SpeechRecognized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; SpeechRecognized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechRecognizedEventArgs&gt; SpeechRecognized" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event SpeechRecognized As EventHandler(Of SpeechRecognizedEventArgs) " FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechRecognizedEventArgs ^&gt; ^ SpeechRecognized;" />
      <MemberSignature Language="F#" Value="member this.SpeechRecognized : EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; " Usage="member this.SpeechRecognized : System.EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; " />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechRecognized As EventHandler(Of SpeechRecognizedEventArgs) " FrameworkAlternate="netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8" />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="b4702-746"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> が読み込み済みで有効な <see cref="T:System.Speech.Recognition.Grammar" /> オブジェクトのいずれかのリストに一致する入力を受け取ると、発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-746">Raised when the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> receives input that matches any of its loaded and enabled <see cref="T:System.Speech.Recognition.Grammar" /> objects.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-747"><xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> または <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> のいずれかのメソッドを使用して、認識操作を開始できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-747">You can initiate a recognition operation using the one of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> methods.</span></span> <span data-ttu-id="b4702-748">認識エンジンは <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> イベントを発生させます。これにより、入力が、読み込まれた <xref:System.Speech.Recognition.Grammar> オブジェクトの1つと一致すると判断され、その値が十分なレベルで認識されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-748">The recognizer raises the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> event if it determines that input matches one of its loaded <xref:System.Speech.Recognition.Grammar> objects with a sufficient level of confidence to constitute recognition.</span></span> <span data-ttu-id="b4702-749"><xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> の <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> プロパティに、受け入れられた <xref:System.Speech.Recognition.RecognitionResult> オブジェクトが含まれています。</span><span class="sxs-lookup"><span data-stu-id="b4702-749">The <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> property of the <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> contains the accepted <xref:System.Speech.Recognition.RecognitionResult> object.</span></span> <span data-ttu-id="b4702-750"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> イベントのハンドラーは、認識された語句と、信頼度の低いスコアを持つ認識 <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> の一覧を取得できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-750">Handlers of <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> events can obtain the recognized phrase as well as a list of recognition <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> with lower confidence scores.</span></span>  
  
 <span data-ttu-id="b4702-751">アプリケーションで <xref:System.Speech.Recognition.SpeechRecognitionEngine> インスタンスを使用している場合は、いずれかの <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> 方法で音声入力が受け入れられるか拒否されるかを示す信頼レベルを変更できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-751">If your application is using a <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance, you can modify the confidence level at which speech input is accepted or rejected with one of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> methods.</span></span>  <span data-ttu-id="b4702-752"><xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> の各プロパティを使用して、音声認識が音声以外の入力にどのように応答するかを変更できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-752">You can modify how the speech recognition responds to non-speech input using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> properties.</span></span>  
  
 <span data-ttu-id="b4702-753">認識エンジンが文法に一致する入力を受け取ると、<xref:System.Speech.Recognition.Grammar> オブジェクトはその <xref:System.Speech.Recognition.Grammar.SpeechRecognized> イベントを発生させることができます。</span><span class="sxs-lookup"><span data-stu-id="b4702-753">When the recognizer receives input that matches a grammar, the <xref:System.Speech.Recognition.Grammar> object can raise its <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event.</span></span> <span data-ttu-id="b4702-754"><xref:System.Speech.Recognition.Grammar> オブジェクトの <xref:System.Speech.Recognition.Grammar.SpeechRecognized> イベントは、音声認識エンジンの <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> イベントの前に発生します。</span><span class="sxs-lookup"><span data-stu-id="b4702-754">The <xref:System.Speech.Recognition.Grammar> object's <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event is raised prior to the speech recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> event.</span></span> <span data-ttu-id="b4702-755">特定の文法に固有のタスクは、常に <xref:System.Speech.Recognition.Grammar.SpeechRecognized> イベントのハンドラーによって実行される必要があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-755">Any tasks specific to a particular grammar should always be performed by a handler for the <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event.</span></span>  
  
 <span data-ttu-id="b4702-756"><xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> デリゲートを作成する場合は、イベントを処理するメソッドを指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-756">When you create a <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> delegate, you identify the method that will handle the event.</span></span> <span data-ttu-id="b4702-757">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="b4702-757">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="b4702-758">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-758">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="b4702-759">イベントハンドラーデリゲートの詳細については、「[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)」を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-759">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-760">次の例は、音声認識の文法を作成し <xref:System.Speech.Recognition.Grammar> オブジェクトを構築し、それを <xref:System.Speech.Recognition.SpeechRecognitionEngine> に読み込んで認識を行うコンソールアプリケーションの一部です。</span><span class="sxs-lookup"><span data-stu-id="b4702-760">The following example is part of a console application that creates speech recognition grammar, constructs a <xref:System.Speech.Recognition.Grammar> object, and loads it into the <xref:System.Speech.Recognition.SpeechRecognitionEngine> to perform recognition.</span></span> <span data-ttu-id="b4702-761">この例では、<xref:System.Speech.Recognition.SpeechRecognitionEngine>への音声入力、関連する認識結果、音声認識エンジンによって発生した関連イベントを示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-761">The example demonstrates speech input to a <xref:System.Speech.Recognition.SpeechRecognitionEngine>, the associated recognition results, and the associated events raised by the speech recognizer.</span></span>  
  
 <span data-ttu-id="b4702-762">"シカゴからマイアミへの飛行を希望しています" などの音声入力を行うと、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> イベントがトリガーされます。</span><span class="sxs-lookup"><span data-stu-id="b4702-762">Spoken input such as "I want to fly from Chicago to Miami" will trigger a <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> event.</span></span> <span data-ttu-id="b4702-763">"ヒューストンからシカゴに移動する" という語句は、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> イベントをトリガーしません。</span><span class="sxs-lookup"><span data-stu-id="b4702-763">Speaking the phrase "Fly me from Houston to Chicago " will not trigger a <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> event.</span></span>  
  
 <span data-ttu-id="b4702-764">この例では、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> イベントのハンドラーを使用して、正常に認識された語句と、コンソールに含まれるセマンティクスを表示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-764">The example uses a handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> event to display successfully recognized phrases and the semantics they contain in the console.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize an in-process speech recognition engine.  
    {  
      using (SpeechRecognitionEngine recognizer = new SpeechRecognitionEngine())  
      {  
  
        // Create SemanticResultValue objects that contain cities and airport codes.  
        SemanticResultValue chicago = new SemanticResultValue("Chicago", "ORD");  
        SemanticResultValue boston = new SemanticResultValue("Boston", "BOS");  
        SemanticResultValue miami = new SemanticResultValue("Miami", "MIA");  
        SemanticResultValue dallas = new SemanticResultValue("Dallas", "DFW");  
  
        // Create a Choices object and add the SemanticResultValue objects, using  
        // implicit conversion from SemanticResultValue to GrammarBuilder  
        Choices cities = new Choices();  
        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  
  
        // Build the phrase and add SemanticResultKeys.  
        GrammarBuilder chooseCities = new GrammarBuilder();  
        chooseCities.Append("I want to fly from");  
        chooseCities.Append(new SemanticResultKey("origin", cities));  
        chooseCities.Append("to");  
        chooseCities.Append(new SemanticResultKey("destination", cities));  
  
        // Build a Grammar object from the GrammarBuilder.  
        Grammar bookFlight = new Grammar(chooseCities);  
        bookFlight.Name = "Book Flight";  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(bookFlight);  
  
        // Set the input to the recognizer.  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Start recognition.  
        recognizer.RecognizeAsync();  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
      Console.WriteLine();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized:  " + e.Result.Text);  
      Console.WriteLine();  
      Console.WriteLine("Semantic results:");  
      Console.WriteLine("  The flight origin is " + e.Result.Semantics["origin"].Value);  
      Console.WriteLine("  The flight destination is " + e.Result.Semantics["destination"].Value);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechDetectedEventArgs" />
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.Recognize" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
      </Docs>
    </Member>
    <Member MemberName="UnloadAllGrammars">
      <MemberSignature Language="C#" Value="public void UnloadAllGrammars ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void UnloadAllGrammars() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars" />
      <MemberSignature Language="VB.NET" Value="Public Sub UnloadAllGrammars ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void UnloadAllGrammars();" />
      <MemberSignature Language="F#" Value="member this.UnloadAllGrammars : unit -&gt; unit" Usage="speechRecognitionEngine.UnloadAllGrammars " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary><span data-ttu-id="b4702-765">すべての <see cref="T:System.Speech.Recognition.Grammar" /> オブジェクトを認識エンジンから削除します。</span><span class="sxs-lookup"><span data-stu-id="b4702-765">Unloads all <see cref="T:System.Speech.Recognition.Grammar" /> objects from the recognizer.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-766">認識エンジンが現在 <xref:System.Speech.Recognition.Grammar> を非同期に読み込んでいる場合、このメソッドは、<xref:System.Speech.Recognition.Grammar> が読み込まれるまで待機してから、<xref:System.Speech.Recognition.SpeechRecognitionEngine> インスタンスからすべての <xref:System.Speech.Recognition.Grammar> オブジェクトをアンロードします。</span><span class="sxs-lookup"><span data-stu-id="b4702-766">If the recognizer is currently loading a <xref:System.Speech.Recognition.Grammar> asynchronously, this method waits until the <xref:System.Speech.Recognition.Grammar> is loaded, before it unloads all of the <xref:System.Speech.Recognition.Grammar> objects from the <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance.</span></span>  
  
 <span data-ttu-id="b4702-767">特定の文法をアンロードするには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-767">To unload a specific grammar, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A> method.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-768">次の例は、音声認識文法の同期読み込みとアンロードを示すコンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-768">The following example shows part of a console application that demonstrates the synchronous loading and unloading of speech recognition grammars.</span></span>  
  
```  
Loading grammars...  
Loaded grammars:  
 - Grammar1  
 - Grammar2  
 - Grammar3  
  
Unloading Grammar1...  
Loaded grammars:  
 - Grammar2  
 - Grammar3  
  
Unloading all grammars...  
No grammars loaded.  
  
Press any key to exit...  
```  
  
```csharp  
  
using System;  
using System.Collections.Generic;  
using System.Globalization;  
using System.Speech.Recognition;  
  
namespace UnloadGrammars  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(new CultureInfo("en-US")))  
      {  
        Console.WriteLine("Loading grammars...");  
  
        // Create and load a number of grammars.  
        Grammar grammar1 = new Grammar(new GrammarBuilder("first grammar"));  
        grammar1.Name = "Grammar1";  
        recognizer.LoadGrammar(grammar1);  
  
        Grammar grammar2 = new Grammar(new GrammarBuilder("second grammar"));  
        grammar2.Name = "Grammar2";  
        recognizer.LoadGrammar(grammar2);  
  
        Grammar grammar3 = new Grammar(new GrammarBuilder("third grammar"));  
        grammar3.Name = "Grammar3";  
        recognizer.LoadGrammar(grammar3);  
  
        // List the recognizer's loaded grammars.  
        ListGrammars(recognizer);  
  
        // Unload one grammar and list the loaded grammars.  
        Console.WriteLine("Unloading Grammar1...");  
        recognizer.UnloadGrammar(grammar1);  
        ListGrammars(recognizer);  
  
        // Unload all grammars and list the loaded grammars.  
        Console.WriteLine("Unloading all grammars...");  
        recognizer.UnloadAllGrammars();  
        ListGrammars(recognizer);  
      }  
  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    private static void ListGrammars(SpeechRecognitionEngine recognizer)  
    {  
      // Make a copy of the recognizer's grammar collection.  
      List<Grammar> loadedGrammars = new List<Grammar>(recognizer.Grammars);  
  
      if (loadedGrammars.Count > 0)  
      {  
        Console.WriteLine("Loaded grammars:");  
        foreach (Grammar g in recognizer.Grammars)  
        {  
          Console.WriteLine(" - {0}", g.Name);  
        }  
      }  
      else  
      {  
        Console.WriteLine("No grammars loaded.");  
      }  
      Console.WriteLine();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="UnloadGrammar">
      <MemberSignature Language="C#" Value="public void UnloadGrammar (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void UnloadGrammar(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void UnloadGrammar(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.UnloadGrammar : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognitionEngine.UnloadGrammar grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar"><span data-ttu-id="b4702-769">アンロードする文法オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="b4702-769">The grammar object to unload.</span></span></param>
        <summary><span data-ttu-id="b4702-770"><see cref="T:System.Speech.Recognition.Grammar" /> インスタンスから、指定された <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> オブジェクトをアンロードします。</span><span class="sxs-lookup"><span data-stu-id="b4702-770">Unloads a specified <see cref="T:System.Speech.Recognition.Grammar" /> object from the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> instance.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-771">レコグナイザーが実行されている場合、アプリケーションは、<xref:System.Speech.Recognition.Grammar> オブジェクトの読み込み、アンロード、有効化、または無効化の前に、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> を使用して <xref:System.Speech.Recognition.SpeechRecognitionEngine> インスタンスを一時停止する必要があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-771">If the recognizer is running, applications must use <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> to pause the <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance before loading, unloading,  enabling, or disabling a <xref:System.Speech.Recognition.Grammar> object.</span></span> <span data-ttu-id="b4702-772">すべての <xref:System.Speech.Recognition.Grammar> オブジェクトをアンロードするには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-772">To unload all <xref:System.Speech.Recognition.Grammar> objects, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A> method.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-773">次の例は、音声認識文法の同期読み込みとアンロードを示すコンソールアプリケーションの一部を示しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-773">The following example shows part of a console application that demonstrates the synchronous loading and unloading of speech recognition grammars.</span></span>  
  
```  
Loading grammars...  
Loaded grammars:  
 - Grammar1  
 - Grammar2  
 - Grammar3  
  
Unloading Grammar1...  
Loaded grammars:  
 - Grammar2  
 - Grammar3  
  
Unloading all grammars...  
No grammars loaded.  
  
Press any key to exit...  
```  
  
```csharp  
  
using System;  
using System.Collections.Generic;  
using System.Globalization;  
using System.Speech.Recognition;  
  
namespace UnloadGrammars  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(new CultureInfo("en-US")))  
      {  
        Console.WriteLine("Loading grammars...");  
  
        // Create and load a number of grammars.  
        Grammar grammar1 = new Grammar(new GrammarBuilder("first grammar"));  
        grammar1.Name = "Grammar1";  
        recognizer.LoadGrammar(grammar1);  
  
        Grammar grammar2 = new Grammar(new GrammarBuilder("second grammar"));  
        grammar2.Name = "Grammar2";  
        recognizer.LoadGrammar(grammar2);  
  
        Grammar grammar3 = new Grammar(new GrammarBuilder("third grammar"));  
        grammar3.Name = "Grammar3";  
        recognizer.LoadGrammar(grammar3);  
  
        // List the recognizer's loaded grammars.  
        ListGrammars(recognizer);  
  
        // Unload one grammar and list the loaded grammars.  
        Console.WriteLine("Unloading Grammar1...");  
        recognizer.UnloadGrammar(grammar1);  
        ListGrammars(recognizer);  
  
        // Unload all grammars and list the loaded grammars.  
        Console.WriteLine("Unloading all grammars...");  
        recognizer.UnloadAllGrammars();  
        ListGrammars(recognizer);  
      }  
  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    private static void ListGrammars(SpeechRecognitionEngine recognizer)  
    {  
      // Make a copy of the recognizer's grammar collection.  
      List<Grammar> loadedGrammars = new List<Grammar>(recognizer.Grammars);  
  
      if (loadedGrammars.Count > 0)  
      {  
        Console.WriteLine("Loaded grammars:");  
        foreach (Grammar g in recognizer.Grammars)  
        {  
          Console.WriteLine(" - {0}", g.Name);  
        }  
      }  
      else  
      {  
        Console.WriteLine("No grammars loaded.");  
      }  
      Console.WriteLine();  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.ArgumentNullException"><span data-ttu-id="b4702-774"><paramref name="Grammar" /> が <see langword="null" /> です。</span><span class="sxs-lookup"><span data-stu-id="b4702-774"><paramref name="Grammar" /> is <see langword="null" />.</span></span></exception>
        <exception cref="T:System.InvalidOperationException"><span data-ttu-id="b4702-775">文法は、この認識エンジンに読み込まれていないか、この認識エンジンは現在文法を非同期に読み込んでいます。</span><span class="sxs-lookup"><span data-stu-id="b4702-775">The grammar is not loaded in this recognizer, or this recognizer is currently loading the grammar asynchronously.</span></span></exception>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars" />
      </Docs>
    </Member>
    <MemberGroup MemberName="UpdateRecognizerSetting">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary><span data-ttu-id="b4702-776">認識エンジンの設定の値を更新します。</span><span class="sxs-lookup"><span data-stu-id="b4702-776">Updates the value of a setting for the recognizer.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-777">レコグナイザーの設定には、文字列、64ビットの整数、またはメモリアドレスデータを含めることができます。</span><span class="sxs-lookup"><span data-stu-id="b4702-777">Recognizer settings can contain string, 64-bit integer, or memory address data.</span></span> <span data-ttu-id="b4702-778">次の表では、Microsoft Speech API (SAPI) 準拠のレコグナイザーに対して定義されている設定について説明します。</span><span class="sxs-lookup"><span data-stu-id="b4702-778">The following table describes the settings that are defined for a Microsoft Speech API (SAPI)-compliant recognizer.</span></span> <span data-ttu-id="b4702-779">次の設定は、設定をサポートする各レコグナイザーに対して同じ範囲である必要があります。</span><span class="sxs-lookup"><span data-stu-id="b4702-779">The following settings must have the same range for each recognizer that supports the setting.</span></span> <span data-ttu-id="b4702-780">SAPI 準拠のレコグナイザーは、これらの設定をサポートするために必要ではなく、他の設定をサポートできます。</span><span class="sxs-lookup"><span data-stu-id="b4702-780">A SAPI-compliant recognizer is not required to support these settings and can support other settings.</span></span>  
  
|<span data-ttu-id="b4702-781">name</span><span class="sxs-lookup"><span data-stu-id="b4702-781">Name</span></span>|<span data-ttu-id="b4702-782">説明</span><span class="sxs-lookup"><span data-stu-id="b4702-782">Description</span></span>|  
|----------|-----------------|  
|`ResourceUsage`|<span data-ttu-id="b4702-783">レコグナイザーの CPU 使用量を指定します。</span><span class="sxs-lookup"><span data-stu-id="b4702-783">Specifies the recognizer's CPU consumption.</span></span> <span data-ttu-id="b4702-784">範囲は 0 ~ 100 です。</span><span class="sxs-lookup"><span data-stu-id="b4702-784">The range is from 0 to 100.</span></span> <span data-ttu-id="b4702-785">既定値は 50 です。</span><span class="sxs-lookup"><span data-stu-id="b4702-785">The default value is 50.</span></span>|  
|`ResponseSpeed`|<span data-ttu-id="b4702-786">音声認識エンジンが認識操作を完了する前に、明確な入力の最後に無音の長さを示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-786">Indicates the length of silence at the end of unambiguous input before the speech recognizer completes a recognition operation.</span></span> <span data-ttu-id="b4702-787">範囲は 0 ~ 1万ミリ秒 (ms) です。</span><span class="sxs-lookup"><span data-stu-id="b4702-787">The range is from 0 to 10,000 milliseconds (ms).</span></span> <span data-ttu-id="b4702-788">この設定は、レコグナイザーの <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> プロパティに対応しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-788">This setting corresponds to the recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> property.</span></span> <span data-ttu-id="b4702-789">既定値は150ミリ秒です。</span><span class="sxs-lookup"><span data-stu-id="b4702-789">Default = 150ms.</span></span>|  
|`ComplexResponseSpeed`|<span data-ttu-id="b4702-790">音声認識エンジンが認識操作を完了する前に、あいまいな入力の最後に無音の長さをミリ秒 (ms) で示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-790">Indicates the length of silence in milliseconds (ms) at the end of ambiguous input before the speech recognizer completes a recognition operation.</span></span> <span data-ttu-id="b4702-791">範囲は 0 ~ 10, 000ms 秒です。</span><span class="sxs-lookup"><span data-stu-id="b4702-791">The range is from 0 to 10,000ms.</span></span> <span data-ttu-id="b4702-792">この設定は、レコグナイザーの <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> プロパティに対応しています。</span><span class="sxs-lookup"><span data-stu-id="b4702-792">This setting corresponds to the recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> property.</span></span> <span data-ttu-id="b4702-793">既定値は500ミリ秒です。</span><span class="sxs-lookup"><span data-stu-id="b4702-793">Default = 500ms.</span></span>|  
|`AdaptationOn`|<span data-ttu-id="b4702-794">音響モデルの適応がオン (値 = `1`) かオフ (値 = `0`) かを示します。</span><span class="sxs-lookup"><span data-stu-id="b4702-794">Indicates whether adaptation of the acoustic model is ON (value = `1`) or OFF (value = `0`).</span></span> <span data-ttu-id="b4702-795">既定値は `1` (ON) です。</span><span class="sxs-lookup"><span data-stu-id="b4702-795">The default value is `1` (ON).</span></span>|  
|`PersistedBackgroundAdaptation`|<span data-ttu-id="b4702-796">バックグラウンドの適応がオン (値 = `1`) かオフ (値 = `0`) かを示し、レジストリに設定を保持します。</span><span class="sxs-lookup"><span data-stu-id="b4702-796">Indicates whether background adaptation is ON (value = `1`) or OFF (value = `0`), and persists the setting in the registry.</span></span> <span data-ttu-id="b4702-797">既定値は `1` (ON) です。</span><span class="sxs-lookup"><span data-stu-id="b4702-797">The default value is `1` (ON).</span></span>|  
  
 <span data-ttu-id="b4702-798">認識エンジンの設定のいずれかを返すには、<xref:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting%2A> メソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="b4702-798">To return one of the recognizer's settings, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting%2A> method.</span></span>  
  
 <span data-ttu-id="b4702-799">`PersistedBackgroundAdaptation`を除き、<xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> メソッドを使用して設定されたプロパティ値は <xref:System.Speech.Recognition.SpeechRecognitionEngine>の現在のインスタンスに対してのみ有効であり、その後は既定の設定に戻ります。</span><span class="sxs-lookup"><span data-stu-id="b4702-799">With the exception of `PersistedBackgroundAdaptation`, property values set using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> methods remain in effect only for the current instance of <xref:System.Speech.Recognition.SpeechRecognitionEngine>, after which they revert to their default settings.</span></span>  
  
 <span data-ttu-id="b4702-800"><xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>、<xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>、および <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> の各プロパティを使用して、音声認識が音声以外の入力にどのように応答するかを変更できます。</span><span class="sxs-lookup"><span data-stu-id="b4702-800">You can modify how the speech recognition responds to non-speech input using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, and <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> properties.</span></span>  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="UpdateRecognizerSetting">
      <MemberSignature Language="C#" Value="public void UpdateRecognizerSetting (string settingName, int updatedValue);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void UpdateRecognizerSetting(string settingName, int32 updatedValue) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Sub UpdateRecognizerSetting (settingName As String, updatedValue As Integer)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void UpdateRecognizerSetting(System::String ^ settingName, int updatedValue);" />
      <MemberSignature Language="F#" Value="member this.UpdateRecognizerSetting : string * int -&gt; unit" Usage="speechRecognitionEngine.UpdateRecognizerSetting (settingName, updatedValue)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="settingName" Type="System.String" />
        <Parameter Name="updatedValue" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="settingName"><span data-ttu-id="b4702-801">更新する設定の名前。</span><span class="sxs-lookup"><span data-stu-id="b4702-801">The name of the setting to update.</span></span></param>
        <param name="updatedValue"><span data-ttu-id="b4702-802">設定の新しい値。</span><span class="sxs-lookup"><span data-stu-id="b4702-802">The new value for the setting.</span></span></param>
        <summary><span data-ttu-id="b4702-803"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> の指定された設定を、指定された整数値で更新します。</span><span class="sxs-lookup"><span data-stu-id="b4702-803">Updates the specified setting for the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> with the specified integer value.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-804">`PersistedBackgroundAdaptation`を除き、<xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> メソッドを使用して設定されたプロパティ値は <xref:System.Speech.Recognition.SpeechRecognitionEngine>の現在のインスタンスに対してのみ有効です。その後、既定の設定に戻ります。</span><span class="sxs-lookup"><span data-stu-id="b4702-804">With the exception of `PersistedBackgroundAdaptation`, property values set using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> method remain in effect only for the current instance of <xref:System.Speech.Recognition.SpeechRecognitionEngine>, after which they revert to their default settings.</span></span> <span data-ttu-id="b4702-805">サポートされている設定の説明については、<xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-805">See <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> for descriptions of supported settings.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="b4702-806">次の例は、en-us ロケールをサポートする認識エンジンに対して定義されているさまざまな設定の値を出力するコンソールアプリケーションの一部です。</span><span class="sxs-lookup"><span data-stu-id="b4702-806">The following example is part of a console application that outputs the values for a number of the settings defined for the recognizer that supports the en-US locale.</span></span> <span data-ttu-id="b4702-807">この例では、信頼レベルの設定を更新してから、レコグナイザーを照会して、更新された値を確認します。</span><span class="sxs-lookup"><span data-stu-id="b4702-807">The example updates the confidence level settings, and then queries the recognizer to check the updated values.</span></span> <span data-ttu-id="b4702-808">この例では、次の出力が生成されます。</span><span class="sxs-lookup"><span data-stu-id="b4702-808">The example generates the following output.</span></span>  
  
```  
Settings for recognizer MS-1033-80-DESK:  
  
  ResourceUsage                  is not supported by this recognizer.  
  ResponseSpeed                  = 150  
  ComplexResponseSpeed           = 500  
  AdaptationOn                   = 1  
  PersistedBackgroundAdaptation  = 1  
  
Updated settings:  
  
  ResourceUsage                  is not supported by this recognizer.  
  ResponseSpeed                  = 200  
  ComplexResponseSpeed           = 300  
  AdaptationOn                   = 0  
  PersistedBackgroundAdaptation  = 0  
  
Press any key to exit...  
```  
  
```csharp  
using System;  
using System.Globalization;  
using System.Speech.Recognition;  
  
namespace RecognizerSettings  
{  
  class Program  
  {  
    static readonly string[] settings = new string[] {  
      "ResourceUsage",  
      "ResponseSpeed",  
      "ComplexResponseSpeed",  
      "AdaptationOn",  
      "PersistedBackgroundAdaptation",  
    };  
  
    static void Main(string[] args)  
    {  
      using (SpeechRecognitionEngine recognizer =  
        new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US")))  
      {  
        Console.WriteLine("Settings for recognizer {0}:",  
          recognizer.RecognizerInfo.Name);  
        Console.WriteLine();  
  
        // List the current settings.  
        ListSettings(recognizer);  
  
        // Change some of the settings.  
        recognizer.UpdateRecognizerSetting("ResponseSpeed", 200);  
        recognizer.UpdateRecognizerSetting("ComplexResponseSpeed", 300);  
        recognizer.UpdateRecognizerSetting("AdaptationOn", 1);  
        recognizer.UpdateRecognizerSetting("PersistedBackgroundAdaptation", 0);  
  
        Console.WriteLine("Updated settings:");  
        Console.WriteLine();  
  
        // List the updated settings.  
        ListSettings(recognizer);  
      }  
  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    private static void ListSettings(SpeechRecognitionEngine recognizer)  
    {  
      foreach (string setting in settings)  
      {  
        try  
        {  
          object value = recognizer.QueryRecognizerSetting(setting);  
          Console.WriteLine("  {0,-30} = {1}", setting, value);  
        }  
        catch  
        {  
          Console.WriteLine("  {0,-30} is not supported by this recognizer.",  
            setting);  
        }  
      }  
      Console.WriteLine();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.ArgumentNullException"><span data-ttu-id="b4702-809"><paramref name="settingName" /> は <see langword="null" />です。</span><span class="sxs-lookup"><span data-stu-id="b4702-809"><paramref name="settingName" /> is <see langword="null" />.</span></span></exception>
        <exception cref="T:System.ArgumentException"><span data-ttu-id="b4702-810"><paramref name="settingName" /> が空の文字列 ("") です。</span><span class="sxs-lookup"><span data-stu-id="b4702-810"><paramref name="settingName" /> is the empty string ("").</span></span></exception>
        <exception cref="T:System.Collections.Generic.KeyNotFoundException"><span data-ttu-id="b4702-811">認識エンジンは、その名前で設定されていません。</span><span class="sxs-lookup"><span data-stu-id="b4702-811">The recognizer does not have a setting by that name.</span></span></exception>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)" />
      </Docs>
    </Member>
    <Member MemberName="UpdateRecognizerSetting">
      <MemberSignature Language="C#" Value="public void UpdateRecognizerSetting (string settingName, string updatedValue);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void UpdateRecognizerSetting(string settingName, string updatedValue) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub UpdateRecognizerSetting (settingName As String, updatedValue As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void UpdateRecognizerSetting(System::String ^ settingName, System::String ^ updatedValue);" />
      <MemberSignature Language="F#" Value="member this.UpdateRecognizerSetting : string * string -&gt; unit" Usage="speechRecognitionEngine.UpdateRecognizerSetting (settingName, updatedValue)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="settingName" Type="System.String" />
        <Parameter Name="updatedValue" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="settingName"><span data-ttu-id="b4702-812">更新する設定の名前。</span><span class="sxs-lookup"><span data-stu-id="b4702-812">The name of the setting to update.</span></span></param>
        <param name="updatedValue"><span data-ttu-id="b4702-813">設定の新しい値。</span><span class="sxs-lookup"><span data-stu-id="b4702-813">The new value for the setting.</span></span></param>
        <summary><span data-ttu-id="b4702-814">指定された音声認識エンジンの設定を、指定された文字列値で更新します。</span><span class="sxs-lookup"><span data-stu-id="b4702-814">Updates the specified speech recognition engine setting with the specified string value.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="b4702-815">`PersistedBackgroundAdaptation`を除き、<xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> メソッドを使用して設定されたプロパティ値は <xref:System.Speech.Recognition.SpeechRecognitionEngine>の現在のインスタンスに対してのみ有効です。その後、既定の設定に戻ります。</span><span class="sxs-lookup"><span data-stu-id="b4702-815">With the exception of `PersistedBackgroundAdaptation`, property values set using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> method remain in effect only for the current instance of <xref:System.Speech.Recognition.SpeechRecognitionEngine>, after which they revert to their default settings.</span></span> <span data-ttu-id="b4702-816">サポートされている設定の説明については、<xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> を参照してください。</span><span class="sxs-lookup"><span data-stu-id="b4702-816">See <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> for descriptions of supported settings.</span></span>  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.ArgumentNullException"><span data-ttu-id="b4702-817"><paramref name="settingName" /> が <see langword="null" /> です。</span><span class="sxs-lookup"><span data-stu-id="b4702-817"><paramref name="settingName" /> is <see langword="null" />.</span></span></exception>
        <exception cref="T:System.ArgumentException"><span data-ttu-id="b4702-818"><paramref name="settingName" /> が空の文字列 ("") です。</span><span class="sxs-lookup"><span data-stu-id="b4702-818"><paramref name="settingName" /> is the empty string ("").</span></span></exception>
        <exception cref="T:System.Collections.Generic.KeyNotFoundException"><span data-ttu-id="b4702-819">認識エンジンは、その名前で設定されていません。</span><span class="sxs-lookup"><span data-stu-id="b4702-819">The recognizer does not have a setting by that name.</span></span></exception>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)" />
      </Docs>
    </Member>
  </Members>
</Type>
